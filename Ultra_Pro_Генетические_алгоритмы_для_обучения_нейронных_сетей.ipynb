{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgPCBVmZFIHO"
      },
      "source": [
        "# **Задание Ultra pro**\n",
        "\n",
        "1. Возьмите любую базу, которую мы решали с помощью нейронок.\n",
        "\n",
        "2. Напишите настройку такой сети с помощью ГА.\n",
        "\n",
        "3. Сделайте мощную сеть самостоятельно.\n",
        "\n",
        "4. Добейтесь, чтобы у ГА точность была выше, чем у вашей сети.\n",
        "\n",
        "Подсказка: ГА требует большой вычислительной мощности, лучше взять базу, которая требует довольно простую сеть и на которой обучение идёт быстро."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qq1xtDuNFNI1"
      },
      "source": [
        "*********************************************\n",
        "\n",
        "В данной работе будет использована база **по обнаружению мин**. Так как она довольна простая.\n",
        "\n",
        "*********************************************"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceIpW1-sF-d3"
      },
      "source": [
        "# Подключение библиотек\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8emWD2YVJ95"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam, Adadelta\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import concatenate, Reshape, Input, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.layers import Flatten, Conv1D, Conv2D, LSTM, MaxPooling1D, Activation\n",
        "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from tensorflow.keras.losses import MAE\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from PIL import Image\n",
        "from google.colab import files\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KF9aDG4V3Sik"
      },
      "source": [
        "# Подготовка данных для обучения сети"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "5OpTfgGWiSzT",
        "outputId": "5ba8a6c3-071d-4900-a13d-c660ab4ae167"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-45c0e20f-b60a-4f46-9d63-b8031372d250\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-45c0e20f-b60a-4f46-9d63-b8031372d250\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sonar.csv to sonar.csv\n",
            "sample_data  sonar.csv\n"
          ]
        }
      ],
      "source": [
        "# Загружаем файл с данными sonar.csv\n",
        "files.upload()\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "vkIz-zC_GZr8",
        "outputId": "3a745bc9-b49f-4e7a-ffbc-75c9851cd784"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(208, 61)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7c9567b2-3de6-479a-ba66-714a1f03d0d8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0200</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.0428</td>\n",
              "      <td>0.0207</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.0986</td>\n",
              "      <td>0.1539</td>\n",
              "      <td>0.1601</td>\n",
              "      <td>0.3109</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>0.1609</td>\n",
              "      <td>0.1582</td>\n",
              "      <td>0.2238</td>\n",
              "      <td>0.0645</td>\n",
              "      <td>0.0660</td>\n",
              "      <td>0.2273</td>\n",
              "      <td>0.3100</td>\n",
              "      <td>0.2999</td>\n",
              "      <td>0.5078</td>\n",
              "      <td>0.4797</td>\n",
              "      <td>0.5783</td>\n",
              "      <td>0.5071</td>\n",
              "      <td>0.4328</td>\n",
              "      <td>0.5550</td>\n",
              "      <td>0.6711</td>\n",
              "      <td>0.6415</td>\n",
              "      <td>0.7104</td>\n",
              "      <td>0.8080</td>\n",
              "      <td>0.6791</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>0.1307</td>\n",
              "      <td>0.2604</td>\n",
              "      <td>0.5121</td>\n",
              "      <td>0.7547</td>\n",
              "      <td>0.8537</td>\n",
              "      <td>0.8507</td>\n",
              "      <td>0.6692</td>\n",
              "      <td>0.6097</td>\n",
              "      <td>0.4943</td>\n",
              "      <td>0.2744</td>\n",
              "      <td>0.0510</td>\n",
              "      <td>0.2834</td>\n",
              "      <td>0.2825</td>\n",
              "      <td>0.4256</td>\n",
              "      <td>0.2641</td>\n",
              "      <td>0.1386</td>\n",
              "      <td>0.1051</td>\n",
              "      <td>0.1343</td>\n",
              "      <td>0.0383</td>\n",
              "      <td>0.0324</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0159</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0523</td>\n",
              "      <td>0.0843</td>\n",
              "      <td>0.0689</td>\n",
              "      <td>0.1183</td>\n",
              "      <td>0.2583</td>\n",
              "      <td>0.2156</td>\n",
              "      <td>0.3481</td>\n",
              "      <td>0.3337</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>0.4918</td>\n",
              "      <td>0.6552</td>\n",
              "      <td>0.6919</td>\n",
              "      <td>0.7797</td>\n",
              "      <td>0.7464</td>\n",
              "      <td>0.9444</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8874</td>\n",
              "      <td>0.8024</td>\n",
              "      <td>0.7818</td>\n",
              "      <td>0.5212</td>\n",
              "      <td>0.4052</td>\n",
              "      <td>0.3957</td>\n",
              "      <td>0.3914</td>\n",
              "      <td>0.3250</td>\n",
              "      <td>0.3200</td>\n",
              "      <td>0.3271</td>\n",
              "      <td>0.2767</td>\n",
              "      <td>0.4423</td>\n",
              "      <td>0.2028</td>\n",
              "      <td>0.3788</td>\n",
              "      <td>0.2947</td>\n",
              "      <td>0.1984</td>\n",
              "      <td>0.2341</td>\n",
              "      <td>0.1306</td>\n",
              "      <td>0.4182</td>\n",
              "      <td>0.3835</td>\n",
              "      <td>0.1057</td>\n",
              "      <td>0.1840</td>\n",
              "      <td>0.1970</td>\n",
              "      <td>0.1674</td>\n",
              "      <td>0.0583</td>\n",
              "      <td>0.1401</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.0621</td>\n",
              "      <td>0.0203</td>\n",
              "      <td>0.0530</td>\n",
              "      <td>0.0742</td>\n",
              "      <td>0.0409</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0125</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.1099</td>\n",
              "      <td>0.1083</td>\n",
              "      <td>0.0974</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>0.3771</td>\n",
              "      <td>0.5598</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>0.6333</td>\n",
              "      <td>0.7060</td>\n",
              "      <td>0.5544</td>\n",
              "      <td>0.5320</td>\n",
              "      <td>0.6479</td>\n",
              "      <td>0.6931</td>\n",
              "      <td>0.6759</td>\n",
              "      <td>0.7551</td>\n",
              "      <td>0.8929</td>\n",
              "      <td>0.8619</td>\n",
              "      <td>0.7974</td>\n",
              "      <td>0.6737</td>\n",
              "      <td>0.4293</td>\n",
              "      <td>0.3648</td>\n",
              "      <td>0.5331</td>\n",
              "      <td>0.2413</td>\n",
              "      <td>0.5070</td>\n",
              "      <td>0.8533</td>\n",
              "      <td>0.6036</td>\n",
              "      <td>0.8514</td>\n",
              "      <td>0.8512</td>\n",
              "      <td>0.5045</td>\n",
              "      <td>0.1862</td>\n",
              "      <td>0.2709</td>\n",
              "      <td>0.4232</td>\n",
              "      <td>0.3043</td>\n",
              "      <td>0.6116</td>\n",
              "      <td>0.6756</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.4719</td>\n",
              "      <td>0.4647</td>\n",
              "      <td>0.2587</td>\n",
              "      <td>0.2129</td>\n",
              "      <td>0.2222</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>0.0176</td>\n",
              "      <td>0.1348</td>\n",
              "      <td>0.0744</td>\n",
              "      <td>0.0130</td>\n",
              "      <td>0.0106</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0166</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0244</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0164</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0171</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.1276</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.1264</td>\n",
              "      <td>0.0881</td>\n",
              "      <td>0.1992</td>\n",
              "      <td>0.0184</td>\n",
              "      <td>0.2261</td>\n",
              "      <td>0.1729</td>\n",
              "      <td>0.2131</td>\n",
              "      <td>0.0693</td>\n",
              "      <td>0.2281</td>\n",
              "      <td>0.4060</td>\n",
              "      <td>0.3973</td>\n",
              "      <td>0.2741</td>\n",
              "      <td>0.3690</td>\n",
              "      <td>0.5556</td>\n",
              "      <td>0.4846</td>\n",
              "      <td>0.3140</td>\n",
              "      <td>0.5334</td>\n",
              "      <td>0.5256</td>\n",
              "      <td>0.2520</td>\n",
              "      <td>0.2090</td>\n",
              "      <td>0.3559</td>\n",
              "      <td>0.6260</td>\n",
              "      <td>0.7340</td>\n",
              "      <td>0.6120</td>\n",
              "      <td>0.3497</td>\n",
              "      <td>0.3953</td>\n",
              "      <td>0.3012</td>\n",
              "      <td>0.5408</td>\n",
              "      <td>0.8814</td>\n",
              "      <td>0.9857</td>\n",
              "      <td>0.9167</td>\n",
              "      <td>0.6121</td>\n",
              "      <td>0.5006</td>\n",
              "      <td>0.3210</td>\n",
              "      <td>0.3202</td>\n",
              "      <td>0.4295</td>\n",
              "      <td>0.3654</td>\n",
              "      <td>0.2655</td>\n",
              "      <td>0.1576</td>\n",
              "      <td>0.0681</td>\n",
              "      <td>0.0294</td>\n",
              "      <td>0.0241</td>\n",
              "      <td>0.0121</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0762</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.0481</td>\n",
              "      <td>0.0394</td>\n",
              "      <td>0.0590</td>\n",
              "      <td>0.0649</td>\n",
              "      <td>0.1209</td>\n",
              "      <td>0.2467</td>\n",
              "      <td>0.3564</td>\n",
              "      <td>0.4459</td>\n",
              "      <td>0.4152</td>\n",
              "      <td>0.3952</td>\n",
              "      <td>0.4256</td>\n",
              "      <td>0.4135</td>\n",
              "      <td>0.4528</td>\n",
              "      <td>0.5326</td>\n",
              "      <td>0.7306</td>\n",
              "      <td>0.6193</td>\n",
              "      <td>0.2032</td>\n",
              "      <td>0.4636</td>\n",
              "      <td>0.4148</td>\n",
              "      <td>0.4292</td>\n",
              "      <td>0.5730</td>\n",
              "      <td>0.5399</td>\n",
              "      <td>0.3161</td>\n",
              "      <td>0.2285</td>\n",
              "      <td>0.6995</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.7262</td>\n",
              "      <td>0.4724</td>\n",
              "      <td>0.5103</td>\n",
              "      <td>0.5459</td>\n",
              "      <td>0.2881</td>\n",
              "      <td>0.0981</td>\n",
              "      <td>0.1951</td>\n",
              "      <td>0.4181</td>\n",
              "      <td>0.4604</td>\n",
              "      <td>0.3217</td>\n",
              "      <td>0.2828</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.1979</td>\n",
              "      <td>0.2444</td>\n",
              "      <td>0.1847</td>\n",
              "      <td>0.0841</td>\n",
              "      <td>0.0692</td>\n",
              "      <td>0.0528</td>\n",
              "      <td>0.0357</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0230</td>\n",
              "      <td>0.0046</td>\n",
              "      <td>0.0156</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0110</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0107</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c9567b2-3de6-479a-ba66-714a1f03d0d8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c9567b2-3de6-479a-ba66-714a1f03d0d8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c9567b2-3de6-479a-ba66-714a1f03d0d8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       0       1       2       3       4   ...      56      57      58      59  60\n",
              "0  0.0200  0.0371  0.0428  0.0207  0.0954  ...  0.0180  0.0084  0.0090  0.0032   R\n",
              "1  0.0453  0.0523  0.0843  0.0689  0.1183  ...  0.0140  0.0049  0.0052  0.0044   R\n",
              "2  0.0262  0.0582  0.1099  0.1083  0.0974  ...  0.0316  0.0164  0.0095  0.0078   R\n",
              "3  0.0100  0.0171  0.0623  0.0205  0.0205  ...  0.0050  0.0044  0.0040  0.0117   R\n",
              "4  0.0762  0.0666  0.0481  0.0394  0.0590  ...  0.0072  0.0048  0.0107  0.0094   R\n",
              "\n",
              "[5 rows x 61 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Загружаем данные из файла sonar.csv\n",
        "df = pd.read_csv('sonar.csv', header=None)\n",
        "print(df.shape) # Размерность данных\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eV7UrVuUJMlR"
      },
      "outputs": [],
      "source": [
        "dataset = df.values                 # Берем только значения массива(без индексов)\n",
        "X = dataset[:,0:60].astype(float)   # Присваиваем переменной Х значения с 0 по 60 колонки, тип данных float\n",
        "Y = dataset[:,60]                   # А переменной Y данные из столбца с индексом 60\n",
        "\n",
        "Y[Y=='R']='0'                       # Если значение элемента столбца равно 'R', присваеваем ему значение '0'\n",
        "Y[Y=='M']='1'                       # Если значение элемента столбца равно 'Y', присваеваем ему значение '1'\n",
        "Y = Y.astype(int)                   # Меняем тип данных столбца на 'int'(целочисленный тип данных)     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FupztbnXJzuW"
      },
      "outputs": [],
      "source": [
        "# Будет выделено 20% от тренировочных данных на тестовую, и будут перемешаны\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmTr_lXTKNbN"
      },
      "source": [
        "# Создание нейронной сети для сраврения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yi-wF-oyQd41"
      },
      "outputs": [],
      "source": [
        "# model = Sequential()\n",
        "\n",
        "# model.add(Dense(60, input_dim=60, activation='relu'))\n",
        "# model.add(Dense(30,  activation='relu'))\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "\n",
        "# history = model.fit(x_train, y_train, batch_size=8, epochs=50, validation_split=0.2, verbose=0)\n",
        "\n",
        "# print(\"Количество эпох: 50\")\n",
        "# print(f\"Ошибка на тестовой выборке  : {round(history.history['val_loss'][-1], 4)}\")\n",
        "# print(f\"Точность на тестовой выборке: {100 * round(history.history['val_accuracy'][-1], 2)} %\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxNIcjXBCbOx"
      },
      "source": [
        "## Проверяем качество обучения на тестовом наборе данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pqt-J9GKCbPB"
      },
      "outputs": [],
      "source": [
        "# # Вычисляем результаты сети на тестовом наборе\n",
        "# scores_drop = model.evaluate(x_test, y_test, verbose=1)\n",
        "# print(\"Верных ответов: \", round(scores_drop[1] * 100, 4), \"%\", sep=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F10JmZ2pUu23"
      },
      "source": [
        "# Реализация **ГА**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVRLql2-evUA"
      },
      "source": [
        "### Необходимые функции"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEcW95XHkmjP"
      },
      "outputs": [],
      "source": [
        "# Функция получения родителей\n",
        "def getParents(curr_popul, nsurv):\n",
        "  indexp1 = random.randint(0, nsurv - 1)\n",
        "  indexp2 = random.randint(0, nsurv - 1)\n",
        "  botp1 = curr_popul[indexp1]\n",
        "  botp2 = curr_popul[indexp2]\n",
        "  return botp1, botp2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_oFg5zebja12"
      },
      "outputs": [],
      "source": [
        "# Функция смешивания (кроссинговера) двух родителей\n",
        "def crossPointFrom2Parents(botp1, botp2, j):\n",
        "  pindex = random.random()\n",
        "  if pindex < 0.5:\n",
        "    x = botp1[j]\n",
        "  else:\n",
        "    x = botp2[j]\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oO3G3JdwlMd"
      },
      "outputs": [],
      "source": [
        "# Функция вычисления результата работы сети\n",
        "def evaluateNet(net, epochs=100, verb=False):\n",
        "  val = 0\n",
        "  #time.time()\n",
        "  model = createConvNet(net)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=1e-4), metrics=['accuracy'])\n",
        "  history = model.fit(x_train, y_train, epochs=epochs, validation_data=(x_test ,y_test), verbose=verb)\n",
        "  val = history.history['val_accuracy'][-1]\n",
        "  return val #, model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Первый вариант"
      ],
      "metadata": {
        "id": "OJCMwYiHKRwa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1yXVkxNsuhd"
      },
      "source": [
        "## Подбор архитектуры "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98IWtGzY8GFm"
      },
      "outputs": [],
      "source": [
        "# Функция создания списка случайных параметров\n",
        "def createRandomNet():\n",
        "  net = []\n",
        "  net.append(random.randint(0,1))  # 0- Нормализация 0,1\n",
        "  net.append(random.randint(2,50)) # 1- Число нейронов(которое будут изменяться)\n",
        "  net.append(random.randint(0,1))  # 2- Способ изменения нейронов в Dense слое\n",
        "  net.append(random.randint(0,5))  # 3- Функция активации первого слоя - ['linear','relu','elu','tanh','softmax','sigmoid']\n",
        "  net.append(random.randint(0,1))  # 4- Будет ли Dropout 0,1\n",
        "  net.append(random.randint(0,3))  # 5- Установка параметра rate в слое Dropout (0.25, 0.3, 0.35, 0.4)\n",
        "\n",
        "\n",
        "  net.append(random.randint(0,1))  # 6 - Будет ли добавлен второй блок\n",
        "  net.append(random.randint(0,1))  # 7-  Нормализация 0,1\n",
        "  net.append(random.randint(2,50)) # 8-  Число нейронов(которое будут изменяться)\n",
        "  net.append(random.randint(0,1))  # 9-  Способ изменения нейронов в Dense слое\n",
        "  net.append(random.randint(0,5))  # 10- Функция активации второго слоя - ['linear','relu','elu','tanh','softmax','sigmoid']\n",
        "  net.append(random.randint(0,1))  # 11- Будет ли Dropout 0,1\n",
        "  net.append(random.randint(0,3))  # 12- Установка параметра rate в слое Dropout (0.25, 0.3, 0.35, 0.4)\n",
        "\n",
        "  net.append(random.randint(0,1))  # 13 - Будет ли добавлен третий блок\n",
        "  net.append(random.randint(0,1))  # 14-  Нормализация 0,1\n",
        "  net.append(random.randint(2,50)) # 15-  Число нейронов(которое будут изменяться)\n",
        "  net.append(random.randint(0,1))  # 16- Способ изменения нейронов в Dense слое\n",
        "  net.append(random.randint(0,5))  # 17- Функция активации третьего слоя - ['linear','relu','elu','tanh','softmax','sigmoid']\n",
        "  net.append(random.randint(0,1))  # 18- Будет ли Dropout 0,1\n",
        "  net.append(random.randint(0,3))  # 19- Установка параметра rate в слое Dropout (0.25, 0.3, 0.35, 0.4)\n",
        "\n",
        "  net.append(random.randint(0,1))  # 20 - Будет ли добавлен четвертый блок\n",
        "  net.append(random.randint(0,1))  # 21-  Нормализация 0,1\n",
        "  net.append(random.randint(2,50)) # 22-  Число нейронов(которое будут изменяться)\n",
        "  net.append(random.randint(0,1))  # 23- Способ изменения нейронов в Dense слое\n",
        "  net.append(random.randint(0,5))  # 24- Функция активации четвертого слоя - ['linear','relu','elu','tanh','softmax','sigmoid']\n",
        "  net.append(random.randint(0,1))  # 25- Будет ли Dropout 0,1\n",
        "  net.append(random.randint(0,3))  # 26- Установка параметра rate в слое Dropout (0.25, 0.3, 0.35, 0.4)\n",
        "\n",
        "\n",
        "  net.append(random.randint(0,1))  # 27- Нормализация 0,1(Перед выходным слоем)\n",
        "  net.append(random.randint(0,4))  # 28- Функция активации выходного слоя - ['linear','relu','elu','softmax','sigmoid']\n",
        "\n",
        "  return net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6EIXu1dKoju"
      },
      "outputs": [],
      "source": [
        "# Функция создания модели\n",
        "def createConvNet(net):\n",
        " \n",
        "  makeFirstNormalization = net[0]       # 0 - Нормализация в начале 0,1\n",
        "  firstDenseNeurons = net[1]            # 1-  Число нейронов(которое будут изменяться)\n",
        "  firstСhangeNeurons = net[2]           # 2-  Способ изменения нейронов в Dense слое(0-умножение на 10; 1-степень)\n",
        "  activation1 = net[3]                  # 3-  Функция активации первого слоя - ['linear','relu','elu','softmax','sigmoid','tanh']\n",
        "  makeDropOut1 = net[4]                 # 4 - Будет ли Dropout 0,1\n",
        "  firstDropout = net[5]                 # 5 - Установка параметра rate в слое Dropout (0.25, 0.3, 0.35, 0.4)\n",
        "\n",
        "  secondLaeyrsDense = net[6]            # 6 - Будет ли добавлен второй блок\n",
        "  makeSecondNormalization = net[7]      # 7 - Нормализация второго блока\n",
        "  secondDenseNeurons = net[8]           # 8-  Число нейронов(которое будут изменяться)\n",
        "  secondСhangeNeurons = net[9]          # 9-  Способ изменения нейронов в Dense слое\n",
        "  activation2 = net[10]                 # 10- Функция активации второго блока - ['linear','relu','elu','softmax','sigmoid','tanh']\n",
        "  makeDropOut2 = net[11]                # 11- Будет ли Dropout 0,1\n",
        "  secondDropout = net[12]               # 12- Установка параметра rate в слое Dropout (0.25, 0.3, 0.35, 0.4)\n",
        "\n",
        "  thirdLaeyrsDense = net[13]            # 13- Будет ли добавлен третий блок\n",
        "  makeThirdNormalization = net[14]      # 14- Нормализация второго блока\n",
        "  thirdDenseNeurons = net[15]           # 15- Число нейронов(которое будут изменяться)\n",
        "  thirdСhangeNeurons = net[16]          # 16- Способ изменения нейронов в Dense слое\n",
        "  activation3 = net[17]                 # 17- Функция активации третьего блока - ['linear','relu','elu','softmax','sigmoid','tanh']\n",
        "  makeDropOut3 = net[18]                # 18- Будет ли Dropout 0,1\n",
        "  thirdDropout = net[19]                # 19- Установка параметра rate в слое Dropout (0.25, 0.3, 0.35, 0.4)\n",
        "\n",
        "\n",
        "  fourthLaeyrsDense = net[20]           # 20- Будет ли добавлен четвертый блок\n",
        "  makeFourthNormalization = net[21]     # 21- Нормализация второго блока\n",
        "  fourthDenseNeurons = net[22]          # 22- Число нейронов(которое будут изменяться)\n",
        "  fourthСhangeNeurons = net[23]         # 23- Способ изменения нейронов в Dense слое\n",
        "  activation4 = net[24]                 # 24- Функция активации четвертого блока - ['linear','relu','elu','softmax','sigmoid','tanh']\n",
        "  makeDropOut4 = net[25]                # 25- Будет ли Dropout 0,1\n",
        "  fourthDropout = net[26]               # 26- Установка параметра rate в слое Dropout (0.25, 0.3, 0.35, 0.4)\n",
        "\n",
        "  finalNormalization = net[27]          # 21- Нормализация перед выходным слоем\n",
        "  activation5 = net[28]                 # 24- Функция активации выходного слоя - ['linear','relu','elu','softmax','sigmoid'] - без tanh\n",
        "\n",
        "\n",
        "  activation_list = ['linear','relu','elu','softmax','sigmoid','tanh']\n",
        "  dropout_list = [0.25, 0.3, 0.35, 0.4]\n",
        "\n",
        "  shape = (60,)\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  if makeFirstNormalization:                                                              # Нормализация в начале \n",
        "    model.add(BatchNormalization(input_shape=(shape)))\n",
        "    if firstСhangeNeurons:\n",
        "      model.add(Dense(firstDenseNeurons**2, activation=activation_list[activation1]))    # Добавление Dense слоя\n",
        "    else:\n",
        "      model.add(Dense(firstDenseNeurons*10, activation=activation_list[activation1]))\n",
        "  \n",
        "  else:  # Или без нормализации\n",
        "    if firstСhangeNeurons:\n",
        "      model.add(Dense(firstDenseNeurons**2, activation=activation_list[activation1], input_shape=(shape)))\n",
        "    else:\n",
        "      model.add(Dense(firstDenseNeurons*10, activation=activation_list[activation1], input_shape=(shape)))\n",
        "  \n",
        "  if makeDropOut1:   # Будет ли Dropout\n",
        "    model.add(Dropout(dropout_list[firstDropout]))\n",
        "\n",
        "\n",
        "\n",
        "  if secondLaeyrsDense:   #  Будет ли второй блок\n",
        "\n",
        "    if makeSecondNormalization:\n",
        "      model.add(BatchNormalization())\n",
        "\n",
        "    if secondСhangeNeurons:\n",
        "      model.add(Dense(secondDenseNeurons**2, activation=activation_list[activation2]))\n",
        "    else:\n",
        "      model.add(Dense(secondDenseNeurons*10, activation=activation_list[activation2]))\n",
        "\n",
        "    if makeDropOut2:   # Будет ли Dropout\n",
        "      model.add(Dropout(dropout_list[secondDropout]))\n",
        "\n",
        "\n",
        "  if thirdLaeyrsDense:   #  Будет ли третий блок\n",
        "\n",
        "    if makeThirdNormalization:\n",
        "      model.add(BatchNormalization())\n",
        "\n",
        "    if thirdСhangeNeurons:\n",
        "      model.add(Dense(thirdDenseNeurons**2, activation=activation_list[activation3]))\n",
        "    else:\n",
        "      model.add(Dense(thirdDenseNeurons*10, activation=activation_list[activation3]))\n",
        "\n",
        "    if makeDropOut3:   # Будет ли Dropout\n",
        "      model.add(Dropout(dropout_list[thirdDropout]))\n",
        "\n",
        "\n",
        "  if fourthLaeyrsDense:   #  Будет ли четвертый блок\n",
        "\n",
        "      if makeFourthNormalization:\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "      if fourthСhangeNeurons:\n",
        "        model.add(Dense(fourthDenseNeurons**2, activation=activation_list[activation4]))\n",
        "      else:\n",
        "        model.add(Dense(fourthDenseNeurons*10, activation=activation_list[activation4]))\n",
        "\n",
        "      if makeDropOut4:   # Будет ли Dropout\n",
        "        model.add(Dropout(dropout_list[fourthDropout]))\n",
        "\n",
        "  \n",
        "  if finalNormalization:   # Нормализация перед выходным слоем\n",
        "    model.add(BatchNormalization())\n",
        "  \n",
        "  model.add(Dense(1, activation=activation_list[activation5]))  #  Без tanh\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCppKi8mx2BE"
      },
      "outputs": [],
      "source": [
        "n = 50            # Общее число ботов\n",
        "nsurv = 10        # Кол-во выживших\n",
        "nnew = n - nsurv  # Кол-во новых\n",
        "l = 29            # Размер бота\n",
        "epochs = 50       # Количество эпох\n",
        "\n",
        "mut = 0.99        # Коэфициент мутаций"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mn-anHNAC5GE",
        "outputId": "1a55cec0-d8ca-4b79-a429-3b6e93d6a7b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 0  --- время: 242.14 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8571428656578064, 0.8333333134651184, 0.8333333134651184, 0.8333333134651184]  ----- Лучшие боты: [[1, 50, 0, 3, 1, 0, 1, 0, 47, 1, 5, 1, 0, 1, 0, 12, 0, 1, 0, 1, 1, 0, 31, 1, 0, 1, 2, 0, 1], [1, 28, 1, 5, 0, 2, 0, 1, 7, 0, 1, 0, 2, 0, 1, 26, 1, 5, 0, 2, 0, 1, 42, 0, 0, 1, 3, 1, 4], [1, 8, 0, 2, 0, 3, 1, 0, 11, 1, 0, 1, 0, 1, 0, 44, 1, 4, 1, 3, 0, 1, 50, 0, 4, 1, 3, 1, 2], [1, 38, 0, 4, 0, 3, 0, 0, 15, 1, 5, 0, 0, 1, 0, 26, 1, 5, 1, 1, 1, 1, 19, 0, 1, 0, 2, 1, 1], [1, 38, 1, 1, 1, 3, 1, 1, 50, 1, 2, 1, 3, 1, 1, 40, 1, 4, 1, 0, 1, 1, 15, 0, 2, 0, 3, 0, 0]]\n",
            "\n",
            "Эпоха 1  --- время: 230.82 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8095238208770752, 0.8095238208770752, 0.8095238208770752, 0.7857142686843872]  ----- Лучшие боты: [[1, 38, 0, 4, 0, 3, 0, 0, 15, 1, 5, 0, 0, 1, 0, 26, 1, 5, 1, 1, 1, 1, 19, 0, 1, 0, 2, 1, 1], [1, 38, 0, 4, 0, 3, 0, 0, 15, 1, 5, 0, 0, 1, 0, 26, 1, 5, 1, 1, 1, 1, 19, 0, 1, 0, 2, 1, 1], [1, 8, 0, 2, 0, 3, 1, 0, 11, 1, 0, 1, 0, 1, 0, 44, 1, 4, 1, 3, 0, 1, 50, 0, 4, 1, 3, 1, 2], [1, 8, 0, 2, 0, 3, 1, 0, 11, 1, 0, 1, 0, 1, 0, 44, 1, 4, 1, 3, 0, 1, 50, 0, 4, 1, 3, 1, 2], [1, 8, 0, 2, 0, 3, 1, 0, 11, 1, 0, 1, 0, 1, 0, 44, 1, 4, 1, 3, 0, 1, 50, 0, 4, 1, 3, 1, 2]]\n",
            "\n",
            "Эпоха 2  --- время: 248.59 \n",
            "Лучшие результаты: [0.7857142686843872, 0.7857142686843872, 0.7857142686843872, 0.761904776096344, 0.761904776096344]  ----- Лучшие боты: [[0, 9, 1, 0, 0, 1, 0, 0, 46, 0, 1, 0, 0, 1, 0, 3, 0, 2, 1, 2, 0, 0, 37, 1, 0, 0, 0, 0, 0], [0, 38, 0, 2, 0, 3, 1, 1, 4, 0, 1, 1, 2, 0, 1, 25, 1, 2, 1, 2, 1, 0, 48, 0, 1, 0, 0, 1, 4], [0, 38, 0, 2, 0, 3, 1, 1, 4, 0, 1, 1, 2, 0, 1, 25, 1, 2, 1, 2, 1, 0, 48, 0, 1, 0, 0, 1, 4], [0, 38, 0, 2, 0, 3, 1, 1, 4, 0, 1, 1, 2, 0, 1, 25, 1, 2, 1, 2, 1, 0, 48, 0, 1, 0, 0, 1, 4], [0, 38, 0, 2, 0, 3, 1, 1, 4, 0, 1, 1, 2, 0, 1, 25, 1, 2, 1, 2, 1, 0, 48, 0, 1, 0, 0, 1, 4]]\n",
            "\n",
            "Эпоха 3  --- время: 264.86 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8571428656578064, 0.8333333134651184, 0.8333333134651184, 0.8333333134651184]  ----- Лучшие боты: [[0, 38, 0, 2, 0, 3, 1, 1, 4, 0, 1, 1, 2, 0, 1, 25, 1, 2, 1, 2, 1, 0, 48, 0, 1, 0, 0, 1, 4], [0, 38, 0, 2, 0, 3, 1, 1, 4, 0, 1, 1, 2, 0, 1, 25, 1, 2, 1, 2, 1, 0, 48, 0, 1, 0, 0, 1, 4], [0, 38, 0, 2, 0, 3, 1, 1, 4, 0, 1, 1, 2, 0, 1, 25, 1, 2, 1, 2, 1, 0, 48, 0, 1, 0, 0, 1, 4], [0, 38, 0, 2, 0, 3, 1, 1, 4, 0, 1, 1, 2, 0, 1, 25, 1, 2, 1, 2, 1, 0, 48, 0, 1, 0, 0, 1, 4], [0, 38, 0, 2, 0, 3, 1, 1, 4, 0, 1, 1, 2, 0, 1, 25, 1, 2, 1, 2, 1, 0, 48, 0, 1, 0, 0, 1, 4]]\n",
            "\n",
            "Эпоха 4  --- время: 253.47 \n",
            "Лучшие результаты: [0.8333333134651184, 0.8095238208770752, 0.8095238208770752, 0.8095238208770752, 0.7857142686843872]  ----- Лучшие боты: [[0, 38, 0, 2, 0, 3, 1, 1, 4, 0, 1, 1, 2, 0, 1, 25, 1, 2, 1, 2, 1, 0, 48, 0, 1, 0, 0, 1, 4], [0, 38, 0, 2, 0, 3, 1, 1, 4, 0, 1, 1, 2, 0, 1, 25, 1, 2, 1, 2, 1, 0, 48, 0, 1, 0, 0, 1, 4], [0, 38, 0, 2, 0, 3, 1, 1, 4, 0, 1, 1, 2, 0, 1, 25, 1, 2, 1, 2, 1, 0, 48, 0, 1, 0, 0, 1, 4], [0, 38, 0, 2, 0, 3, 1, 1, 4, 0, 1, 1, 2, 0, 1, 25, 1, 2, 1, 2, 1, 0, 48, 0, 1, 0, 0, 1, 4], [0, 38, 0, 2, 0, 3, 1, 1, 4, 0, 1, 1, 2, 0, 1, 25, 1, 2, 1, 2, 1, 0, 48, 0, 1, 0, 0, 1, 4]]\n",
            "\n",
            "Эпоха 5  --- время: 242.89 \n",
            "Лучшие результаты: [0.8333333134651184, 0.8095238208770752, 0.7857142686843872, 0.7857142686843872, 0.761904776096344]  ----- Лучшие боты: [[0, 38, 0, 2, 0, 3, 1, 1, 4, 0, 1, 1, 2, 0, 1, 25, 1, 2, 1, 2, 1, 0, 48, 0, 1, 0, 0, 1, 4], [0, 38, 0, 2, 0, 3, 1, 1, 4, 0, 1, 1, 2, 0, 1, 25, 1, 2, 1, 2, 1, 0, 48, 0, 1, 0, 0, 1, 4], [0, 38, 0, 2, 0, 3, 1, 1, 4, 0, 1, 1, 2, 0, 1, 25, 1, 2, 1, 2, 1, 0, 48, 0, 1, 0, 0, 1, 4], [0, 38, 0, 2, 0, 3, 1, 1, 4, 0, 1, 1, 2, 0, 1, 25, 1, 2, 1, 2, 1, 0, 48, 0, 1, 0, 0, 1, 4], [0, 23, 0, 0, 0, 2, 1, 1, 44, 0, 3, 0, 3, 0, 0, 4, 1, 5, 1, 0, 1, 0, 18, 1, 0, 1, 2, 1, 4]]\n",
            "\n",
            "Эпоха 6  --- время: 263.85 \n",
            "Лучшие результаты: [0.8095238208770752, 0.8095238208770752, 0.8095238208770752, 0.7857142686843872, 0.7857142686843872]  ----- Лучшие боты: [[0, 38, 0, 2, 0, 3, 1, 1, 4, 0, 1, 1, 2, 0, 1, 25, 1, 2, 1, 2, 1, 0, 48, 0, 1, 0, 0, 1, 4], [0, 38, 0, 2, 0, 3, 1, 1, 4, 0, 1, 1, 2, 0, 1, 25, 1, 2, 1, 2, 1, 0, 48, 0, 1, 0, 0, 1, 4], [0, 23, 0, 0, 0, 2, 1, 1, 44, 0, 3, 0, 3, 0, 0, 4, 1, 5, 1, 0, 1, 0, 18, 1, 0, 1, 2, 1, 4], [0, 23, 0, 0, 0, 2, 1, 1, 44, 0, 3, 0, 3, 0, 0, 4, 1, 5, 1, 0, 1, 0, 18, 1, 0, 1, 2, 1, 4], [0, 23, 0, 0, 0, 2, 1, 1, 44, 0, 3, 0, 3, 0, 0, 4, 1, 5, 1, 0, 1, 0, 18, 1, 0, 1, 2, 1, 4]]\n",
            "\n",
            "Эпоха 7  --- время: 242.85 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8095238208770752, 0.761904776096344, 0.761904776096344, 0.761904776096344]  ----- Лучшие боты: [[0, 23, 0, 0, 0, 2, 1, 1, 44, 0, 3, 0, 3, 0, 0, 4, 1, 5, 1, 0, 1, 0, 18, 1, 0, 1, 2, 1, 4], [0, 23, 0, 0, 0, 2, 1, 1, 44, 0, 3, 0, 3, 0, 0, 4, 1, 5, 1, 0, 1, 0, 18, 1, 0, 1, 2, 1, 4], [0, 23, 0, 0, 0, 2, 1, 1, 44, 0, 3, 0, 3, 0, 0, 4, 1, 5, 1, 0, 1, 0, 18, 1, 0, 1, 2, 1, 4], [0, 38, 0, 2, 0, 3, 1, 1, 4, 0, 1, 1, 2, 0, 1, 25, 1, 2, 1, 2, 1, 0, 48, 0, 1, 0, 0, 1, 4], [0, 38, 0, 2, 0, 3, 1, 1, 4, 0, 1, 1, 2, 0, 1, 25, 1, 2, 1, 2, 1, 0, 48, 0, 1, 0, 0, 1, 4]]\n",
            "\n",
            "Эпоха 8  --- время: 239.6 \n",
            "Лучшие результаты: [0.8333333134651184, 0.8095238208770752, 0.8095238208770752, 0.7857142686843872, 0.761904776096344]  ----- Лучшие боты: [[0, 38, 0, 2, 0, 3, 1, 1, 4, 0, 1, 1, 2, 0, 1, 25, 1, 2, 1, 2, 1, 0, 48, 0, 1, 0, 0, 1, 4], [1, 31, 0, 1, 0, 0, 1, 1, 49, 0, 0, 0, 0, 0, 0, 27, 1, 1, 1, 0, 0, 0, 9, 1, 3, 1, 2, 0, 4], [0, 23, 0, 0, 0, 2, 1, 1, 44, 0, 3, 0, 3, 0, 0, 4, 1, 5, 1, 0, 1, 0, 18, 1, 0, 1, 2, 1, 4], [0, 23, 0, 0, 0, 2, 1, 1, 44, 0, 3, 0, 3, 0, 0, 4, 1, 5, 1, 0, 1, 0, 18, 1, 0, 1, 2, 1, 4], [0, 23, 0, 0, 0, 2, 1, 1, 44, 0, 3, 0, 3, 0, 0, 4, 1, 5, 1, 0, 1, 0, 18, 1, 0, 1, 2, 1, 4]]\n",
            "\n",
            "Эпоха 9  --- время: 232.82 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8333333134651184, 0.8333333134651184, 0.8095238208770752, 0.8095238208770752]  ----- Лучшие боты: [[1, 31, 0, 1, 0, 0, 1, 1, 49, 0, 0, 0, 0, 0, 0, 27, 1, 1, 1, 0, 0, 0, 9, 1, 3, 1, 2, 0, 4], [0, 12, 0, 1, 1, 0, 1, 0, 35, 1, 1, 0, 3, 1, 1, 11, 1, 5, 1, 1, 1, 1, 27, 0, 4, 1, 3, 0, 1], [0, 12, 0, 1, 1, 0, 1, 0, 35, 1, 1, 0, 3, 1, 1, 11, 1, 5, 1, 1, 1, 1, 27, 0, 4, 1, 3, 0, 1], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 38, 0, 2, 0, 3, 1, 1, 4, 0, 1, 1, 2, 0, 1, 25, 1, 2, 1, 2, 1, 0, 48, 0, 1, 0, 0, 1, 4]]\n",
            "\n",
            "Эпоха 10  --- время: 229.13 \n",
            "Лучшие результаты: [0.8333333134651184, 0.8333333134651184, 0.8333333134651184, 0.8333333134651184, 0.7857142686843872]  ----- Лучшие боты: [[0, 38, 0, 2, 0, 3, 1, 1, 4, 0, 1, 1, 2, 0, 1, 25, 1, 2, 1, 2, 1, 0, 48, 0, 1, 0, 0, 1, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 38, 0, 2, 0, 3, 1, 1, 4, 0, 1, 1, 2, 0, 1, 25, 1, 2, 1, 2, 1, 0, 48, 0, 1, 0, 0, 1, 4], [0, 38, 0, 2, 0, 3, 1, 1, 4, 0, 1, 1, 2, 0, 1, 25, 1, 2, 1, 2, 1, 0, 48, 0, 1, 0, 0, 1, 4]]\n",
            "\n",
            "Эпоха 11  --- время: 226.28 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8333333134651184, 0.8095238208770752, 0.7857142686843872, 0.7857142686843872]  ----- Лучшие боты: [[0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 12  --- время: 231.25 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8571428656578064, 0.8333333134651184, 0.8333333134651184, 0.8333333134651184]  ----- Лучшие боты: [[0, 25, 0, 0, 0, 1, 1, 0, 11, 1, 1, 0, 2, 1, 1, 40, 1, 4, 0, 0, 0, 1, 17, 0, 3, 1, 3, 1, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 13  --- время: 245.88 \n",
            "Лучшие результаты: [0.8333333134651184, 0.8333333134651184, 0.8095238208770752, 0.8095238208770752, 0.8095238208770752]  ----- Лучшие боты: [[0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 14  --- время: 238.29 \n",
            "Лучшие результаты: [0.8333333134651184, 0.8333333134651184, 0.8333333134651184, 0.8333333134651184, 0.8095238208770752]  ----- Лучшие боты: [[0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 15  --- время: 216.81 \n",
            "Лучшие результаты: [0.8333333134651184, 0.8333333134651184, 0.8333333134651184, 0.8095238208770752, 0.8095238208770752]  ----- Лучшие боты: [[0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 16  --- время: 245.3 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8333333134651184, 0.8333333134651184, 0.8333333134651184, 0.8095238208770752]  ----- Лучшие боты: [[0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 17  --- время: 234.65 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8095238208770752, 0.8095238208770752, 0.8095238208770752, 0.8095238208770752]  ----- Лучшие боты: [[0, 44, 1, 2, 0, 1, 1, 0, 43, 0, 1, 0, 3, 0, 0, 40, 1, 5, 1, 0, 1, 0, 17, 0, 5, 1, 0, 0, 1], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 18  --- время: 253.91 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8333333134651184, 0.8333333134651184, 0.8095238208770752, 0.8095238208770752]  ----- Лучшие боты: [[0, 44, 1, 2, 0, 1, 1, 0, 43, 0, 1, 0, 3, 0, 0, 40, 1, 5, 1, 0, 1, 0, 17, 0, 5, 1, 0, 0, 1], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 19  --- время: 225.73 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8571428656578064, 0.8333333134651184, 0.8333333134651184, 0.8095238208770752]  ----- Лучшие боты: [[0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 44, 1, 2, 0, 1, 1, 0, 43, 0, 1, 0, 3, 0, 0, 40, 1, 5, 1, 0, 1, 0, 17, 0, 5, 1, 0, 0, 1], [0, 44, 1, 2, 0, 1, 1, 0, 43, 0, 1, 0, 3, 0, 0, 40, 1, 5, 1, 0, 1, 0, 17, 0, 5, 1, 0, 0, 1], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 20  --- время: 235.65 \n",
            "Лучшие результаты: [0.8333333134651184, 0.8095238208770752, 0.8095238208770752, 0.8095238208770752, 0.8095238208770752]  ----- Лучшие боты: [[0, 44, 1, 2, 0, 1, 1, 0, 43, 0, 1, 0, 3, 0, 0, 40, 1, 5, 1, 0, 1, 0, 17, 0, 5, 1, 0, 0, 1], [0, 44, 1, 2, 0, 1, 1, 0, 43, 0, 1, 0, 3, 0, 0, 40, 1, 5, 1, 0, 1, 0, 17, 0, 5, 1, 0, 0, 1], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 21  --- время: 231.74 \n",
            "Лучшие результаты: [0.8333333134651184, 0.8333333134651184, 0.8333333134651184, 0.8095238208770752, 0.7857142686843872]  ----- Лучшие боты: [[0, 50, 0, 1, 1, 1, 1, 0, 42, 0, 0, 1, 3, 0, 1, 18, 0, 5, 0, 3, 0, 1, 13, 0, 3, 1, 1, 0, 2], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 22  --- время: 243.66 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8333333134651184, 0.8333333134651184, 0.8095238208770752, 0.8095238208770752]  ----- Лучшие боты: [[0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 23  --- время: 224.89 \n",
            "Лучшие результаты: [0.8333333134651184, 0.8095238208770752, 0.8095238208770752, 0.8095238208770752, 0.8095238208770752]  ----- Лучшие боты: [[0, 31, 0, 1, 0, 3, 1, 0, 26, 0, 5, 0, 2, 0, 1, 28, 1, 5, 1, 0, 0, 0, 16, 0, 5, 1, 0, 0, 0], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 24  --- время: 239.16 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8333333134651184, 0.8333333134651184, 0.8333333134651184, 0.8333333134651184]  ----- Лучшие боты: [[1, 39, 1, 1, 1, 3, 0, 0, 44, 1, 5, 0, 1, 0, 1, 50, 1, 0, 0, 3, 0, 0, 9, 0, 3, 0, 2, 1, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 25  --- время: 227.24 \n",
            "Лучшие результаты: [0.9047619104385376, 0.8095238208770752, 0.8095238208770752, 0.8095238208770752, 0.8095238208770752]  ----- Лучшие боты: [[0, 31, 0, 1, 0, 3, 1, 0, 26, 0, 5, 0, 2, 0, 1, 28, 1, 5, 1, 0, 0, 0, 16, 0, 5, 1, 0, 0, 0], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 26  --- время: 223.32 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8571428656578064, 0.8333333134651184, 0.8333333134651184, 0.8333333134651184]  ----- Лучшие боты: [[0, 11, 0, 0, 0, 0, 0, 0, 49, 0, 0, 0, 2, 0, 0, 32, 0, 3, 0, 2, 1, 1, 41, 1, 5, 1, 1, 1, 1], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 27  --- время: 236.31 \n",
            "Лучшие результаты: [0.8333333134651184, 0.8333333134651184, 0.8095238208770752, 0.8095238208770752, 0.8095238208770752]  ----- Лучшие боты: [[0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 28  --- время: 222.16 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8095238208770752, 0.8095238208770752, 0.8095238208770752, 0.7857142686843872]  ----- Лучшие боты: [[0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 29  --- время: 237.62 \n",
            "Лучшие результаты: [0.8333333134651184, 0.8095238208770752, 0.8095238208770752, 0.7857142686843872, 0.7857142686843872]  ----- Лучшие боты: [[0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 30  --- время: 233.53 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8333333134651184, 0.8333333134651184, 0.8333333134651184, 0.8095238208770752]  ----- Лучшие боты: [[0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 31  --- время: 228.43 \n",
            "Лучшие результаты: [0.8333333134651184, 0.8095238208770752, 0.8095238208770752, 0.8095238208770752, 0.7857142686843872]  ----- Лучшие боты: [[0, 22, 0, 2, 0, 0, 0, 1, 44, 1, 5, 0, 1, 0, 1, 29, 0, 5, 1, 3, 1, 0, 5, 0, 1, 0, 2, 1, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 32  --- время: 224.54 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8333333134651184, 0.8333333134651184, 0.8095238208770752, 0.8095238208770752]  ----- Лучшие боты: [[0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 22, 0, 2, 0, 0, 0, 1, 44, 1, 5, 0, 1, 0, 1, 29, 0, 5, 1, 3, 1, 0, 5, 0, 1, 0, 2, 1, 4], [0, 22, 0, 2, 0, 0, 0, 1, 44, 1, 5, 0, 1, 0, 1, 29, 0, 5, 1, 3, 1, 0, 5, 0, 1, 0, 2, 1, 4], [0, 22, 0, 2, 0, 0, 0, 1, 44, 1, 5, 0, 1, 0, 1, 29, 0, 5, 1, 3, 1, 0, 5, 0, 1, 0, 2, 1, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 33  --- время: 227.7 \n",
            "Лучшие результаты: [0.8333333134651184, 0.8333333134651184, 0.8095238208770752, 0.8095238208770752, 0.8095238208770752]  ----- Лучшие боты: [[0, 22, 0, 2, 0, 0, 0, 1, 44, 1, 5, 0, 1, 0, 1, 29, 0, 5, 1, 3, 1, 0, 5, 0, 1, 0, 2, 1, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 34  --- время: 228.25 \n",
            "Лучшие результаты: [0.8333333134651184, 0.8333333134651184, 0.8095238208770752, 0.8095238208770752, 0.8095238208770752]  ----- Лучшие боты: [[0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 22, 0, 2, 0, 0, 0, 1, 44, 1, 5, 0, 1, 0, 1, 29, 0, 5, 1, 3, 1, 0, 5, 0, 1, 0, 2, 1, 4], [0, 22, 0, 2, 0, 0, 0, 1, 44, 1, 5, 0, 1, 0, 1, 29, 0, 5, 1, 3, 1, 0, 5, 0, 1, 0, 2, 1, 4], [0, 22, 0, 2, 0, 0, 0, 1, 44, 1, 5, 0, 1, 0, 1, 29, 0, 5, 1, 3, 1, 0, 5, 0, 1, 0, 2, 1, 4]]\n",
            "\n",
            "Эпоха 35  --- время: 222.12 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8095238208770752, 0.8095238208770752, 0.7857142686843872, 0.7857142686843872]  ----- Лучшие боты: [[0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 36  --- время: 221.58 \n",
            "Лучшие результаты: [0.8333333134651184, 0.8333333134651184, 0.8333333134651184, 0.8095238208770752, 0.8095238208770752]  ----- Лучшие боты: [[0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 37  --- время: 244.23 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8333333134651184, 0.8333333134651184, 0.8333333134651184, 0.8333333134651184]  ----- Лучшие боты: [[0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 38  --- время: 232.1 \n",
            "Лучшие результаты: [0.8333333134651184, 0.8095238208770752, 0.8095238208770752, 0.8095238208770752, 0.8095238208770752]  ----- Лучшие боты: [[1, 46, 1, 4, 1, 3, 1, 1, 45, 1, 0, 1, 3, 0, 1, 3, 0, 5, 1, 0, 0, 1, 4, 0, 0, 0, 0, 1, 0], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 39  --- время: 246.98 \n",
            "Лучшие результаты: [0.8333333134651184, 0.8333333134651184, 0.8333333134651184, 0.8095238208770752, 0.8095238208770752]  ----- Лучшие боты: [[0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 40  --- время: 247.37 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8333333134651184, 0.8333333134651184, 0.8095238208770752, 0.8095238208770752]  ----- Лучшие боты: [[1, 46, 1, 4, 1, 3, 1, 1, 45, 1, 0, 1, 3, 0, 1, 3, 0, 5, 1, 0, 0, 1, 4, 0, 0, 0, 0, 1, 0], [1, 46, 1, 4, 1, 3, 1, 1, 45, 1, 0, 1, 3, 0, 1, 3, 0, 5, 1, 0, 0, 1, 4, 0, 0, 0, 0, 1, 0], [1, 46, 1, 4, 1, 3, 1, 1, 45, 1, 0, 1, 3, 0, 1, 3, 0, 5, 1, 0, 0, 1, 4, 0, 0, 0, 0, 1, 0], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 41  --- время: 249.06 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8571428656578064, 0.8095238208770752, 0.8095238208770752, 0.8095238208770752]  ----- Лучшие боты: [[0, 17, 0, 5, 0, 1, 1, 1, 37, 1, 2, 0, 2, 0, 1, 42, 1, 5, 1, 2, 1, 1, 14, 1, 1, 1, 0, 0, 2], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 42  --- время: 232.66 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8571428656578064, 0.8333333134651184, 0.8095238208770752, 0.7857142686843872]  ----- Лучшие боты: [[0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 17, 0, 5, 0, 1, 1, 1, 37, 1, 2, 0, 2, 0, 1, 42, 1, 5, 1, 2, 1, 1, 14, 1, 1, 1, 0, 0, 2], [0, 17, 0, 5, 0, 1, 1, 1, 37, 1, 2, 0, 2, 0, 1, 42, 1, 5, 1, 2, 1, 1, 14, 1, 1, 1, 0, 0, 2], [0, 17, 0, 5, 0, 1, 1, 1, 37, 1, 2, 0, 2, 0, 1, 42, 1, 5, 1, 2, 1, 1, 14, 1, 1, 1, 0, 0, 2]]\n",
            "\n",
            "Эпоха 43  --- время: 247.45 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8333333134651184, 0.8333333134651184, 0.8095238208770752, 0.8095238208770752]  ----- Лучшие боты: [[0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 17, 0, 5, 0, 1, 1, 1, 37, 1, 2, 0, 2, 0, 1, 42, 1, 5, 1, 2, 1, 1, 14, 1, 1, 1, 0, 0, 2], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 44  --- время: 252.34 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8333333134651184, 0.8333333134651184, 0.8333333134651184, 0.8095238208770752]  ----- Лучшие боты: [[0, 17, 0, 5, 0, 1, 1, 1, 37, 1, 2, 0, 2, 0, 1, 42, 1, 5, 1, 2, 1, 1, 14, 1, 1, 1, 0, 0, 2], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 45  --- время: 243.05 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8333333134651184, 0.8095238208770752, 0.8095238208770752, 0.8095238208770752]  ----- Лучшие боты: [[0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 46  --- время: 259.01 \n",
            "Лучшие результаты: [0.8333333134651184, 0.8333333134651184, 0.8095238208770752, 0.8095238208770752, 0.8095238208770752]  ----- Лучшие боты: [[0, 17, 0, 5, 0, 1, 1, 1, 37, 1, 2, 0, 2, 0, 1, 42, 1, 5, 1, 2, 1, 1, 14, 1, 1, 1, 0, 0, 2], [0, 17, 0, 5, 0, 1, 1, 1, 37, 1, 2, 0, 2, 0, 1, 42, 1, 5, 1, 2, 1, 1, 14, 1, 1, 1, 0, 0, 2], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 47  --- время: 229.37 \n",
            "Лучшие результаты: [0.8095238208770752, 0.8095238208770752, 0.8095238208770752, 0.8095238208770752, 0.7857142686843872]  ----- Лучшие боты: [[0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 17, 0, 5, 0, 1, 1, 1, 37, 1, 2, 0, 2, 0, 1, 42, 1, 5, 1, 2, 1, 1, 14, 1, 1, 1, 0, 0, 2], [0, 17, 0, 5, 0, 1, 1, 1, 37, 1, 2, 0, 2, 0, 1, 42, 1, 5, 1, 2, 1, 1, 14, 1, 1, 1, 0, 0, 2], [0, 17, 0, 5, 0, 1, 1, 1, 37, 1, 2, 0, 2, 0, 1, 42, 1, 5, 1, 2, 1, 1, 14, 1, 1, 1, 0, 0, 2]]\n",
            "\n",
            "Эпоха 48  --- время: 248.5 \n",
            "Лучшие результаты: [0.8333333134651184, 0.8095238208770752, 0.8095238208770752, 0.7857142686843872, 0.7857142686843872]  ----- Лучшие боты: [[0, 17, 0, 5, 0, 1, 1, 1, 37, 1, 2, 0, 2, 0, 1, 42, 1, 5, 1, 2, 1, 1, 14, 1, 1, 1, 0, 0, 2], [0, 17, 0, 5, 0, 1, 1, 1, 37, 1, 2, 0, 2, 0, 1, 42, 1, 5, 1, 2, 1, 1, 14, 1, 1, 1, 0, 0, 2], [0, 17, 0, 5, 0, 1, 1, 1, 37, 1, 2, 0, 2, 0, 1, 42, 1, 5, 1, 2, 1, 1, 14, 1, 1, 1, 0, 0, 2], [0, 17, 0, 5, 0, 1, 1, 1, 37, 1, 2, 0, 2, 0, 1, 42, 1, 5, 1, 2, 1, 1, 14, 1, 1, 1, 0, 0, 2], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n",
            "Эпоха 49  --- время: 241.61 \n",
            "Лучшие результаты: [0.8095238208770752, 0.8095238208770752, 0.8095238208770752, 0.8095238208770752, 0.8095238208770752]  ----- Лучшие боты: [[0, 17, 0, 5, 0, 1, 1, 1, 37, 1, 2, 0, 2, 0, 1, 42, 1, 5, 1, 2, 1, 1, 14, 1, 1, 1, 0, 0, 2], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4], [0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "popul = []\n",
        "#val = []\n",
        "\n",
        "# Создаем случайных ботов\n",
        "popul = [createRandomNet() for _ in range(n)]\n",
        "\n",
        "for ep in range(epochs):\n",
        "  val = []\n",
        "  curr_time = time.time()\n",
        "  #print(f\"Эпоха {ep}:\")\n",
        "  \n",
        "  for i in range(n):\n",
        "    bot = popul[i]\n",
        "    f = evaluateNet(bot)\n",
        "    #print(f\"Бот: {i} готов\")\n",
        "    val.append(f)\n",
        "\n",
        "  sval = sorted(val, reverse=True)\n",
        "\n",
        "  end_time = time.time() - curr_time\n",
        "  print(f\"Эпоха {ep}  --- время: {round(end_time, 2)} \")\n",
        "  print(f'Лучшие результаты: {sval[:5]}  ----- Лучшие боты: {popul[:5]}')\n",
        "  print()\n",
        "\n",
        "  newpopul = []\n",
        "  for i in range(nsurv):\n",
        "    index = val.index(sval[i])\n",
        "    newpopul.append(popul[index])\n",
        "  \n",
        "  for i in range(nnew):\n",
        "    botp1, botp2 = getParents(newpopul, nsurv)\n",
        "    newbot = []\n",
        "    net4Mut = createRandomNet()\n",
        "\n",
        "    for j in range(l):\n",
        "      x = crossPointFrom2Parents(botp1, botp2, j)\n",
        "      if random.random() < mut:\n",
        "        x = net4Mut[j]\n",
        "      newbot.append(x)\n",
        "    newpopul.append(newbot)\n",
        "  \n",
        "  popul = newpopul"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MCJt8wuLULR"
      },
      "source": [
        "## Проверка результатов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtBxRraTTMyT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3978982-8e4d-4d6f-ccd2-f7f7a5a478ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]\n",
            "[0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]\n",
            "[0, 26, 1, 2, 1, 0, 0, 0, 37, 1, 3, 1, 2, 0, 1, 37, 0, 0, 0, 3, 1, 1, 28, 1, 2, 0, 0, 0, 4]\n"
          ]
        }
      ],
      "source": [
        "# Вывод трех лучших ботов\n",
        "for i in range(3):\n",
        "  print(popul[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKAZTPyPTVbJ"
      },
      "source": [
        "## Обучение лучшей модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANB-dqABTYKK"
      },
      "outputs": [],
      "source": [
        "model = createConvNet(popul[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJE8gPEfTmHL"
      },
      "source": [
        "### Архитектура сети"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLD3obDKToJ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a867b264-3beb-4d3a-e72c-2b3029d874be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2500\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8664 (Dense)          (None, 676)               41236     \n",
            "                                                                 \n",
            " dropout_2999 (Dropout)      (None, 676)               0         \n",
            "                                                                 \n",
            " batch_normalization_4098 (B  (None, 676)              2704      \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " dense_8665 (Dense)          (None, 784)               530768    \n",
            "                                                                 \n",
            " dense_8666 (Dense)          (None, 1)                 785       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 575,493\n",
            "Trainable params: 574,141\n",
            "Non-trainable params: 1,352\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNQtWHO7TroY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "b43cfbdd-1ec0-4ab6-a5c8-a49c7b4a1a42"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "plot_model(model, show_shapes=True, dpi = 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_RRW3o1gjLL"
      },
      "source": [
        "## Обучим лучшую архитектуру"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HihLxGwAgnwA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70fce4b0-98a6-4c98-af07-d1c9547a47d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "6/6 [==============================] - 1s 45ms/step - loss: 0.7675 - accuracy: 0.5361 - val_loss: 0.6674 - val_accuracy: 0.6429\n",
            "Epoch 2/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6191 - accuracy: 0.6566 - val_loss: 0.6522 - val_accuracy: 0.6429\n",
            "Epoch 3/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4921 - accuracy: 0.7530 - val_loss: 0.6381 - val_accuracy: 0.6190\n",
            "Epoch 4/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5226 - accuracy: 0.7410 - val_loss: 0.6261 - val_accuracy: 0.6190\n",
            "Epoch 5/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4907 - accuracy: 0.7590 - val_loss: 0.6222 - val_accuracy: 0.6190\n",
            "Epoch 6/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4959 - accuracy: 0.7711 - val_loss: 0.6248 - val_accuracy: 0.5952\n",
            "Epoch 7/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4533 - accuracy: 0.7831 - val_loss: 0.6237 - val_accuracy: 0.6190\n",
            "Epoch 8/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4396 - accuracy: 0.7831 - val_loss: 0.6199 - val_accuracy: 0.6190\n",
            "Epoch 9/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4798 - accuracy: 0.7590 - val_loss: 0.6120 - val_accuracy: 0.6190\n",
            "Epoch 10/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4106 - accuracy: 0.8072 - val_loss: 0.6057 - val_accuracy: 0.5952\n",
            "Epoch 11/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3970 - accuracy: 0.7892 - val_loss: 0.5996 - val_accuracy: 0.6190\n",
            "Epoch 12/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4205 - accuracy: 0.8193 - val_loss: 0.5941 - val_accuracy: 0.6190\n",
            "Epoch 13/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3842 - accuracy: 0.8012 - val_loss: 0.5920 - val_accuracy: 0.6190\n",
            "Epoch 14/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3929 - accuracy: 0.8554 - val_loss: 0.5919 - val_accuracy: 0.6190\n",
            "Epoch 15/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4329 - accuracy: 0.7771 - val_loss: 0.5944 - val_accuracy: 0.6190\n",
            "Epoch 16/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4161 - accuracy: 0.7831 - val_loss: 0.5958 - val_accuracy: 0.6190\n",
            "Epoch 17/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3432 - accuracy: 0.8434 - val_loss: 0.5915 - val_accuracy: 0.6429\n",
            "Epoch 18/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3609 - accuracy: 0.8193 - val_loss: 0.5843 - val_accuracy: 0.6667\n",
            "Epoch 19/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3730 - accuracy: 0.8193 - val_loss: 0.5764 - val_accuracy: 0.6667\n",
            "Epoch 20/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3878 - accuracy: 0.8253 - val_loss: 0.5721 - val_accuracy: 0.6667\n",
            "Epoch 21/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3899 - accuracy: 0.8193 - val_loss: 0.5739 - val_accuracy: 0.6667\n",
            "Epoch 22/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3764 - accuracy: 0.8313 - val_loss: 0.5774 - val_accuracy: 0.6429\n",
            "Epoch 23/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3650 - accuracy: 0.8313 - val_loss: 0.5763 - val_accuracy: 0.6429\n",
            "Epoch 24/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3371 - accuracy: 0.8494 - val_loss: 0.5638 - val_accuracy: 0.6429\n",
            "Epoch 25/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3343 - accuracy: 0.8494 - val_loss: 0.5528 - val_accuracy: 0.6667\n",
            "Epoch 26/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3254 - accuracy: 0.8614 - val_loss: 0.5462 - val_accuracy: 0.7143\n",
            "Epoch 27/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3065 - accuracy: 0.8554 - val_loss: 0.5410 - val_accuracy: 0.7381\n",
            "Epoch 28/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3185 - accuracy: 0.8373 - val_loss: 0.5407 - val_accuracy: 0.7381\n",
            "Epoch 29/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3650 - accuracy: 0.8434 - val_loss: 0.5424 - val_accuracy: 0.7381\n",
            "Epoch 30/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2944 - accuracy: 0.8735 - val_loss: 0.5332 - val_accuracy: 0.7619\n",
            "Epoch 31/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3260 - accuracy: 0.8855 - val_loss: 0.5200 - val_accuracy: 0.7857\n",
            "Epoch 32/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3343 - accuracy: 0.8253 - val_loss: 0.5134 - val_accuracy: 0.7857\n",
            "Epoch 33/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3583 - accuracy: 0.8494 - val_loss: 0.5121 - val_accuracy: 0.7619\n",
            "Epoch 34/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3300 - accuracy: 0.8193 - val_loss: 0.5128 - val_accuracy: 0.7619\n",
            "Epoch 35/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2859 - accuracy: 0.8735 - val_loss: 0.5094 - val_accuracy: 0.7619\n",
            "Epoch 36/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3011 - accuracy: 0.8735 - val_loss: 0.5038 - val_accuracy: 0.7857\n",
            "Epoch 37/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3257 - accuracy: 0.8554 - val_loss: 0.4970 - val_accuracy: 0.7857\n",
            "Epoch 38/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2682 - accuracy: 0.9157 - val_loss: 0.4941 - val_accuracy: 0.7619\n",
            "Epoch 39/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3272 - accuracy: 0.8494 - val_loss: 0.4942 - val_accuracy: 0.7381\n",
            "Epoch 40/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2794 - accuracy: 0.8855 - val_loss: 0.4870 - val_accuracy: 0.7619\n",
            "Epoch 41/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2715 - accuracy: 0.8795 - val_loss: 0.4786 - val_accuracy: 0.8333\n",
            "Epoch 42/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2744 - accuracy: 0.8795 - val_loss: 0.4767 - val_accuracy: 0.7857\n",
            "Epoch 43/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2495 - accuracy: 0.8735 - val_loss: 0.4731 - val_accuracy: 0.8095\n",
            "Epoch 44/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2850 - accuracy: 0.8554 - val_loss: 0.4634 - val_accuracy: 0.8333\n",
            "Epoch 45/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3115 - accuracy: 0.8735 - val_loss: 0.4583 - val_accuracy: 0.8333\n",
            "Epoch 46/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2794 - accuracy: 0.8795 - val_loss: 0.4546 - val_accuracy: 0.8333\n",
            "Epoch 47/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2650 - accuracy: 0.8976 - val_loss: 0.4467 - val_accuracy: 0.7857\n",
            "Epoch 48/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2674 - accuracy: 0.8855 - val_loss: 0.4483 - val_accuracy: 0.7857\n",
            "Epoch 49/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2549 - accuracy: 0.8795 - val_loss: 0.4503 - val_accuracy: 0.7857\n",
            "Epoch 50/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2437 - accuracy: 0.9337 - val_loss: 0.4523 - val_accuracy: 0.7857\n",
            "Epoch 51/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2768 - accuracy: 0.8855 - val_loss: 0.4539 - val_accuracy: 0.7619\n",
            "Epoch 52/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2707 - accuracy: 0.8976 - val_loss: 0.4521 - val_accuracy: 0.7619\n",
            "Epoch 53/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2574 - accuracy: 0.8795 - val_loss: 0.4211 - val_accuracy: 0.8333\n",
            "Epoch 54/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2678 - accuracy: 0.9036 - val_loss: 0.4112 - val_accuracy: 0.8333\n",
            "Epoch 55/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2373 - accuracy: 0.9036 - val_loss: 0.4088 - val_accuracy: 0.8333\n",
            "Epoch 56/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2628 - accuracy: 0.8916 - val_loss: 0.4077 - val_accuracy: 0.8095\n",
            "Epoch 57/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2724 - accuracy: 0.8855 - val_loss: 0.4204 - val_accuracy: 0.7857\n",
            "Epoch 58/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2470 - accuracy: 0.8976 - val_loss: 0.4190 - val_accuracy: 0.7857\n",
            "Epoch 59/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2335 - accuracy: 0.9036 - val_loss: 0.4062 - val_accuracy: 0.8095\n",
            "Epoch 60/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2407 - accuracy: 0.8916 - val_loss: 0.4024 - val_accuracy: 0.7857\n",
            "Epoch 61/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2414 - accuracy: 0.8916 - val_loss: 0.3979 - val_accuracy: 0.8095\n",
            "Epoch 62/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2088 - accuracy: 0.9217 - val_loss: 0.3944 - val_accuracy: 0.8095\n",
            "Epoch 63/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2480 - accuracy: 0.9036 - val_loss: 0.3873 - val_accuracy: 0.8095\n",
            "Epoch 64/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2281 - accuracy: 0.8855 - val_loss: 0.3938 - val_accuracy: 0.8095\n",
            "Epoch 65/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2886 - accuracy: 0.8675 - val_loss: 0.3961 - val_accuracy: 0.8095\n",
            "Epoch 66/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2290 - accuracy: 0.9036 - val_loss: 0.3696 - val_accuracy: 0.8333\n",
            "Epoch 67/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2077 - accuracy: 0.9157 - val_loss: 0.3601 - val_accuracy: 0.8333\n",
            "Epoch 68/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1982 - accuracy: 0.9337 - val_loss: 0.3654 - val_accuracy: 0.8095\n",
            "Epoch 69/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2053 - accuracy: 0.9217 - val_loss: 0.3851 - val_accuracy: 0.8333\n",
            "Epoch 70/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2244 - accuracy: 0.9217 - val_loss: 0.4133 - val_accuracy: 0.7857\n",
            "Epoch 71/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1747 - accuracy: 0.9458 - val_loss: 0.4206 - val_accuracy: 0.8095\n",
            "Epoch 72/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2182 - accuracy: 0.8976 - val_loss: 0.3942 - val_accuracy: 0.8333\n",
            "Epoch 73/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2014 - accuracy: 0.9217 - val_loss: 0.3752 - val_accuracy: 0.8095\n",
            "Epoch 74/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2178 - accuracy: 0.9217 - val_loss: 0.3785 - val_accuracy: 0.8095\n",
            "Epoch 75/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2023 - accuracy: 0.9157 - val_loss: 0.3791 - val_accuracy: 0.8095\n",
            "Epoch 76/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2100 - accuracy: 0.8976 - val_loss: 0.3820 - val_accuracy: 0.8333\n",
            "Epoch 77/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1989 - accuracy: 0.9217 - val_loss: 0.3753 - val_accuracy: 0.8333\n",
            "Epoch 78/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1869 - accuracy: 0.9277 - val_loss: 0.3581 - val_accuracy: 0.8333\n",
            "Epoch 79/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1934 - accuracy: 0.9096 - val_loss: 0.3561 - val_accuracy: 0.8333\n",
            "Epoch 80/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1966 - accuracy: 0.9217 - val_loss: 0.3514 - val_accuracy: 0.8333\n",
            "Epoch 81/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1730 - accuracy: 0.9337 - val_loss: 0.3652 - val_accuracy: 0.8095\n",
            "Epoch 82/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2027 - accuracy: 0.9157 - val_loss: 0.3688 - val_accuracy: 0.7857\n",
            "Epoch 83/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1813 - accuracy: 0.9217 - val_loss: 0.3707 - val_accuracy: 0.7857\n",
            "Epoch 84/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1979 - accuracy: 0.9217 - val_loss: 0.3474 - val_accuracy: 0.8333\n",
            "Epoch 85/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1756 - accuracy: 0.9277 - val_loss: 0.3270 - val_accuracy: 0.8333\n",
            "Epoch 86/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1614 - accuracy: 0.9518 - val_loss: 0.3256 - val_accuracy: 0.8333\n",
            "Epoch 87/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1935 - accuracy: 0.9398 - val_loss: 0.3355 - val_accuracy: 0.8333\n",
            "Epoch 88/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1866 - accuracy: 0.9578 - val_loss: 0.3544 - val_accuracy: 0.8333\n",
            "Epoch 89/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1613 - accuracy: 0.9518 - val_loss: 0.3600 - val_accuracy: 0.8571\n",
            "Epoch 90/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1840 - accuracy: 0.9337 - val_loss: 0.3446 - val_accuracy: 0.8333\n",
            "Epoch 91/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1739 - accuracy: 0.9458 - val_loss: 0.3311 - val_accuracy: 0.8333\n",
            "Epoch 92/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1847 - accuracy: 0.9337 - val_loss: 0.3280 - val_accuracy: 0.8095\n",
            "Epoch 93/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1642 - accuracy: 0.9518 - val_loss: 0.3298 - val_accuracy: 0.8333\n",
            "Epoch 94/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1759 - accuracy: 0.9277 - val_loss: 0.3543 - val_accuracy: 0.8095\n",
            "Epoch 95/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1723 - accuracy: 0.9458 - val_loss: 0.3604 - val_accuracy: 0.8095\n",
            "Epoch 96/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1353 - accuracy: 0.9639 - val_loss: 0.3463 - val_accuracy: 0.8571\n",
            "Epoch 97/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2013 - accuracy: 0.9157 - val_loss: 0.3214 - val_accuracy: 0.8571\n",
            "Epoch 98/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1574 - accuracy: 0.9458 - val_loss: 0.3124 - val_accuracy: 0.8571\n",
            "Epoch 99/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1583 - accuracy: 0.9458 - val_loss: 0.3170 - val_accuracy: 0.8571\n",
            "Epoch 100/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1318 - accuracy: 0.9699 - val_loss: 0.3486 - val_accuracy: 0.8333\n",
            "Epoch 101/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1625 - accuracy: 0.9337 - val_loss: 0.3597 - val_accuracy: 0.8571\n",
            "Epoch 102/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1453 - accuracy: 0.9578 - val_loss: 0.3566 - val_accuracy: 0.8571\n",
            "Epoch 103/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1804 - accuracy: 0.9337 - val_loss: 0.3472 - val_accuracy: 0.8571\n",
            "Epoch 104/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1019 - accuracy: 0.9819 - val_loss: 0.3418 - val_accuracy: 0.8571\n",
            "Epoch 105/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1360 - accuracy: 0.9518 - val_loss: 0.3210 - val_accuracy: 0.8571\n",
            "Epoch 106/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1471 - accuracy: 0.9518 - val_loss: 0.3362 - val_accuracy: 0.8333\n",
            "Epoch 107/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1297 - accuracy: 0.9759 - val_loss: 0.3390 - val_accuracy: 0.8571\n",
            "Epoch 108/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1455 - accuracy: 0.9458 - val_loss: 0.3382 - val_accuracy: 0.8571\n",
            "Epoch 109/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1409 - accuracy: 0.9518 - val_loss: 0.3420 - val_accuracy: 0.8333\n",
            "Epoch 110/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1472 - accuracy: 0.9518 - val_loss: 0.3286 - val_accuracy: 0.8333\n",
            "Epoch 111/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1065 - accuracy: 0.9819 - val_loss: 0.3264 - val_accuracy: 0.8333\n",
            "Epoch 112/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1333 - accuracy: 0.9699 - val_loss: 0.3237 - val_accuracy: 0.8333\n",
            "Epoch 113/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1421 - accuracy: 0.9398 - val_loss: 0.3212 - val_accuracy: 0.8333\n",
            "Epoch 114/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1417 - accuracy: 0.9518 - val_loss: 0.3148 - val_accuracy: 0.8333\n",
            "Epoch 115/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1484 - accuracy: 0.9458 - val_loss: 0.3119 - val_accuracy: 0.8333\n",
            "Epoch 116/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1497 - accuracy: 0.9518 - val_loss: 0.3009 - val_accuracy: 0.8571\n",
            "Epoch 117/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1230 - accuracy: 0.9639 - val_loss: 0.2980 - val_accuracy: 0.9048\n",
            "Epoch 118/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1271 - accuracy: 0.9699 - val_loss: 0.3003 - val_accuracy: 0.8571\n",
            "Epoch 119/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1181 - accuracy: 0.9639 - val_loss: 0.3015 - val_accuracy: 0.8810\n",
            "Epoch 120/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1187 - accuracy: 0.9639 - val_loss: 0.3084 - val_accuracy: 0.8333\n",
            "Epoch 121/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1443 - accuracy: 0.9518 - val_loss: 0.3257 - val_accuracy: 0.8333\n",
            "Epoch 122/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1365 - accuracy: 0.9458 - val_loss: 0.3489 - val_accuracy: 0.8095\n",
            "Epoch 123/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1056 - accuracy: 0.9639 - val_loss: 0.3183 - val_accuracy: 0.8810\n",
            "Epoch 124/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1352 - accuracy: 0.9518 - val_loss: 0.3003 - val_accuracy: 0.8810\n",
            "Epoch 125/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1224 - accuracy: 0.9578 - val_loss: 0.2990 - val_accuracy: 0.8571\n",
            "Epoch 126/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1403 - accuracy: 0.9458 - val_loss: 0.3174 - val_accuracy: 0.8810\n",
            "Epoch 127/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1143 - accuracy: 0.9639 - val_loss: 0.3624 - val_accuracy: 0.8571\n",
            "Epoch 128/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1170 - accuracy: 0.9699 - val_loss: 0.3893 - val_accuracy: 0.8333\n",
            "Epoch 129/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1226 - accuracy: 0.9759 - val_loss: 0.3813 - val_accuracy: 0.8333\n",
            "Epoch 130/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1023 - accuracy: 0.9819 - val_loss: 0.3369 - val_accuracy: 0.8333\n",
            "Epoch 131/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1192 - accuracy: 0.9458 - val_loss: 0.3119 - val_accuracy: 0.8571\n",
            "Epoch 132/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0902 - accuracy: 0.9699 - val_loss: 0.2910 - val_accuracy: 0.9048\n",
            "Epoch 133/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1184 - accuracy: 0.9699 - val_loss: 0.2934 - val_accuracy: 0.8810\n",
            "Epoch 134/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1247 - accuracy: 0.9699 - val_loss: 0.3137 - val_accuracy: 0.8810\n",
            "Epoch 135/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1097 - accuracy: 0.9759 - val_loss: 0.2946 - val_accuracy: 0.9286\n",
            "Epoch 136/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1024 - accuracy: 0.9699 - val_loss: 0.2833 - val_accuracy: 0.9524\n",
            "Epoch 137/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0953 - accuracy: 0.9759 - val_loss: 0.3054 - val_accuracy: 0.9048\n",
            "Epoch 138/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0954 - accuracy: 0.9819 - val_loss: 0.3152 - val_accuracy: 0.8810\n",
            "Epoch 139/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1182 - accuracy: 0.9699 - val_loss: 0.3196 - val_accuracy: 0.8571\n",
            "Epoch 140/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1213 - accuracy: 0.9639 - val_loss: 0.3397 - val_accuracy: 0.8571\n",
            "Epoch 141/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0927 - accuracy: 0.9759 - val_loss: 0.3277 - val_accuracy: 0.9048\n",
            "Epoch 142/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1317 - accuracy: 0.9398 - val_loss: 0.3040 - val_accuracy: 0.9286\n",
            "Epoch 143/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0931 - accuracy: 0.9759 - val_loss: 0.2892 - val_accuracy: 0.8810\n",
            "Epoch 144/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1042 - accuracy: 0.9759 - val_loss: 0.3126 - val_accuracy: 0.8810\n",
            "Epoch 145/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1136 - accuracy: 0.9699 - val_loss: 0.3542 - val_accuracy: 0.8571\n",
            "Epoch 146/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0873 - accuracy: 0.9880 - val_loss: 0.3643 - val_accuracy: 0.8571\n",
            "Epoch 147/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1139 - accuracy: 0.9578 - val_loss: 0.3635 - val_accuracy: 0.8571\n",
            "Epoch 148/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0994 - accuracy: 0.9699 - val_loss: 0.3560 - val_accuracy: 0.8333\n",
            "Epoch 149/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1093 - accuracy: 0.9639 - val_loss: 0.3626 - val_accuracy: 0.8333\n",
            "Epoch 150/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0783 - accuracy: 0.9819 - val_loss: 0.3840 - val_accuracy: 0.8333\n",
            "Epoch 151/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0884 - accuracy: 0.9699 - val_loss: 0.3996 - val_accuracy: 0.8333\n",
            "Epoch 152/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1245 - accuracy: 0.9759 - val_loss: 0.4142 - val_accuracy: 0.8333\n",
            "Epoch 153/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0933 - accuracy: 0.9699 - val_loss: 0.4101 - val_accuracy: 0.8333\n",
            "Epoch 154/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0824 - accuracy: 0.9819 - val_loss: 0.3777 - val_accuracy: 0.8571\n",
            "Epoch 155/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0931 - accuracy: 0.9819 - val_loss: 0.3278 - val_accuracy: 0.8333\n",
            "Epoch 156/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0897 - accuracy: 0.9759 - val_loss: 0.3102 - val_accuracy: 0.8333\n",
            "Epoch 157/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1161 - accuracy: 0.9759 - val_loss: 0.3141 - val_accuracy: 0.9048\n",
            "Epoch 158/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0985 - accuracy: 0.9819 - val_loss: 0.3883 - val_accuracy: 0.8571\n",
            "Epoch 159/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1258 - accuracy: 0.9639 - val_loss: 0.4305 - val_accuracy: 0.8571\n",
            "Epoch 160/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0804 - accuracy: 0.9940 - val_loss: 0.4212 - val_accuracy: 0.8333\n",
            "Epoch 161/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0958 - accuracy: 0.9819 - val_loss: 0.3773 - val_accuracy: 0.8333\n",
            "Epoch 162/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1057 - accuracy: 0.9639 - val_loss: 0.3216 - val_accuracy: 0.8810\n",
            "Epoch 163/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0895 - accuracy: 0.9819 - val_loss: 0.3168 - val_accuracy: 0.8810\n",
            "Epoch 164/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0879 - accuracy: 0.9819 - val_loss: 0.3230 - val_accuracy: 0.9048\n",
            "Epoch 165/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0810 - accuracy: 0.9819 - val_loss: 0.3293 - val_accuracy: 0.8810\n",
            "Epoch 166/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0968 - accuracy: 0.9759 - val_loss: 0.3364 - val_accuracy: 0.8571\n",
            "Epoch 167/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0620 - accuracy: 0.9880 - val_loss: 0.3126 - val_accuracy: 0.8571\n",
            "Epoch 168/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1179 - accuracy: 0.9639 - val_loss: 0.3113 - val_accuracy: 0.8571\n",
            "Epoch 169/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0791 - accuracy: 0.9940 - val_loss: 0.3165 - val_accuracy: 0.8571\n",
            "Epoch 170/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0838 - accuracy: 0.9699 - val_loss: 0.3242 - val_accuracy: 0.8810\n",
            "Epoch 171/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0937 - accuracy: 0.9699 - val_loss: 0.3342 - val_accuracy: 0.8810\n",
            "Epoch 172/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0579 - accuracy: 0.9940 - val_loss: 0.3463 - val_accuracy: 0.8571\n",
            "Epoch 173/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0877 - accuracy: 0.9819 - val_loss: 0.3542 - val_accuracy: 0.8571\n",
            "Epoch 174/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0742 - accuracy: 0.9759 - val_loss: 0.4096 - val_accuracy: 0.8571\n",
            "Epoch 175/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0845 - accuracy: 0.9759 - val_loss: 0.4200 - val_accuracy: 0.8571\n",
            "Epoch 176/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0705 - accuracy: 0.9940 - val_loss: 0.4093 - val_accuracy: 0.8333\n",
            "Epoch 177/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0572 - accuracy: 0.9940 - val_loss: 0.3898 - val_accuracy: 0.8333\n",
            "Epoch 178/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0699 - accuracy: 0.9880 - val_loss: 0.3701 - val_accuracy: 0.8333\n",
            "Epoch 179/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0975 - accuracy: 0.9699 - val_loss: 0.3628 - val_accuracy: 0.8333\n",
            "Epoch 180/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0959 - accuracy: 0.9699 - val_loss: 0.3589 - val_accuracy: 0.8571\n",
            "Epoch 181/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0504 - accuracy: 0.9940 - val_loss: 0.3674 - val_accuracy: 0.8571\n",
            "Epoch 182/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0798 - accuracy: 0.9699 - val_loss: 0.3423 - val_accuracy: 0.8333\n",
            "Epoch 183/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0981 - accuracy: 0.9699 - val_loss: 0.3671 - val_accuracy: 0.8333\n",
            "Epoch 184/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1171 - accuracy: 0.9578 - val_loss: 0.3943 - val_accuracy: 0.8333\n",
            "Epoch 185/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0717 - accuracy: 0.9819 - val_loss: 0.4264 - val_accuracy: 0.8333\n",
            "Epoch 186/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0536 - accuracy: 0.9880 - val_loss: 0.4609 - val_accuracy: 0.8333\n",
            "Epoch 187/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0869 - accuracy: 0.9639 - val_loss: 0.4564 - val_accuracy: 0.8333\n",
            "Epoch 188/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0902 - accuracy: 0.9639 - val_loss: 0.4067 - val_accuracy: 0.8333\n",
            "Epoch 189/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0706 - accuracy: 0.9880 - val_loss: 0.3750 - val_accuracy: 0.8333\n",
            "Epoch 190/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0827 - accuracy: 0.9759 - val_loss: 0.3627 - val_accuracy: 0.8333\n",
            "Epoch 191/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0757 - accuracy: 0.9639 - val_loss: 0.3624 - val_accuracy: 0.8571\n",
            "Epoch 192/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0745 - accuracy: 0.9819 - val_loss: 0.3810 - val_accuracy: 0.8333\n",
            "Epoch 193/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0631 - accuracy: 0.9880 - val_loss: 0.3783 - val_accuracy: 0.8571\n",
            "Epoch 194/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0970 - accuracy: 0.9759 - val_loss: 0.3742 - val_accuracy: 0.8571\n",
            "Epoch 195/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0614 - accuracy: 0.9880 - val_loss: 0.3458 - val_accuracy: 0.8810\n",
            "Epoch 196/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0859 - accuracy: 0.9819 - val_loss: 0.3032 - val_accuracy: 0.9286\n",
            "Epoch 197/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0859 - accuracy: 0.9819 - val_loss: 0.2757 - val_accuracy: 0.9286\n",
            "Epoch 198/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1082 - accuracy: 0.9699 - val_loss: 0.2772 - val_accuracy: 0.9286\n",
            "Epoch 199/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0617 - accuracy: 0.9940 - val_loss: 0.2812 - val_accuracy: 0.9048\n",
            "Epoch 200/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1179 - accuracy: 0.9578 - val_loss: 0.2982 - val_accuracy: 0.9286\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f62200caa90>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=1e-4), metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=200, validation_data=(x_test ,y_test), verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxDU6SAZjmGe"
      },
      "source": [
        "# Второй вариант\n",
        "**Более простая архитектура сети. Меньше гиперпараметров.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ya2b1k5QGK4K"
      },
      "outputs": [],
      "source": [
        "def createRandomNet():\n",
        "  net = []\n",
        "  net.append(random.randint(0,1))  # 0- Нормализация 0,1\n",
        "  net.append(random.randint(2,10)) # 1- Число нейронов(которое будут изменяться)\n",
        "  net.append(random.randint(0,1))  # 2- Способ изменения нейронов в Dense слое\n",
        "  net.append(random.randint(0,5))  # 3- Функция активации первого слоя - ['linear','relu','elu','tanh','softmax','sigmoid']\n",
        "  net.append(random.randint(0,1))  # 4- Будет ли Dropout 0,1\n",
        "  net.append(random.randint(0,3))  # 5- Установка параметра rate в слое Dropout (0.25, 0.3, 0.35, 0.4)\n",
        "\n",
        "\n",
        "  net.append(random.randint(0,1))  # 6 - Будет ли добавлен второй блок\n",
        "  net.append(random.randint(0,1))  # 7-  Нормализация 0,1\n",
        "  net.append(random.randint(2,10)) # 8-  Число нейронов(которое будут изменяться)\n",
        "  net.append(random.randint(0,1))  # 9-  Способ изменения нейронов в Dense слое\n",
        "  net.append(random.randint(0,5))  # 10- Функция активации второго слоя - ['linear','relu','elu','tanh','softmax','sigmoid']\n",
        "  net.append(random.randint(0,1))  # 11- Будет ли Dropout 0,1\n",
        "  net.append(random.randint(0,3))  # 12- Установка параметра rate в слое Dropout (0.25, 0.3, 0.35, 0.4)\n",
        "\n",
        "  net.append(random.randint(0,1))  # 27- Нормализация 0,1(Перед выходным слоем)\n",
        "  net.append(random.randint(0,4))  # 28- Функция активации выходного слоя - ['linear','relu','elu','softmax','sigmoid']\n",
        "\n",
        "  return net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9F7FkFLKF1-b"
      },
      "outputs": [],
      "source": [
        "def createConvNet(net):\n",
        " \n",
        "  makeFirstNormalization = net[0]       # 0 - Нормализация в начале 0,1\n",
        "  firstDenseNeurons = net[1]            # 1-  Число нейронов(которое будут изменяться)\n",
        "  firstСhangeNeurons = net[2]           # 2-  Способ изменения нейронов в Dense слое(0-умножение на 10; 1-степень)\n",
        "  activation1 = net[3]                  # 3-  Функция активации первого слоя - ['linear','relu','elu','softmax','sigmoid','tanh']\n",
        "  makeDropOut1 = net[4]                 # 4 - Будет ли Dropout 0,1\n",
        "  firstDropout = net[5]                 # 5 - Установка параметра rate в слое Dropout (0.25, 0.3, 0.35, 0.4)\n",
        "\n",
        "  secondLaeyrsDense = net[6]            # 6 - Будет ли добавлен второй блок\n",
        "  makeSecondNormalization = net[7]      # 7 - Нормализация второго блока\n",
        "  secondDenseNeurons = net[8]           # 8-  Число нейронов(которое будут изменяться)\n",
        "  secondСhangeNeurons = net[9]          # 9-  Способ изменения нейронов в Dense слое\n",
        "  activation2 = net[10]                 # 10- Функция активации второго блока - ['linear','relu','elu','softmax','sigmoid','tanh']\n",
        "  makeDropOut2 = net[11]                # 11- Будет ли Dropout 0,1\n",
        "  secondDropout = net[12]               # 12- Установка параметра rate в слое Dropout (0.25, 0.3, 0.35, 0.4)\n",
        "\n",
        "  finalNormalization = net[13]          # 13- Нормализация перед выходным слоем\n",
        "  activation5 = net[14]                 # 14- Функция активации выходного слоя - ['linear','relu','elu','softmax','sigmoid'] - без tanh\n",
        "\n",
        "\n",
        "  activation_list = ['linear','relu','elu','softmax','sigmoid','tanh']\n",
        "  dropout_list = [0.25, 0.3, 0.35, 0.4]\n",
        "\n",
        "  shape = (60,)\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  if makeFirstNormalization:                                                              # Нормализация в начале \n",
        "    model.add(BatchNormalization(input_shape=(shape)))\n",
        "    if firstСhangeNeurons:\n",
        "      model.add(Dense(firstDenseNeurons**2, activation=activation_list[activation1]))    # Добавление Dense слоя\n",
        "    else:\n",
        "      model.add(Dense(firstDenseNeurons*10, activation=activation_list[activation1]))\n",
        "  \n",
        "  else:  # Или без нормализации\n",
        "    if firstСhangeNeurons:\n",
        "      model.add(Dense(firstDenseNeurons**2, activation=activation_list[activation1], input_shape=(shape)))\n",
        "    else:\n",
        "      model.add(Dense(firstDenseNeurons*10, activation=activation_list[activation1], input_shape=(shape)))\n",
        "  \n",
        "  if makeDropOut1:   # Будет ли Dropout\n",
        "    model.add(Dropout(dropout_list[firstDropout]))\n",
        "\n",
        "\n",
        "\n",
        "  if secondLaeyrsDense:   #  Будет ли второй блок\n",
        "\n",
        "    if makeSecondNormalization:\n",
        "      model.add(BatchNormalization())\n",
        "\n",
        "    if secondСhangeNeurons:\n",
        "      model.add(Dense(secondDenseNeurons**2, activation=activation_list[activation2]))\n",
        "    else:\n",
        "      model.add(Dense(secondDenseNeurons*10, activation=activation_list[activation2]))\n",
        "\n",
        "    if makeDropOut2:   # Будет ли Dropout\n",
        "      model.add(Dropout(dropout_list[secondDropout]))\n",
        "\n",
        "\n",
        "  if finalNormalization:   # Нормализация перед выходным слоем\n",
        "    model.add(BatchNormalization())\n",
        "  \n",
        "  model.add(Dense(1, activation=activation_list[activation2]))  #  Без tanh\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6PiMxIPI31l"
      },
      "outputs": [],
      "source": [
        "n = 50            # Общее число ботов\n",
        "nsurv = 10        # Кол-во выживших\n",
        "nnew = n - nsurv  # Кол-во новых\n",
        "l = 15            # Размер бота\n",
        "epochs = 50       # Количество эпох\n",
        "\n",
        "mut = 0.99        # Коэфициент мутаций"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezYwHE56I31o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d0601bd-5304-4eaa-c569-7211c0b39df6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 0  --- время: 204.62 \n",
            "Лучшие результаты: [0.8095238208770752, 0.7857142686843872, 0.761904776096344, 0.761904776096344, 0.738095223903656]  ----- Лучшие боты: [[0, 5, 1, 4, 1, 0, 0, 1, 3, 1, 4, 1, 1, 1, 2], [1, 4, 1, 4, 1, 1, 0, 1, 2, 0, 5, 0, 0, 1, 2], [0, 7, 1, 3, 0, 2, 1, 1, 2, 1, 4, 0, 1, 1, 1], [0, 2, 0, 0, 0, 1, 0, 0, 4, 0, 0, 1, 2, 0, 2], [0, 8, 0, 4, 1, 1, 1, 0, 4, 0, 1, 1, 0, 0, 0]]\n",
            "\n",
            "Эпоха 1  --- время: 206.77 \n",
            "Лучшие результаты: [0.8095238208770752, 0.738095223903656, 0.738095223903656, 0.738095223903656, 0.6904761791229248]  ----- Лучшие боты: [[1, 3, 0, 5, 0, 3, 0, 0, 6, 0, 4, 1, 1, 0, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 9, 1, 0, 0, 2, 0, 1, 6, 1, 4, 1, 0, 0, 0], [1, 9, 1, 0, 0, 2, 0, 1, 6, 1, 4, 1, 0, 0, 0], [1, 5, 0, 1, 0, 3, 1, 0, 8, 1, 1, 0, 3, 0, 1]]\n",
            "\n",
            "Эпоха 2  --- время: 213.04 \n",
            "Лучшие результаты: [0.761904776096344, 0.761904776096344, 0.738095223903656, 0.738095223903656, 0.738095223903656]  ----- Лучшие боты: [[1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 5, 0, 1, 0, 3, 1, 0, 8, 1, 1, 0, 3, 0, 1], [1, 5, 0, 1, 0, 3, 1, 0, 8, 1, 1, 0, 3, 0, 1], [1, 5, 0, 1, 0, 3, 1, 0, 8, 1, 1, 0, 3, 0, 1], [1, 9, 1, 0, 0, 2, 0, 1, 6, 1, 4, 1, 0, 0, 0]]\n",
            "\n",
            "Эпоха 3  --- время: 222.35 \n",
            "Лучшие результаты: [0.7857142686843872, 0.738095223903656, 0.738095223903656, 0.738095223903656, 0.7142857313156128]  ----- Лучшие боты: [[1, 3, 0, 5, 0, 3, 0, 0, 6, 0, 4, 1, 1, 0, 1], [1, 3, 0, 5, 0, 3, 0, 0, 6, 0, 4, 1, 1, 0, 1], [0, 7, 0, 0, 0, 1, 1, 1, 2, 0, 2, 0, 3, 0, 3], [0, 7, 0, 0, 0, 1, 1, 1, 2, 0, 2, 0, 3, 0, 3], [0, 7, 0, 0, 0, 1, 1, 1, 2, 0, 2, 0, 3, 0, 3]]\n",
            "\n",
            "Эпоха 4  --- время: 202.66 \n",
            "Лучшие результаты: [0.8095238208770752, 0.761904776096344, 0.761904776096344, 0.761904776096344, 0.738095223903656]  ----- Лучшие боты: [[1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 9, 1, 0, 0, 2, 0, 1, 6, 1, 4, 1, 0, 0, 0], [1, 9, 1, 0, 0, 2, 0, 1, 6, 1, 4, 1, 0, 0, 0], [1, 9, 1, 0, 0, 2, 0, 1, 6, 1, 4, 1, 0, 0, 0], [1, 9, 1, 0, 0, 2, 0, 1, 6, 1, 4, 1, 0, 0, 0]]\n",
            "\n",
            "Эпоха 5  --- время: 217.45 \n",
            "Лучшие результаты: [0.761904776096344, 0.761904776096344, 0.761904776096344, 0.761904776096344, 0.738095223903656]  ----- Лучшие боты: [[1, 9, 1, 0, 0, 2, 0, 1, 6, 1, 4, 1, 0, 0, 0], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 9, 1, 0, 0, 2, 0, 1, 6, 1, 4, 1, 0, 0, 0]]\n",
            "\n",
            "Эпоха 6  --- время: 222.95 \n",
            "Лучшие результаты: [0.8095238208770752, 0.8095238208770752, 0.7857142686843872, 0.761904776096344, 0.738095223903656]  ----- Лучшие боты: [[1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 9, 1, 0, 0, 2, 0, 1, 6, 1, 4, 1, 0, 0, 0]]\n",
            "\n",
            "Эпоха 7  --- время: 215.55 \n",
            "Лучшие результаты: [0.761904776096344, 0.761904776096344, 0.761904776096344, 0.761904776096344, 0.738095223903656]  ----- Лучшие боты: [[1, 9, 1, 0, 0, 2, 0, 1, 6, 1, 4, 1, 0, 0, 0], [1, 9, 1, 0, 0, 2, 0, 1, 6, 1, 4, 1, 0, 0, 0], [1, 10, 1, 2, 0, 1, 0, 0, 2, 0, 4, 1, 2, 1, 0], [1, 9, 1, 0, 0, 2, 0, 1, 6, 1, 4, 1, 0, 0, 0], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1]]\n",
            "\n",
            "Эпоха 8  --- время: 215.08 \n",
            "Лучшие результаты: [0.8809523582458496, 0.8333333134651184, 0.8095238208770752, 0.7857142686843872, 0.7857142686843872]  ----- Лучшие боты: [[1, 9, 1, 0, 0, 2, 0, 1, 6, 1, 4, 1, 0, 0, 0], [1, 9, 1, 0, 0, 2, 0, 1, 6, 1, 4, 1, 0, 0, 0], [1, 9, 1, 0, 0, 2, 0, 1, 6, 1, 4, 1, 0, 0, 0], [1, 9, 1, 0, 0, 2, 0, 1, 6, 1, 4, 1, 0, 0, 0], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1]]\n",
            "\n",
            "Эпоха 9  --- время: 224.52 \n",
            "Лучшие результаты: [0.7857142686843872, 0.761904776096344, 0.738095223903656, 0.738095223903656, 0.738095223903656]  ----- Лучшие боты: [[1, 9, 1, 0, 0, 2, 0, 1, 6, 1, 4, 1, 0, 0, 0], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1]]\n",
            "\n",
            "Эпоха 10  --- время: 215.29 \n",
            "Лучшие результаты: [0.8095238208770752, 0.761904776096344, 0.761904776096344, 0.738095223903656, 0.738095223903656]  ----- Лучшие боты: [[1, 3, 0, 5, 0, 3, 1, 1, 5, 0, 4, 0, 2, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1]]\n",
            "\n",
            "Эпоха 11  --- время: 234.3 \n",
            "Лучшие результаты: [0.8095238208770752, 0.7857142686843872, 0.7857142686843872, 0.761904776096344, 0.761904776096344]  ----- Лучшие боты: [[1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1]]\n",
            "\n",
            "Эпоха 12  --- время: 233.65 \n",
            "Лучшие результаты: [0.8571428656578064, 0.7857142686843872, 0.761904776096344, 0.761904776096344, 0.761904776096344]  ----- Лучшие боты: [[1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1]]\n",
            "\n",
            "Эпоха 13  --- время: 208.17 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8095238208770752, 0.7857142686843872, 0.7857142686843872, 0.761904776096344]  ----- Лучшие боты: [[1, 10, 0, 2, 1, 2, 0, 1, 8, 0, 4, 0, 0, 0, 0], [0, 10, 1, 1, 0, 0, 0, 0, 6, 1, 1, 1, 2, 0, 3], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1]]\n",
            "\n",
            "Эпоха 14  --- время: 230.08 \n",
            "Лучшие результаты: [0.8095238208770752, 0.738095223903656, 0.6904761791229248, 0.6904761791229248, 0.6904761791229248]  ----- Лучшие боты: [[0, 6, 0, 0, 0, 3, 1, 0, 9, 0, 4, 1, 1, 1, 3], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 10, 0, 2, 1, 2, 0, 1, 8, 0, 4, 0, 0, 0, 0]]\n",
            "\n",
            "Эпоха 15  --- время: 215.32 \n",
            "Лучшие результаты: [0.761904776096344, 0.761904776096344, 0.7142857313156128, 0.7142857313156128, 0.7142857313156128]  ----- Лучшие боты: [[1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [0, 10, 1, 1, 0, 0, 0, 0, 6, 1, 1, 1, 2, 0, 3], [0, 6, 0, 0, 0, 3, 1, 0, 9, 0, 4, 1, 1, 1, 3], [0, 6, 0, 0, 0, 3, 1, 0, 9, 0, 4, 1, 1, 1, 3], [0, 6, 0, 0, 0, 3, 1, 0, 9, 0, 4, 1, 1, 1, 3]]\n",
            "\n",
            "Эпоха 16  --- время: 230.36 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8333333134651184, 0.8095238208770752, 0.7857142686843872, 0.761904776096344]  ----- Лучшие боты: [[1, 4, 0, 2, 1, 1, 1, 0, 8, 0, 4, 0, 3, 1, 3], [1, 4, 0, 2, 1, 1, 1, 0, 8, 0, 4, 0, 3, 1, 3], [0, 6, 0, 0, 0, 3, 1, 0, 9, 0, 4, 1, 1, 1, 3], [0, 6, 0, 0, 0, 3, 1, 0, 9, 0, 4, 1, 1, 1, 3], [0, 6, 0, 0, 0, 3, 1, 0, 9, 0, 4, 1, 1, 1, 3]]\n",
            "\n",
            "Эпоха 17  --- время: 209.06 \n",
            "Лучшие результаты: [0.7857142686843872, 0.7857142686843872, 0.7857142686843872, 0.761904776096344, 0.761904776096344]  ----- Лучшие боты: [[0, 10, 1, 5, 0, 2, 1, 0, 4, 0, 5, 0, 2, 0, 4], [1, 4, 0, 2, 1, 1, 1, 0, 8, 0, 4, 0, 3, 1, 3], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 4, 0, 2, 1, 1, 1, 0, 8, 0, 4, 0, 3, 1, 3], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1]]\n",
            "\n",
            "Эпоха 18  --- время: 221.97 \n",
            "Лучшие результаты: [0.8095238208770752, 0.8095238208770752, 0.761904776096344, 0.738095223903656, 0.738095223903656]  ----- Лучшие боты: [[1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1]]\n",
            "\n",
            "Эпоха 19  --- время: 214.72 \n",
            "Лучшие результаты: [0.8095238208770752, 0.7857142686843872, 0.761904776096344, 0.761904776096344, 0.761904776096344]  ----- Лучшие боты: [[1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1]]\n",
            "\n",
            "Эпоха 20  --- время: 218.69 \n",
            "Лучшие результаты: [0.8095238208770752, 0.7857142686843872, 0.7857142686843872, 0.7857142686843872, 0.7857142686843872]  ----- Лучшие боты: [[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [0, 4, 0, 0, 0, 0, 1, 1, 2, 0, 4, 0, 2, 0, 0], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1], [1, 7, 1, 4, 1, 2, 0, 0, 2, 0, 4, 0, 1, 1, 1]]\n",
            "\n",
            "Эпоха 21  --- время: 195.71 \n",
            "Лучшие результаты: [0.8095238208770752, 0.761904776096344, 0.761904776096344, 0.761904776096344, 0.761904776096344]  ----- Лучшие боты: [[1, 10, 0, 4, 0, 2, 0, 0, 10, 0, 2, 0, 0, 0, 2], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]]\n",
            "\n",
            "Эпоха 22  --- время: 195.24 \n",
            "Лучшие результаты: [0.9285714030265808, 0.8333333134651184, 0.8333333134651184, 0.8095238208770752, 0.7857142686843872]  ----- Лучшие боты: [[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]]\n",
            "\n",
            "Эпоха 23  --- время: 193.75 \n",
            "Лучшие результаты: [0.9047619104385376, 0.8333333134651184, 0.8333333134651184, 0.7857142686843872, 0.761904776096344]  ----- Лучшие боты: [[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]]\n",
            "\n",
            "Эпоха 24  --- время: 204.41 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8333333134651184, 0.8333333134651184, 0.7857142686843872, 0.7857142686843872]  ----- Лучшие боты: [[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]]\n",
            "\n",
            "Эпоха 25  --- время: 217.23 \n",
            "Лучшие результаты: [0.8809523582458496, 0.8809523582458496, 0.7857142686843872, 0.761904776096344, 0.761904776096344]  ----- Лучшие боты: [[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]]\n",
            "\n",
            "Эпоха 26  --- время: 199.44 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8333333134651184, 0.8333333134651184, 0.8333333134651184, 0.8095238208770752]  ----- Лучшие боты: [[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]]\n",
            "\n",
            "Эпоха 27  --- время: 218.21 \n",
            "Лучшие результаты: [0.9047619104385376, 0.9047619104385376, 0.8571428656578064, 0.8333333134651184, 0.7857142686843872]  ----- Лучшие боты: [[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]]\n",
            "\n",
            "Эпоха 28  --- время: 228.68 \n",
            "Лучшие результаты: [0.8809523582458496, 0.8809523582458496, 0.8571428656578064, 0.8095238208770752, 0.8095238208770752]  ----- Лучшие боты: [[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]]\n",
            "\n",
            "Эпоха 29  --- время: 233.57 \n",
            "Лучшие результаты: [0.8333333134651184, 0.8095238208770752, 0.8095238208770752, 0.8095238208770752, 0.7857142686843872]  ----- Лучшие боты: [[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]]\n",
            "\n",
            "Эпоха 30  --- время: 205.75 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8333333134651184, 0.8333333134651184, 0.8095238208770752, 0.8095238208770752]  ----- Лучшие боты: [[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]]\n",
            "\n",
            "Эпоха 31  --- время: 203.48 \n",
            "Лучшие результаты: [0.8809523582458496, 0.8809523582458496, 0.8333333134651184, 0.8095238208770752, 0.8095238208770752]  ----- Лучшие боты: [[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]]\n",
            "\n",
            "Эпоха 32  --- время: 215.46 \n",
            "Лучшие результаты: [0.8333333134651184, 0.8095238208770752, 0.8095238208770752, 0.8095238208770752, 0.7857142686843872]  ----- Лучшие боты: [[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]]\n",
            "\n",
            "Эпоха 33  --- время: 213.54 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8333333134651184, 0.8095238208770752, 0.8095238208770752, 0.7857142686843872]  ----- Лучшие боты: [[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]]\n",
            "\n",
            "Эпоха 34  --- время: 208.7 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8571428656578064, 0.8333333134651184, 0.8333333134651184, 0.8095238208770752]  ----- Лучшие боты: [[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]]\n",
            "\n",
            "Эпоха 35  --- время: 211.36 \n",
            "Лучшие результаты: [0.8333333134651184, 0.8333333134651184, 0.8333333134651184, 0.8095238208770752, 0.8095238208770752]  ----- Лучшие боты: [[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]]\n",
            "\n",
            "Эпоха 36  --- время: 208.95 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8333333134651184, 0.8095238208770752, 0.7857142686843872, 0.7857142686843872]  ----- Лучшие боты: [[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]]\n",
            "\n",
            "Эпоха 37  --- время: 213.13 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8333333134651184, 0.8095238208770752, 0.7857142686843872, 0.761904776096344]  ----- Лучшие боты: [[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]]\n",
            "\n",
            "Эпоха 38  --- время: 209.71 \n",
            "Лучшие результаты: [0.9047619104385376, 0.8809523582458496, 0.8571428656578064, 0.8333333134651184, 0.8333333134651184]  ----- Лучшие боты: [[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 8, 1, 4, 0, 0, 1, 1, 2, 0, 4, 1, 3, 0, 0], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]]\n",
            "\n",
            "Эпоха 39  --- время: 213.45 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8333333134651184, 0.8333333134651184, 0.7857142686843872, 0.761904776096344]  ----- Лучшие боты: [[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]]\n",
            "\n",
            "Эпоха 40  --- время: 205.98 \n",
            "Лучшие результаты: [0.8333333134651184, 0.8333333134651184, 0.8333333134651184, 0.8333333134651184, 0.8095238208770752]  ----- Лучшие боты: [[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]]\n",
            "\n",
            "Эпоха 41  --- время: 225.7 \n",
            "Лучшие результаты: [0.8333333134651184, 0.8333333134651184, 0.7857142686843872, 0.7857142686843872, 0.761904776096344]  ----- Лучшие боты: [[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]]\n",
            "\n",
            "Эпоха 42  --- время: 213.92 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8571428656578064, 0.8095238208770752, 0.8095238208770752, 0.7857142686843872]  ----- Лучшие боты: [[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]]\n",
            "\n",
            "Эпоха 43  --- время: 207.65 \n",
            "Лучшие результаты: [0.8809523582458496, 0.8095238208770752, 0.8095238208770752, 0.8095238208770752, 0.8095238208770752]  ----- Лучшие боты: [[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]]\n",
            "\n",
            "Эпоха 44  --- время: 217.05 \n",
            "Лучшие результаты: [0.8333333134651184, 0.8095238208770752, 0.8095238208770752, 0.7857142686843872, 0.761904776096344]  ----- Лучшие боты: [[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]]\n",
            "\n",
            "Эпоха 45  --- время: 212.48 \n",
            "Лучшие результаты: [0.8333333134651184, 0.8333333134651184, 0.8095238208770752, 0.7857142686843872, 0.761904776096344]  ----- Лучшие боты: [[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]]\n",
            "\n",
            "Эпоха 46  --- время: 220.57 \n",
            "Лучшие результаты: [0.9047619104385376, 0.8571428656578064, 0.8333333134651184, 0.8333333134651184, 0.8095238208770752]  ----- Лучшие боты: [[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]]\n",
            "\n",
            "Эпоха 47  --- время: 214.4 \n",
            "Лучшие результаты: [0.8809523582458496, 0.8571428656578064, 0.8333333134651184, 0.8095238208770752, 0.8095238208770752]  ----- Лучшие боты: [[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]]\n",
            "\n",
            "Эпоха 48  --- время: 223.32 \n",
            "Лучшие результаты: [0.8333333134651184, 0.8333333134651184, 0.8095238208770752, 0.8095238208770752, 0.8095238208770752]  ----- Лучшие боты: [[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]]\n",
            "\n",
            "Эпоха 49  --- время: 252.97 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8333333134651184, 0.761904776096344, 0.761904776096344, 0.761904776096344]  ----- Лучшие боты: [[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1], [1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "popul = []\n",
        "#val = []\n",
        "\n",
        "# Создаем случайных ботов\n",
        "popul = [createRandomNet() for _ in range(n)]\n",
        "\n",
        "for ep in range(epochs):\n",
        "  val = []\n",
        "  curr_time = time.time()\n",
        "  #print(f\"Эпоха {ep}:\")\n",
        "  \n",
        "  for i in range(n):\n",
        "    bot = popul[i]\n",
        "    f = evaluateNet(bot)\n",
        "    #print(f\"Бот: {i} готов\")\n",
        "    val.append(f)\n",
        "\n",
        "  sval = sorted(val, reverse=True)\n",
        "\n",
        "  end_time = time.time() - curr_time\n",
        "  print(f\"Эпоха {ep}  --- время: {round(end_time, 2)} \")\n",
        "  print(f'Лучшие результаты: {sval[:5]}  ----- Лучшие боты: {popul[:5]}')\n",
        "  print()\n",
        "\n",
        "  newpopul = []\n",
        "  for i in range(nsurv):\n",
        "    index = val.index(sval[i])\n",
        "    newpopul.append(popul[index])\n",
        "  \n",
        "  for i in range(nnew):\n",
        "    botp1, botp2 = getParents(newpopul, nsurv)\n",
        "    newbot = []\n",
        "    net4Mut = createRandomNet()\n",
        "\n",
        "    for j in range(l):\n",
        "      x = crossPointFrom2Parents(botp1, botp2, j)\n",
        "      if random.random() < mut:\n",
        "        x = net4Mut[j]\n",
        "      newbot.append(x)\n",
        "    newpopul.append(newbot)\n",
        "  \n",
        "  popul = newpopul"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuWLVSAg1_3L"
      },
      "source": [
        "## Проверка результатов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMnAPJHQ1_3P",
        "outputId": "698711fa-3901-4233-9036-20cf4cd6b14d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]\n",
            "[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]\n",
            "[1, 10, 1, 1, 0, 3, 0, 0, 4, 0, 4, 0, 1, 0, 1]\n"
          ]
        }
      ],
      "source": [
        "# Вывод трех лучших ботов\n",
        "for i in range(3):\n",
        "  print(popul[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLMpGKml1_3Q"
      },
      "source": [
        "## Обучение лучшей модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHxq66_R1_3R"
      },
      "outputs": [],
      "source": [
        "model = createConvNet(popul[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIpb4DaN1_3R"
      },
      "source": [
        "### Архитектура сети"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRmI0lu01_3S"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5VxEQId1_3T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "3b75926c-67af-450c-bf04-bd282db0a998"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "plot_model(model, show_shapes=True, dpi = 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YemFpEsrO6pV"
      },
      "source": [
        "## Обучим лучшую архитектуру"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba67e4a6-eb18-43c3-8496-1c5bdacba303",
        "id": "q9fZP3SUO6pZ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "6/6 [==============================] - 2s 129ms/step - loss: 0.7368 - accuracy: 0.5301 - val_loss: 0.6851 - val_accuracy: 0.5952\n",
            "Epoch 2/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.7313 - accuracy: 0.5361 - val_loss: 0.6838 - val_accuracy: 0.5952\n",
            "Epoch 3/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.7046 - accuracy: 0.5964 - val_loss: 0.6824 - val_accuracy: 0.5952\n",
            "Epoch 4/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.7014 - accuracy: 0.5964 - val_loss: 0.6809 - val_accuracy: 0.5952\n",
            "Epoch 5/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6838 - accuracy: 0.5964 - val_loss: 0.6796 - val_accuracy: 0.5952\n",
            "Epoch 6/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6770 - accuracy: 0.5783 - val_loss: 0.6779 - val_accuracy: 0.5952\n",
            "Epoch 7/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6618 - accuracy: 0.6265 - val_loss: 0.6757 - val_accuracy: 0.5952\n",
            "Epoch 8/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6580 - accuracy: 0.6446 - val_loss: 0.6734 - val_accuracy: 0.5952\n",
            "Epoch 9/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6444 - accuracy: 0.6747 - val_loss: 0.6713 - val_accuracy: 0.5714\n",
            "Epoch 10/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6356 - accuracy: 0.6747 - val_loss: 0.6690 - val_accuracy: 0.5714\n",
            "Epoch 11/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6277 - accuracy: 0.6928 - val_loss: 0.6667 - val_accuracy: 0.5714\n",
            "Epoch 12/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6289 - accuracy: 0.6807 - val_loss: 0.6639 - val_accuracy: 0.5714\n",
            "Epoch 13/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6040 - accuracy: 0.6867 - val_loss: 0.6610 - val_accuracy: 0.5952\n",
            "Epoch 14/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6004 - accuracy: 0.7289 - val_loss: 0.6580 - val_accuracy: 0.5952\n",
            "Epoch 15/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5977 - accuracy: 0.7289 - val_loss: 0.6550 - val_accuracy: 0.5952\n",
            "Epoch 16/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5795 - accuracy: 0.7410 - val_loss: 0.6520 - val_accuracy: 0.6190\n",
            "Epoch 17/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5719 - accuracy: 0.7590 - val_loss: 0.6488 - val_accuracy: 0.6190\n",
            "Epoch 18/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5668 - accuracy: 0.7892 - val_loss: 0.6455 - val_accuracy: 0.6190\n",
            "Epoch 19/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5627 - accuracy: 0.7651 - val_loss: 0.6425 - val_accuracy: 0.6429\n",
            "Epoch 20/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5746 - accuracy: 0.7229 - val_loss: 0.6395 - val_accuracy: 0.6429\n",
            "Epoch 21/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5569 - accuracy: 0.7831 - val_loss: 0.6364 - val_accuracy: 0.6667\n",
            "Epoch 22/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5476 - accuracy: 0.7651 - val_loss: 0.6328 - val_accuracy: 0.6905\n",
            "Epoch 23/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5507 - accuracy: 0.7651 - val_loss: 0.6292 - val_accuracy: 0.6905\n",
            "Epoch 24/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5345 - accuracy: 0.7771 - val_loss: 0.6258 - val_accuracy: 0.7143\n",
            "Epoch 25/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5270 - accuracy: 0.7831 - val_loss: 0.6221 - val_accuracy: 0.7381\n",
            "Epoch 26/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5306 - accuracy: 0.7831 - val_loss: 0.6182 - val_accuracy: 0.7619\n",
            "Epoch 27/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5187 - accuracy: 0.7771 - val_loss: 0.6141 - val_accuracy: 0.7619\n",
            "Epoch 28/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5189 - accuracy: 0.8012 - val_loss: 0.6101 - val_accuracy: 0.7619\n",
            "Epoch 29/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5168 - accuracy: 0.7771 - val_loss: 0.6059 - val_accuracy: 0.7619\n",
            "Epoch 30/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5145 - accuracy: 0.7892 - val_loss: 0.6017 - val_accuracy: 0.7619\n",
            "Epoch 31/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5066 - accuracy: 0.7952 - val_loss: 0.5977 - val_accuracy: 0.7619\n",
            "Epoch 32/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4984 - accuracy: 0.7771 - val_loss: 0.5941 - val_accuracy: 0.7619\n",
            "Epoch 33/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5049 - accuracy: 0.7952 - val_loss: 0.5902 - val_accuracy: 0.7619\n",
            "Epoch 34/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4912 - accuracy: 0.7952 - val_loss: 0.5859 - val_accuracy: 0.7619\n",
            "Epoch 35/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4912 - accuracy: 0.7952 - val_loss: 0.5816 - val_accuracy: 0.7619\n",
            "Epoch 36/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4786 - accuracy: 0.8012 - val_loss: 0.5769 - val_accuracy: 0.7619\n",
            "Epoch 37/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4848 - accuracy: 0.7831 - val_loss: 0.5726 - val_accuracy: 0.7619\n",
            "Epoch 38/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4890 - accuracy: 0.7952 - val_loss: 0.5684 - val_accuracy: 0.7619\n",
            "Epoch 39/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4822 - accuracy: 0.8072 - val_loss: 0.5640 - val_accuracy: 0.7619\n",
            "Epoch 40/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4772 - accuracy: 0.7952 - val_loss: 0.5598 - val_accuracy: 0.7619\n",
            "Epoch 41/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4587 - accuracy: 0.8253 - val_loss: 0.5555 - val_accuracy: 0.7619\n",
            "Epoch 42/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4656 - accuracy: 0.8313 - val_loss: 0.5512 - val_accuracy: 0.7619\n",
            "Epoch 43/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4678 - accuracy: 0.8133 - val_loss: 0.5469 - val_accuracy: 0.7619\n",
            "Epoch 44/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4553 - accuracy: 0.8133 - val_loss: 0.5424 - val_accuracy: 0.7619\n",
            "Epoch 45/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4484 - accuracy: 0.8193 - val_loss: 0.5382 - val_accuracy: 0.7619\n",
            "Epoch 46/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4594 - accuracy: 0.8313 - val_loss: 0.5338 - val_accuracy: 0.7619\n",
            "Epoch 47/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4477 - accuracy: 0.8253 - val_loss: 0.5290 - val_accuracy: 0.7857\n",
            "Epoch 48/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4424 - accuracy: 0.8193 - val_loss: 0.5243 - val_accuracy: 0.7857\n",
            "Epoch 49/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4438 - accuracy: 0.8193 - val_loss: 0.5195 - val_accuracy: 0.8095\n",
            "Epoch 50/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4393 - accuracy: 0.8253 - val_loss: 0.5148 - val_accuracy: 0.8333\n",
            "Epoch 51/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4470 - accuracy: 0.8012 - val_loss: 0.5105 - val_accuracy: 0.8333\n",
            "Epoch 52/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4428 - accuracy: 0.8133 - val_loss: 0.5066 - val_accuracy: 0.8333\n",
            "Epoch 53/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4412 - accuracy: 0.8133 - val_loss: 0.5026 - val_accuracy: 0.8333\n",
            "Epoch 54/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4236 - accuracy: 0.8313 - val_loss: 0.4985 - val_accuracy: 0.8333\n",
            "Epoch 55/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4222 - accuracy: 0.8193 - val_loss: 0.4940 - val_accuracy: 0.8333\n",
            "Epoch 56/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4322 - accuracy: 0.8313 - val_loss: 0.4893 - val_accuracy: 0.8333\n",
            "Epoch 57/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4254 - accuracy: 0.8193 - val_loss: 0.4849 - val_accuracy: 0.8333\n",
            "Epoch 58/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4184 - accuracy: 0.8193 - val_loss: 0.4803 - val_accuracy: 0.8333\n",
            "Epoch 59/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4161 - accuracy: 0.8193 - val_loss: 0.4753 - val_accuracy: 0.8333\n",
            "Epoch 60/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4163 - accuracy: 0.8494 - val_loss: 0.4711 - val_accuracy: 0.8333\n",
            "Epoch 61/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4165 - accuracy: 0.8434 - val_loss: 0.4669 - val_accuracy: 0.8571\n",
            "Epoch 62/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4202 - accuracy: 0.8373 - val_loss: 0.4626 - val_accuracy: 0.8810\n",
            "Epoch 63/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4213 - accuracy: 0.8253 - val_loss: 0.4583 - val_accuracy: 0.8810\n",
            "Epoch 64/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4185 - accuracy: 0.8434 - val_loss: 0.4541 - val_accuracy: 0.9048\n",
            "Epoch 65/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3988 - accuracy: 0.8614 - val_loss: 0.4500 - val_accuracy: 0.9048\n",
            "Epoch 66/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4062 - accuracy: 0.8133 - val_loss: 0.4463 - val_accuracy: 0.9048\n",
            "Epoch 67/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4011 - accuracy: 0.8554 - val_loss: 0.4423 - val_accuracy: 0.9048\n",
            "Epoch 68/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3945 - accuracy: 0.8313 - val_loss: 0.4385 - val_accuracy: 0.9048\n",
            "Epoch 69/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4004 - accuracy: 0.8494 - val_loss: 0.4343 - val_accuracy: 0.9048\n",
            "Epoch 70/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3875 - accuracy: 0.8494 - val_loss: 0.4298 - val_accuracy: 0.9048\n",
            "Epoch 71/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3776 - accuracy: 0.8735 - val_loss: 0.4259 - val_accuracy: 0.9048\n",
            "Epoch 72/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3911 - accuracy: 0.8193 - val_loss: 0.4221 - val_accuracy: 0.9048\n",
            "Epoch 73/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4001 - accuracy: 0.8434 - val_loss: 0.4187 - val_accuracy: 0.9048\n",
            "Epoch 74/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3876 - accuracy: 0.8373 - val_loss: 0.4148 - val_accuracy: 0.9048\n",
            "Epoch 75/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3875 - accuracy: 0.8313 - val_loss: 0.4108 - val_accuracy: 0.9048\n",
            "Epoch 76/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3862 - accuracy: 0.8554 - val_loss: 0.4077 - val_accuracy: 0.9048\n",
            "Epoch 77/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3780 - accuracy: 0.8614 - val_loss: 0.4045 - val_accuracy: 0.9048\n",
            "Epoch 78/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3780 - accuracy: 0.8554 - val_loss: 0.4009 - val_accuracy: 0.9048\n",
            "Epoch 79/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3729 - accuracy: 0.8795 - val_loss: 0.3979 - val_accuracy: 0.9048\n",
            "Epoch 80/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3750 - accuracy: 0.8675 - val_loss: 0.3945 - val_accuracy: 0.9048\n",
            "Epoch 81/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3678 - accuracy: 0.8434 - val_loss: 0.3912 - val_accuracy: 0.9048\n",
            "Epoch 82/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3599 - accuracy: 0.8614 - val_loss: 0.3876 - val_accuracy: 0.9048\n",
            "Epoch 83/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3799 - accuracy: 0.8614 - val_loss: 0.3841 - val_accuracy: 0.9048\n",
            "Epoch 84/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3719 - accuracy: 0.8855 - val_loss: 0.3811 - val_accuracy: 0.9048\n",
            "Epoch 85/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3709 - accuracy: 0.8614 - val_loss: 0.3785 - val_accuracy: 0.9048\n",
            "Epoch 86/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3538 - accuracy: 0.8675 - val_loss: 0.3754 - val_accuracy: 0.9048\n",
            "Epoch 87/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3576 - accuracy: 0.8735 - val_loss: 0.3725 - val_accuracy: 0.9048\n",
            "Epoch 88/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3707 - accuracy: 0.8554 - val_loss: 0.3701 - val_accuracy: 0.9048\n",
            "Epoch 89/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3577 - accuracy: 0.8675 - val_loss: 0.3673 - val_accuracy: 0.9048\n",
            "Epoch 90/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3415 - accuracy: 0.9036 - val_loss: 0.3646 - val_accuracy: 0.9048\n",
            "Epoch 91/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3594 - accuracy: 0.8614 - val_loss: 0.3627 - val_accuracy: 0.9048\n",
            "Epoch 92/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3535 - accuracy: 0.8554 - val_loss: 0.3605 - val_accuracy: 0.9048\n",
            "Epoch 93/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3492 - accuracy: 0.8795 - val_loss: 0.3581 - val_accuracy: 0.9048\n",
            "Epoch 94/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3697 - accuracy: 0.8735 - val_loss: 0.3562 - val_accuracy: 0.9048\n",
            "Epoch 95/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3579 - accuracy: 0.8494 - val_loss: 0.3536 - val_accuracy: 0.9048\n",
            "Epoch 96/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3409 - accuracy: 0.8675 - val_loss: 0.3513 - val_accuracy: 0.9048\n",
            "Epoch 97/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3453 - accuracy: 0.8675 - val_loss: 0.3488 - val_accuracy: 0.9048\n",
            "Epoch 98/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3572 - accuracy: 0.8916 - val_loss: 0.3467 - val_accuracy: 0.9048\n",
            "Epoch 99/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3423 - accuracy: 0.8855 - val_loss: 0.3444 - val_accuracy: 0.9048\n",
            "Epoch 100/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3440 - accuracy: 0.8855 - val_loss: 0.3425 - val_accuracy: 0.9048\n",
            "Epoch 101/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3397 - accuracy: 0.8675 - val_loss: 0.3410 - val_accuracy: 0.9048\n",
            "Epoch 102/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3515 - accuracy: 0.8675 - val_loss: 0.3393 - val_accuracy: 0.9048\n",
            "Epoch 103/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3336 - accuracy: 0.8916 - val_loss: 0.3374 - val_accuracy: 0.9048\n",
            "Epoch 104/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3347 - accuracy: 0.8855 - val_loss: 0.3352 - val_accuracy: 0.9048\n",
            "Epoch 105/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3285 - accuracy: 0.8916 - val_loss: 0.3335 - val_accuracy: 0.9048\n",
            "Epoch 106/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3425 - accuracy: 0.8855 - val_loss: 0.3313 - val_accuracy: 0.9048\n",
            "Epoch 107/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3257 - accuracy: 0.9096 - val_loss: 0.3294 - val_accuracy: 0.9048\n",
            "Epoch 108/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3184 - accuracy: 0.8976 - val_loss: 0.3271 - val_accuracy: 0.9048\n",
            "Epoch 109/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3208 - accuracy: 0.8855 - val_loss: 0.3247 - val_accuracy: 0.9048\n",
            "Epoch 110/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3260 - accuracy: 0.9036 - val_loss: 0.3228 - val_accuracy: 0.9048\n",
            "Epoch 111/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3509 - accuracy: 0.8795 - val_loss: 0.3212 - val_accuracy: 0.9048\n",
            "Epoch 112/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3340 - accuracy: 0.8855 - val_loss: 0.3192 - val_accuracy: 0.9048\n",
            "Epoch 113/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3152 - accuracy: 0.9096 - val_loss: 0.3185 - val_accuracy: 0.9048\n",
            "Epoch 114/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3231 - accuracy: 0.9036 - val_loss: 0.3171 - val_accuracy: 0.9048\n",
            "Epoch 115/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3168 - accuracy: 0.9096 - val_loss: 0.3156 - val_accuracy: 0.9048\n",
            "Epoch 116/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3185 - accuracy: 0.9096 - val_loss: 0.3141 - val_accuracy: 0.9048\n",
            "Epoch 117/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3247 - accuracy: 0.8976 - val_loss: 0.3128 - val_accuracy: 0.9048\n",
            "Epoch 118/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3161 - accuracy: 0.9096 - val_loss: 0.3111 - val_accuracy: 0.9048\n",
            "Epoch 119/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3254 - accuracy: 0.8916 - val_loss: 0.3093 - val_accuracy: 0.9048\n",
            "Epoch 120/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3360 - accuracy: 0.8434 - val_loss: 0.3080 - val_accuracy: 0.9048\n",
            "Epoch 121/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3163 - accuracy: 0.9217 - val_loss: 0.3059 - val_accuracy: 0.9048\n",
            "Epoch 122/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3085 - accuracy: 0.9096 - val_loss: 0.3044 - val_accuracy: 0.9048\n",
            "Epoch 123/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3118 - accuracy: 0.9036 - val_loss: 0.3037 - val_accuracy: 0.9048\n",
            "Epoch 124/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3151 - accuracy: 0.9096 - val_loss: 0.3025 - val_accuracy: 0.9048\n",
            "Epoch 125/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2949 - accuracy: 0.9458 - val_loss: 0.3018 - val_accuracy: 0.9048\n",
            "Epoch 126/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3078 - accuracy: 0.9217 - val_loss: 0.3010 - val_accuracy: 0.9048\n",
            "Epoch 127/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3077 - accuracy: 0.8976 - val_loss: 0.3000 - val_accuracy: 0.9048\n",
            "Epoch 128/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2965 - accuracy: 0.9217 - val_loss: 0.2992 - val_accuracy: 0.9048\n",
            "Epoch 129/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2931 - accuracy: 0.9398 - val_loss: 0.2983 - val_accuracy: 0.9048\n",
            "Epoch 130/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3064 - accuracy: 0.9096 - val_loss: 0.2969 - val_accuracy: 0.9048\n",
            "Epoch 131/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3016 - accuracy: 0.9036 - val_loss: 0.2950 - val_accuracy: 0.9048\n",
            "Epoch 132/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3018 - accuracy: 0.9036 - val_loss: 0.2938 - val_accuracy: 0.9048\n",
            "Epoch 133/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2877 - accuracy: 0.9337 - val_loss: 0.2920 - val_accuracy: 0.9048\n",
            "Epoch 134/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2928 - accuracy: 0.9157 - val_loss: 0.2909 - val_accuracy: 0.9048\n",
            "Epoch 135/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2944 - accuracy: 0.9337 - val_loss: 0.2895 - val_accuracy: 0.9048\n",
            "Epoch 136/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3017 - accuracy: 0.9096 - val_loss: 0.2884 - val_accuracy: 0.9048\n",
            "Epoch 137/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2983 - accuracy: 0.9096 - val_loss: 0.2874 - val_accuracy: 0.9048\n",
            "Epoch 138/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2933 - accuracy: 0.9277 - val_loss: 0.2867 - val_accuracy: 0.9048\n",
            "Epoch 139/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2808 - accuracy: 0.9217 - val_loss: 0.2859 - val_accuracy: 0.9048\n",
            "Epoch 140/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2927 - accuracy: 0.9217 - val_loss: 0.2853 - val_accuracy: 0.9048\n",
            "Epoch 141/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2832 - accuracy: 0.9337 - val_loss: 0.2842 - val_accuracy: 0.9048\n",
            "Epoch 142/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2916 - accuracy: 0.9096 - val_loss: 0.2831 - val_accuracy: 0.9048\n",
            "Epoch 143/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2751 - accuracy: 0.9337 - val_loss: 0.2827 - val_accuracy: 0.9048\n",
            "Epoch 144/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2833 - accuracy: 0.9337 - val_loss: 0.2818 - val_accuracy: 0.9048\n",
            "Epoch 145/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2859 - accuracy: 0.9157 - val_loss: 0.2806 - val_accuracy: 0.8810\n",
            "Epoch 146/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2880 - accuracy: 0.9096 - val_loss: 0.2802 - val_accuracy: 0.8810\n",
            "Epoch 147/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2795 - accuracy: 0.9337 - val_loss: 0.2791 - val_accuracy: 0.8810\n",
            "Epoch 148/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2857 - accuracy: 0.9277 - val_loss: 0.2786 - val_accuracy: 0.8810\n",
            "Epoch 149/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3035 - accuracy: 0.9157 - val_loss: 0.2785 - val_accuracy: 0.8810\n",
            "Epoch 150/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2774 - accuracy: 0.9217 - val_loss: 0.2778 - val_accuracy: 0.8810\n",
            "Epoch 151/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2793 - accuracy: 0.9036 - val_loss: 0.2764 - val_accuracy: 0.8810\n",
            "Epoch 152/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2734 - accuracy: 0.9217 - val_loss: 0.2752 - val_accuracy: 0.8810\n",
            "Epoch 153/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2869 - accuracy: 0.9337 - val_loss: 0.2744 - val_accuracy: 0.8810\n",
            "Epoch 154/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2747 - accuracy: 0.9217 - val_loss: 0.2740 - val_accuracy: 0.8810\n",
            "Epoch 155/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2722 - accuracy: 0.9157 - val_loss: 0.2732 - val_accuracy: 0.8810\n",
            "Epoch 156/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2703 - accuracy: 0.9398 - val_loss: 0.2723 - val_accuracy: 0.8810\n",
            "Epoch 157/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2677 - accuracy: 0.9458 - val_loss: 0.2716 - val_accuracy: 0.8810\n",
            "Epoch 158/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2562 - accuracy: 0.9337 - val_loss: 0.2700 - val_accuracy: 0.8810\n",
            "Epoch 159/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2562 - accuracy: 0.9036 - val_loss: 0.2690 - val_accuracy: 0.8810\n",
            "Epoch 160/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2756 - accuracy: 0.9398 - val_loss: 0.2685 - val_accuracy: 0.8810\n",
            "Epoch 161/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2711 - accuracy: 0.9217 - val_loss: 0.2676 - val_accuracy: 0.8810\n",
            "Epoch 162/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2681 - accuracy: 0.9157 - val_loss: 0.2676 - val_accuracy: 0.8810\n",
            "Epoch 163/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2602 - accuracy: 0.9398 - val_loss: 0.2672 - val_accuracy: 0.8810\n",
            "Epoch 164/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2652 - accuracy: 0.9217 - val_loss: 0.2670 - val_accuracy: 0.8810\n",
            "Epoch 165/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2607 - accuracy: 0.9217 - val_loss: 0.2668 - val_accuracy: 0.8810\n",
            "Epoch 166/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2709 - accuracy: 0.9458 - val_loss: 0.2668 - val_accuracy: 0.8810\n",
            "Epoch 167/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2615 - accuracy: 0.9458 - val_loss: 0.2663 - val_accuracy: 0.8810\n",
            "Epoch 168/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2617 - accuracy: 0.9277 - val_loss: 0.2652 - val_accuracy: 0.8810\n",
            "Epoch 169/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2799 - accuracy: 0.9337 - val_loss: 0.2641 - val_accuracy: 0.9048\n",
            "Epoch 170/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2468 - accuracy: 0.9398 - val_loss: 0.2627 - val_accuracy: 0.9048\n",
            "Epoch 171/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2644 - accuracy: 0.9217 - val_loss: 0.2614 - val_accuracy: 0.9048\n",
            "Epoch 172/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2480 - accuracy: 0.9518 - val_loss: 0.2606 - val_accuracy: 0.9048\n",
            "Epoch 173/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2592 - accuracy: 0.9337 - val_loss: 0.2604 - val_accuracy: 0.8810\n",
            "Epoch 174/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2700 - accuracy: 0.9096 - val_loss: 0.2599 - val_accuracy: 0.8810\n",
            "Epoch 175/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2586 - accuracy: 0.9217 - val_loss: 0.2593 - val_accuracy: 0.8810\n",
            "Epoch 176/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2630 - accuracy: 0.9337 - val_loss: 0.2581 - val_accuracy: 0.8810\n",
            "Epoch 177/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2547 - accuracy: 0.9398 - val_loss: 0.2575 - val_accuracy: 0.8810\n",
            "Epoch 178/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2531 - accuracy: 0.9277 - val_loss: 0.2562 - val_accuracy: 0.8810\n",
            "Epoch 179/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2494 - accuracy: 0.9458 - val_loss: 0.2561 - val_accuracy: 0.8810\n",
            "Epoch 180/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2379 - accuracy: 0.9518 - val_loss: 0.2556 - val_accuracy: 0.9048\n",
            "Epoch 181/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2457 - accuracy: 0.9398 - val_loss: 0.2548 - val_accuracy: 0.9286\n",
            "Epoch 182/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2476 - accuracy: 0.9277 - val_loss: 0.2541 - val_accuracy: 0.9286\n",
            "Epoch 183/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2486 - accuracy: 0.9157 - val_loss: 0.2535 - val_accuracy: 0.9286\n",
            "Epoch 184/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2440 - accuracy: 0.9398 - val_loss: 0.2527 - val_accuracy: 0.9048\n",
            "Epoch 185/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2479 - accuracy: 0.9398 - val_loss: 0.2516 - val_accuracy: 0.9286\n",
            "Epoch 186/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2332 - accuracy: 0.9458 - val_loss: 0.2510 - val_accuracy: 0.9048\n",
            "Epoch 187/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2573 - accuracy: 0.9217 - val_loss: 0.2505 - val_accuracy: 0.9286\n",
            "Epoch 188/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2364 - accuracy: 0.9518 - val_loss: 0.2498 - val_accuracy: 0.9286\n",
            "Epoch 189/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2468 - accuracy: 0.9157 - val_loss: 0.2497 - val_accuracy: 0.9286\n",
            "Epoch 190/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2380 - accuracy: 0.9458 - val_loss: 0.2488 - val_accuracy: 0.9286\n",
            "Epoch 191/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2628 - accuracy: 0.9277 - val_loss: 0.2479 - val_accuracy: 0.9286\n",
            "Epoch 192/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2532 - accuracy: 0.9398 - val_loss: 0.2472 - val_accuracy: 0.9286\n",
            "Epoch 193/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2395 - accuracy: 0.9337 - val_loss: 0.2468 - val_accuracy: 0.9286\n",
            "Epoch 194/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2446 - accuracy: 0.9458 - val_loss: 0.2458 - val_accuracy: 0.9286\n",
            "Epoch 195/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2320 - accuracy: 0.9337 - val_loss: 0.2455 - val_accuracy: 0.9048\n",
            "Epoch 196/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2378 - accuracy: 0.9398 - val_loss: 0.2455 - val_accuracy: 0.9048\n",
            "Epoch 197/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2239 - accuracy: 0.9518 - val_loss: 0.2448 - val_accuracy: 0.9048\n",
            "Epoch 198/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2278 - accuracy: 0.9337 - val_loss: 0.2443 - val_accuracy: 0.9048\n",
            "Epoch 199/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2618 - accuracy: 0.9157 - val_loss: 0.2444 - val_accuracy: 0.9048\n",
            "Epoch 200/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2346 - accuracy: 0.9398 - val_loss: 0.2442 - val_accuracy: 0.9048\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd82957b990>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=1e-4), metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=200, validation_data=(x_test ,y_test), verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Третий вариант\n",
        "**Один блок**"
      ],
      "metadata": {
        "id": "cWsRRtwcB722"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crxoetUOCE2Y"
      },
      "outputs": [],
      "source": [
        "def createRandomNet():\n",
        "  net = []\n",
        "  net.append(random.randint(0,1))  # 0- Нормализация 0,1\n",
        "  net.append(random.randint(2,50)) # 1- Число нейронов(которое будут изменяться)\n",
        "  net.append(random.randint(0,1))  # 2- Способ изменения нейронов в Dense слое\n",
        "  net.append(random.randint(0,5))  # 3- Функция активации первого слоя - ['linear','relu','elu','tanh','softmax','sigmoid']\n",
        "  net.append(random.randint(0,1))  # 4- Будет ли Dropout 0,1\n",
        "  net.append(random.randint(0,3))  # 5- Установка параметра rate в слое Dropout (0.25, 0.3, 0.35, 0.4)\n",
        "\n",
        "\n",
        "  net.append(random.randint(0,1))  # 6- Нормализация 0,1(Перед выходным слоем)\n",
        "  net.append(random.randint(0,4))  # 7- Функция активации выходного слоя - ['linear','relu','elu','softmax','sigmoid']\n",
        "\n",
        "  return net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nq5ZfoHLCE2Z"
      },
      "outputs": [],
      "source": [
        "def createConvNet(net):\n",
        " \n",
        "  makeFirstNormalization = net[0]       # 0 - Нормализация в начале 0,1\n",
        "  firstDenseNeurons = net[1]            # 1-  Число нейронов(которое будут изменяться)\n",
        "  firstСhangeNeurons = net[2]           # 2-  Способ изменения нейронов в Dense слое(0-умножение на 10; 1-степень)\n",
        "  activation1 = net[3]                  # 3-  Функция активации первого слоя - ['linear','relu','elu','softmax','sigmoid','tanh']\n",
        "  makeDropOut = net[4]                  # 4 - Будет ли Dropout 0,1\n",
        "  firstDropout = net[5]                 # 5 - Установка параметра rate в слое Dropout (0.25, 0.3, 0.35, 0.4)\n",
        "\n",
        "  finalNormalization = net[6]           # 6- Нормализация перед выходным слоем\n",
        "  activation2 = net[7]                  # 7- Функция активации выходного слоя - ['linear','relu','elu','softmax','sigmoid'] - без tanh\n",
        "\n",
        "\n",
        "  activation_list = ['linear','relu','elu','softmax','sigmoid','tanh']\n",
        "  dropout_list = [0.25, 0.3, 0.35, 0.4]\n",
        "\n",
        "  shape = (60,)\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  if makeFirstNormalization:                                                              # Нормализация в начале \n",
        "    model.add(BatchNormalization(input_shape=(shape)))\n",
        "    if firstСhangeNeurons:\n",
        "      model.add(Dense(firstDenseNeurons**2, activation=activation_list[activation1]))    # Добавление Dense слоя\n",
        "    else:\n",
        "      model.add(Dense(firstDenseNeurons*10, activation=activation_list[activation1]))\n",
        "  \n",
        "  else:  # Или без нормализации\n",
        "    if firstСhangeNeurons:\n",
        "      model.add(Dense(firstDenseNeurons**2, activation=activation_list[activation1], input_shape=(shape)))\n",
        "    else:\n",
        "      model.add(Dense(firstDenseNeurons*10, activation=activation_list[activation1], input_shape=(shape)))\n",
        "  \n",
        "  if makeDropOut:   # Будет ли Dropout\n",
        "    model.add(Dropout(dropout_list[firstDropout]))\n",
        "\n",
        "  # Выходной слой\n",
        "  if finalNormalization:   # Нормализация перед выходным слоем\n",
        "    model.add(BatchNormalization())\n",
        "  \n",
        "  model.add(Dense(1, activation=activation_list[activation2]))  #  Без tanh\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0H4wzV8CE2a"
      },
      "outputs": [],
      "source": [
        "n = 50            # Общее число ботов\n",
        "nsurv = 10         # Кол-во выживших\n",
        "nnew = n - nsurv   # Кол-во новых\n",
        "l = 8              # Размер бота\n",
        "epochs = 30        # Количество эпох\n",
        "\n",
        "mut = 0.99         # Коэфициент мутаций"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ebmaujnCE2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13a8b59e-6ca4-4b94-bad1-e3ed7eda3b0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 0  --- время: 400.25 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8333333134651184, 0.8333333134651184, 0.8333333134651184, 0.8095238208770752]  ----- Лучшие боты: [[0, 37, 1, 1, 1, 2, 1, 2], [1, 12, 1, 4, 0, 3, 0, 2], [0, 30, 1, 5, 0, 2, 0, 3], [0, 46, 1, 0, 0, 0, 0, 0], [1, 38, 1, 3, 0, 1, 1, 3]]\n",
            "\n",
            "Эпоха 1  --- время: 376.96 \n",
            "Лучшие результаты: [0.8809523582458496, 0.8809523582458496, 0.8571428656578064, 0.8571428656578064, 0.8333333134651184]  ----- Лучшие боты: [[1, 50, 1, 1, 0, 0, 1, 4], [0, 34, 1, 2, 1, 2, 0, 4], [0, 34, 1, 2, 1, 2, 0, 4], [0, 34, 1, 2, 1, 2, 0, 4], [0, 37, 1, 1, 1, 2, 1, 2]]\n",
            "\n",
            "Эпоха 2  --- время: 370.0 \n",
            "Лучшие результаты: [0.8571428656578064, 0.8571428656578064, 0.8333333134651184, 0.8333333134651184, 0.8333333134651184]  ----- Лучшие боты: [[1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [0, 37, 1, 1, 1, 2, 1, 2], [0, 37, 1, 1, 1, 2, 1, 2], [0, 34, 1, 2, 1, 2, 0, 4]]\n",
            "\n",
            "Эпоха 3  --- время: 338.46 \n",
            "Лучшие результаты: [0.9047619104385376, 0.8809523582458496, 0.8571428656578064, 0.8571428656578064, 0.8571428656578064]  ----- Лучшие боты: [[1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [0, 34, 1, 2, 1, 2, 0, 4], [0, 34, 1, 2, 1, 2, 0, 4], [0, 34, 1, 2, 1, 2, 0, 4]]\n",
            "\n",
            "Эпоха 4  --- время: 404.1 \n",
            "Лучшие результаты: [0.8809523582458496, 0.8809523582458496, 0.8809523582458496, 0.8571428656578064, 0.8571428656578064]  ----- Лучшие боты: [[1, 37, 0, 0, 1, 2, 0, 0], [1, 50, 1, 5, 1, 3, 1, 1], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4]]\n",
            "\n",
            "Эпоха 5  --- время: 412.29 \n",
            "Лучшие результаты: [0.9047619104385376, 0.8809523582458496, 0.8809523582458496, 0.8809523582458496, 0.8809523582458496]  ----- Лучшие боты: [[1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4]]\n",
            "\n",
            "Эпоха 6  --- время: 386.99 \n",
            "Лучшие результаты: [0.8809523582458496, 0.8809523582458496, 0.8571428656578064, 0.8571428656578064, 0.8571428656578064]  ----- Лучшие боты: [[1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4]]\n",
            "\n",
            "Эпоха 7  --- время: 397.41 \n",
            "Лучшие результаты: [0.9047619104385376, 0.8809523582458496, 0.8809523582458496, 0.8809523582458496, 0.8571428656578064]  ----- Лучшие боты: [[1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4]]\n",
            "\n",
            "Эпоха 8  --- время: 392.18 \n",
            "Лучшие результаты: [0.8809523582458496, 0.8571428656578064, 0.8571428656578064, 0.8571428656578064, 0.8571428656578064]  ----- Лучшие боты: [[1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4]]\n",
            "\n",
            "Эпоха 9  --- время: 386.6 \n",
            "Лучшие результаты: [0.9047619104385376, 0.8809523582458496, 0.8809523582458496, 0.8809523582458496, 0.8809523582458496]  ----- Лучшие боты: [[1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4]]\n",
            "\n",
            "Эпоха 10  --- время: 390.7 \n",
            "Лучшие результаты: [0.9285714030265808, 0.8809523582458496, 0.8809523582458496, 0.8809523582458496, 0.8571428656578064]  ----- Лучшие боты: [[1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4]]\n",
            "\n",
            "Эпоха 11  --- время: 399.59 \n",
            "Лучшие результаты: [0.8809523582458496, 0.8571428656578064, 0.8571428656578064, 0.8571428656578064, 0.8571428656578064]  ----- Лучшие боты: [[1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4]]\n",
            "\n",
            "Эпоха 12  --- время: 380.5 \n",
            "Лучшие результаты: [0.9047619104385376, 0.9047619104385376, 0.9047619104385376, 0.8809523582458496, 0.8809523582458496]  ----- Лучшие боты: [[1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4]]\n",
            "\n",
            "Эпоха 13  --- время: 385.19 \n",
            "Лучшие результаты: [0.9047619104385376, 0.9047619104385376, 0.9047619104385376, 0.8809523582458496, 0.8809523582458496]  ----- Лучшие боты: [[1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4]]\n",
            "\n",
            "Эпоха 14  --- время: 364.19 \n",
            "Лучшие результаты: [0.8809523582458496, 0.8571428656578064, 0.8571428656578064, 0.8571428656578064, 0.8571428656578064]  ----- Лучшие боты: [[1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4]]\n",
            "\n",
            "Эпоха 15  --- время: 414.4 \n",
            "Лучшие результаты: [0.9047619104385376, 0.9047619104385376, 0.9047619104385376, 0.8809523582458496, 0.8809523582458496]  ----- Лучшие боты: [[1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4]]\n",
            "\n",
            "Эпоха 16  --- время: 375.51 \n",
            "Лучшие результаты: [0.9047619104385376, 0.9047619104385376, 0.8809523582458496, 0.8571428656578064, 0.8571428656578064]  ----- Лучшие боты: [[1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4]]\n",
            "\n",
            "Эпоха 17  --- время: 400.67 \n",
            "Лучшие результаты: [0.8809523582458496, 0.8809523582458496, 0.8571428656578064, 0.8571428656578064, 0.8571428656578064]  ----- Лучшие боты: [[1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4]]\n",
            "\n",
            "Эпоха 18  --- время: 411.24 \n",
            "Лучшие результаты: [0.8809523582458496, 0.8809523582458496, 0.8571428656578064, 0.8571428656578064, 0.8571428656578064]  ----- Лучшие боты: [[1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4]]\n",
            "\n",
            "Эпоха 19  --- время: 381.01 \n",
            "Лучшие результаты: [0.9285714030265808, 0.9047619104385376, 0.8809523582458496, 0.8809523582458496, 0.8809523582458496]  ----- Лучшие боты: [[1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4]]\n",
            "\n",
            "Эпоха 20  --- время: 394.49 \n",
            "Лучшие результаты: [0.8809523582458496, 0.8809523582458496, 0.8809523582458496, 0.8809523582458496, 0.8809523582458496]  ----- Лучшие боты: [[1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4]]\n",
            "\n",
            "Эпоха 21  --- время: 394.6 \n",
            "Лучшие результаты: [0.9047619104385376, 0.8809523582458496, 0.8809523582458496, 0.8809523582458496, 0.8809523582458496]  ----- Лучшие боты: [[1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4]]\n",
            "\n",
            "Эпоха 22  --- время: 371.41 \n",
            "Лучшие результаты: [0.9047619104385376, 0.8809523582458496, 0.8571428656578064, 0.8571428656578064, 0.8571428656578064]  ----- Лучшие боты: [[1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4]]\n",
            "\n",
            "Эпоха 23  --- время: 367.47 \n",
            "Лучшие результаты: [0.9047619104385376, 0.9047619104385376, 0.8809523582458496, 0.8809523582458496, 0.8809523582458496]  ----- Лучшие боты: [[1, 50, 1, 1, 0, 0, 1, 4], [1, 37, 0, 2, 0, 0, 0, 2], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4]]\n",
            "\n",
            "Эпоха 24  --- время: 325.79 \n",
            "Лучшие результаты: [0.9047619104385376, 0.8809523582458496, 0.8809523582458496, 0.8571428656578064, 0.8571428656578064]  ----- Лучшие боты: [[1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4]]\n",
            "\n",
            "Эпоха 25  --- время: 344.52 \n",
            "Лучшие результаты: [0.9047619104385376, 0.8809523582458496, 0.8809523582458496, 0.8809523582458496, 0.8809523582458496]  ----- Лучшие боты: [[1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4]]\n",
            "\n",
            "Эпоха 26  --- время: 330.12 \n",
            "Лучшие результаты: [0.9047619104385376, 0.8809523582458496, 0.8809523582458496, 0.8571428656578064, 0.8571428656578064]  ----- Лучшие боты: [[1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4]]\n",
            "\n",
            "Эпоха 27  --- время: 355.75 \n",
            "Лучшие результаты: [0.8809523582458496, 0.8809523582458496, 0.8571428656578064, 0.8571428656578064, 0.8571428656578064]  ----- Лучшие боты: [[1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4]]\n",
            "\n",
            "Эпоха 28  --- время: 350.14 \n",
            "Лучшие результаты: [0.8809523582458496, 0.8809523582458496, 0.8809523582458496, 0.8571428656578064, 0.8571428656578064]  ----- Лучшие боты: [[1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4]]\n",
            "\n",
            "Эпоха 29  --- время: 376.13 \n",
            "Лучшие результаты: [0.9047619104385376, 0.8809523582458496, 0.8809523582458496, 0.8809523582458496, 0.8571428656578064]  ----- Лучшие боты: [[1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4], [1, 50, 1, 1, 0, 0, 1, 4]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "popul = []\n",
        "#val = []\n",
        "\n",
        "# Создаем случайных ботов\n",
        "popul = [createRandomNet() for _ in range(n)]\n",
        "\n",
        "for ep in range(epochs):\n",
        "  val = []\n",
        "  curr_time = time.time()\n",
        "  #print(f\"Эпоха {ep}:\")\n",
        "  \n",
        "  for i in range(n):\n",
        "    bot = popul[i]\n",
        "    f = evaluateNet(bot)\n",
        "    #print(f\"Бот: {i} готов\")\n",
        "    val.append(f)\n",
        "\n",
        "  sval = sorted(val, reverse=True)\n",
        "\n",
        "  end_time = time.time() - curr_time\n",
        "  print(f\"Эпоха {ep}  --- время: {round(end_time, 2)} \")\n",
        "  print(f'Лучшие результаты: {sval[:5]}  ----- Лучшие боты: {popul[:5]}')\n",
        "  print()\n",
        "\n",
        "  newpopul = []\n",
        "  for i in range(nsurv):\n",
        "    index = val.index(sval[i])\n",
        "    newpopul.append(popul[index])\n",
        "  \n",
        "  for i in range(nnew):\n",
        "    botp1, botp2 = getParents(newpopul, nsurv)\n",
        "    newbot = []\n",
        "    net4Mut = createRandomNet()\n",
        "\n",
        "    for j in range(l):\n",
        "      x = crossPointFrom2Parents(botp1, botp2, j)\n",
        "      if random.random() < mut:\n",
        "        x = net4Mut[j]\n",
        "      newbot.append(x)\n",
        "    newpopul.append(newbot)\n",
        "  \n",
        "  popul = newpopul"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dntweCwkCE2c"
      },
      "source": [
        "## Проверка результатов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MTPC5OpCE2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2917375e-2b5e-4ee8-c48c-6c5bd998376b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 50, 1, 1, 0, 0, 1, 4]\n",
            "[1, 50, 1, 1, 0, 0, 1, 4]\n",
            "[1, 50, 1, 1, 0, 0, 1, 4]\n"
          ]
        }
      ],
      "source": [
        "# Вывод трех лучших ботов\n",
        "for i in range(3):\n",
        "  print(popul[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr_BB_hBCE2d"
      },
      "source": [
        "## Обучение лучшей модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ze8jy_QyCE2d"
      },
      "outputs": [],
      "source": [
        "model = createConvNet(popul[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4y0HkuLCE2e"
      },
      "source": [
        "### Архитектура сети"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhglUhLkCE2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f9dc631-ea3d-4906-9af0-a1e6f1fb499e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1500\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization_1765 (B  (None, 60)               240       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " dense_3000 (Dense)          (None, 2500)              152500    \n",
            "                                                                 \n",
            " batch_normalization_1766 (B  (None, 2500)             10000     \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " dense_3001 (Dense)          (None, 1)                 2501      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 165,241\n",
            "Trainable params: 160,121\n",
            "Non-trainable params: 5,120\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66upI4PkCE2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "bc4704d8-6052-4fee-b7d3-40d443ace322"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "plot_model(model, show_shapes=True, dpi = 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8siGILcOCE2f"
      },
      "source": [
        "# Обучим лучшую архитектуру"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWUbkahGCE2g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c4326bf-7507-4db5-8a16-0135e1ef9154"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "6/6 [==============================] - 2s 102ms/step - loss: 0.0360 - accuracy: 0.9880 - val_loss: 0.4447 - val_accuracy: 0.9048\n",
            "Epoch 2/200\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.4034 - val_accuracy: 0.9048\n",
            "Epoch 3/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0223 - accuracy: 0.9940 - val_loss: 0.3828 - val_accuracy: 0.9048\n",
            "Epoch 4/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0074 - accuracy: 0.9940 - val_loss: 0.3675 - val_accuracy: 0.9048\n",
            "Epoch 5/200\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3607 - val_accuracy: 0.9048\n",
            "Epoch 6/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.0064 - accuracy: 0.9940 - val_loss: 0.3571 - val_accuracy: 0.9048\n",
            "Epoch 7/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 8.5704e-04 - accuracy: 1.0000 - val_loss: 0.3370 - val_accuracy: 0.9048\n",
            "Epoch 8/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0147 - accuracy: 0.9940 - val_loss: 0.3219 - val_accuracy: 0.9048\n",
            "Epoch 9/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3003 - val_accuracy: 0.9048\n",
            "Epoch 10/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0225 - accuracy: 0.9880 - val_loss: 0.2835 - val_accuracy: 0.9286\n",
            "Epoch 11/200\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2587 - val_accuracy: 0.9286\n",
            "Epoch 12/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.0076 - accuracy: 0.9940 - val_loss: 0.2516 - val_accuracy: 0.9286\n",
            "Epoch 13/200\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2474 - val_accuracy: 0.9286\n",
            "Epoch 14/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9286\n",
            "Epoch 15/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.0458 - accuracy: 0.9880 - val_loss: 0.2477 - val_accuracy: 0.9286\n",
            "Epoch 16/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2647 - val_accuracy: 0.9286\n",
            "Epoch 17/200\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 5.4129e-04 - accuracy: 1.0000 - val_loss: 0.2741 - val_accuracy: 0.9048\n",
            "Epoch 18/200\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0714 - accuracy: 0.9940 - val_loss: 0.2756 - val_accuracy: 0.9048\n",
            "Epoch 19/200\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2470 - val_accuracy: 0.9286\n",
            "Epoch 20/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.0770 - accuracy: 0.9880 - val_loss: 0.2396 - val_accuracy: 0.9286\n",
            "Epoch 21/200\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 6.9070e-04 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9286\n",
            "Epoch 22/200\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2496 - val_accuracy: 0.9286\n",
            "Epoch 23/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 0.9048\n",
            "Epoch 24/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 2.7134e-04 - accuracy: 1.0000 - val_loss: 0.2664 - val_accuracy: 0.9048\n",
            "Epoch 25/200\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0115 - accuracy: 0.9940 - val_loss: 0.2649 - val_accuracy: 0.9048\n",
            "Epoch 26/200\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2557 - val_accuracy: 0.9048\n",
            "Epoch 27/200\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2519 - val_accuracy: 0.9048\n",
            "Epoch 28/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2480 - val_accuracy: 0.9048\n",
            "Epoch 29/200\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0122 - accuracy: 0.9940 - val_loss: 0.2418 - val_accuracy: 0.9048\n",
            "Epoch 30/200\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2348 - val_accuracy: 0.9286\n",
            "Epoch 31/200\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0074 - accuracy: 0.9940 - val_loss: 0.2377 - val_accuracy: 0.9048\n",
            "Epoch 32/200\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0367 - accuracy: 0.9880 - val_loss: 0.2499 - val_accuracy: 0.9048\n",
            "Epoch 33/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2468 - val_accuracy: 0.9048\n",
            "Epoch 34/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0115 - accuracy: 0.9940 - val_loss: 0.2402 - val_accuracy: 0.9048\n",
            "Epoch 35/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0349 - accuracy: 0.9880 - val_loss: 0.2232 - val_accuracy: 0.9048\n",
            "Epoch 36/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0200 - accuracy: 0.9880 - val_loss: 0.2059 - val_accuracy: 0.9286\n",
            "Epoch 37/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9286\n",
            "Epoch 38/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1970 - val_accuracy: 0.9286\n",
            "Epoch 39/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1984 - val_accuracy: 0.9286\n",
            "Epoch 40/200\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.1032 - accuracy: 0.9819 - val_loss: 0.1954 - val_accuracy: 0.9286\n",
            "Epoch 41/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.0079 - accuracy: 0.9940 - val_loss: 0.1886 - val_accuracy: 0.9048\n",
            "Epoch 42/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 0.1907 - val_accuracy: 0.9048\n",
            "Epoch 43/200\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9048\n",
            "Epoch 44/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0096 - accuracy: 0.9940 - val_loss: 0.1954 - val_accuracy: 0.9048\n",
            "Epoch 45/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0213 - accuracy: 0.9940 - val_loss: 0.1961 - val_accuracy: 0.9048\n",
            "Epoch 46/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9048\n",
            "Epoch 47/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 0.9286\n",
            "Epoch 48/200\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9286\n",
            "Epoch 49/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.0158 - accuracy: 0.9940 - val_loss: 0.1998 - val_accuracy: 0.9286\n",
            "Epoch 50/200\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0484 - accuracy: 0.9880 - val_loss: 0.2009 - val_accuracy: 0.9286\n",
            "Epoch 51/200\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.2001 - val_accuracy: 0.9286\n",
            "Epoch 52/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 0.9286\n",
            "Epoch 53/200\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9286\n",
            "Epoch 54/200\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 0.9286\n",
            "Epoch 55/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.0688 - accuracy: 0.9880 - val_loss: 0.1952 - val_accuracy: 0.9286\n",
            "Epoch 56/200\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0214 - accuracy: 0.9940 - val_loss: 0.1890 - val_accuracy: 0.9286\n",
            "Epoch 57/200\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0270 - accuracy: 0.9940 - val_loss: 0.1854 - val_accuracy: 0.9524\n",
            "Epoch 58/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9524\n",
            "Epoch 59/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2001 - val_accuracy: 0.9524\n",
            "Epoch 60/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9524\n",
            "Epoch 61/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.2032 - val_accuracy: 0.9524\n",
            "Epoch 62/200\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 0.0089 - accuracy: 0.9940 - val_loss: 0.2010 - val_accuracy: 0.9524\n",
            "Epoch 63/200\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9524\n",
            "Epoch 64/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2008 - val_accuracy: 0.9286\n",
            "Epoch 65/200\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 0.0436 - accuracy: 0.9940 - val_loss: 0.2034 - val_accuracy: 0.9286\n",
            "Epoch 66/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2106 - val_accuracy: 0.9286\n",
            "Epoch 67/200\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.2211 - val_accuracy: 0.9286\n",
            "Epoch 68/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.0532 - accuracy: 0.9880 - val_loss: 0.2181 - val_accuracy: 0.9286\n",
            "Epoch 69/200\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.9286\n",
            "Epoch 70/200\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 3.4746e-04 - accuracy: 1.0000 - val_loss: 0.1988 - val_accuracy: 0.9286\n",
            "Epoch 71/200\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.9524\n",
            "Epoch 72/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.9524\n",
            "Epoch 73/200\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9524\n",
            "Epoch 74/200\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.2065 - val_accuracy: 0.9286\n",
            "Epoch 75/200\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2158 - val_accuracy: 0.9286\n",
            "Epoch 76/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.0164 - accuracy: 0.9940 - val_loss: 0.2186 - val_accuracy: 0.9286\n",
            "Epoch 77/200\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.0267 - accuracy: 0.9940 - val_loss: 0.2284 - val_accuracy: 0.9286\n",
            "Epoch 78/200\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9286\n",
            "Epoch 79/200\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2536 - val_accuracy: 0.9286\n",
            "Epoch 80/200\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.2616 - val_accuracy: 0.9286\n",
            "Epoch 81/200\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 3.9358e-04 - accuracy: 1.0000 - val_loss: 0.2645 - val_accuracy: 0.9286\n",
            "Epoch 82/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.3877e-04 - accuracy: 1.0000 - val_loss: 0.2672 - val_accuracy: 0.9286\n",
            "Epoch 83/200\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2687 - val_accuracy: 0.9286\n",
            "Epoch 84/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 8.4310e-04 - accuracy: 1.0000 - val_loss: 0.2692 - val_accuracy: 0.9286\n",
            "Epoch 85/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.2664 - val_accuracy: 0.9286\n",
            "Epoch 86/200\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 0.0087 - accuracy: 0.9940 - val_loss: 0.2668 - val_accuracy: 0.9286\n",
            "Epoch 87/200\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 3.4073e-04 - accuracy: 1.0000 - val_loss: 0.2609 - val_accuracy: 0.9286\n",
            "Epoch 88/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 9.0793e-04 - accuracy: 1.0000 - val_loss: 0.2599 - val_accuracy: 0.9286\n",
            "Epoch 89/200\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.0107 - accuracy: 0.9940 - val_loss: 0.2499 - val_accuracy: 0.9286\n",
            "Epoch 90/200\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 4.3290e-04 - accuracy: 1.0000 - val_loss: 0.2510 - val_accuracy: 0.9286\n",
            "Epoch 91/200\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2478 - val_accuracy: 0.9286\n",
            "Epoch 92/200\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 5.6781e-04 - accuracy: 1.0000 - val_loss: 0.2468 - val_accuracy: 0.9286\n",
            "Epoch 93/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9286\n",
            "Epoch 94/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 4.9534e-04 - accuracy: 1.0000 - val_loss: 0.2454 - val_accuracy: 0.9286\n",
            "Epoch 95/200\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2498 - val_accuracy: 0.9286\n",
            "Epoch 96/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0498 - accuracy: 0.9940 - val_loss: 0.2489 - val_accuracy: 0.9286\n",
            "Epoch 97/200\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0206 - accuracy: 0.9880 - val_loss: 0.2495 - val_accuracy: 0.9048\n",
            "Epoch 98/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.8810\n",
            "Epoch 99/200\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0615 - accuracy: 0.9940 - val_loss: 0.2432 - val_accuracy: 0.8810\n",
            "Epoch 100/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 3.9004e-04 - accuracy: 1.0000 - val_loss: 0.2492 - val_accuracy: 0.8810\n",
            "Epoch 101/200\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0336 - accuracy: 0.9940 - val_loss: 0.2497 - val_accuracy: 0.8810\n",
            "Epoch 102/200\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0092 - accuracy: 0.9940 - val_loss: 0.2480 - val_accuracy: 0.8810\n",
            "Epoch 103/200\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0160 - accuracy: 0.9940 - val_loss: 0.2507 - val_accuracy: 0.8810\n",
            "Epoch 104/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.2510 - val_accuracy: 0.8571\n",
            "Epoch 105/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.8571\n",
            "Epoch 106/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0074 - accuracy: 0.9940 - val_loss: 0.2465 - val_accuracy: 0.8571\n",
            "Epoch 107/200\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.7250e-04 - accuracy: 1.0000 - val_loss: 0.2451 - val_accuracy: 0.8571\n",
            "Epoch 108/200\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0330 - accuracy: 0.9880 - val_loss: 0.2391 - val_accuracy: 0.8571\n",
            "Epoch 109/200\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0076 - accuracy: 0.9940 - val_loss: 0.2391 - val_accuracy: 0.8571\n",
            "Epoch 110/200\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 7.2003e-04 - accuracy: 1.0000 - val_loss: 0.2468 - val_accuracy: 0.8571\n",
            "Epoch 111/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2562 - val_accuracy: 0.8810\n",
            "Epoch 112/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 0.8810\n",
            "Epoch 113/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2599 - val_accuracy: 0.8810\n",
            "Epoch 114/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 0.2600 - val_accuracy: 0.8810\n",
            "Epoch 115/200\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0099 - accuracy: 0.9940 - val_loss: 0.2630 - val_accuracy: 0.8571\n",
            "Epoch 116/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.8571\n",
            "Epoch 117/200\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2602 - val_accuracy: 0.8571\n",
            "Epoch 118/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 6.8817e-04 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.8571\n",
            "Epoch 119/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.0285 - accuracy: 0.9940 - val_loss: 0.2642 - val_accuracy: 0.8571\n",
            "Epoch 120/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2609 - val_accuracy: 0.8571\n",
            "Epoch 121/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0120 - accuracy: 0.9940 - val_loss: 0.2605 - val_accuracy: 0.8571\n",
            "Epoch 122/200\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 0.8571\n",
            "Epoch 123/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2552 - val_accuracy: 0.8571\n",
            "Epoch 124/200\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.8571\n",
            "Epoch 125/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.0247 - accuracy: 0.9940 - val_loss: 0.2528 - val_accuracy: 0.8571\n",
            "Epoch 126/200\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0081 - accuracy: 0.9940 - val_loss: 0.2654 - val_accuracy: 0.8810\n",
            "Epoch 127/200\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0202 - accuracy: 0.9940 - val_loss: 0.2671 - val_accuracy: 0.8810\n",
            "Epoch 128/200\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0094 - accuracy: 0.9940 - val_loss: 0.2762 - val_accuracy: 0.8810\n",
            "Epoch 129/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0266 - accuracy: 0.9880 - val_loss: 0.2900 - val_accuracy: 0.8810\n",
            "Epoch 130/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0175 - accuracy: 0.9940 - val_loss: 0.2889 - val_accuracy: 0.9048\n",
            "Epoch 131/200\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 6.3213e-04 - accuracy: 1.0000 - val_loss: 0.2673 - val_accuracy: 0.9048\n",
            "Epoch 132/200\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 5.1552e-04 - accuracy: 1.0000 - val_loss: 0.2577 - val_accuracy: 0.9286\n",
            "Epoch 133/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2558 - val_accuracy: 0.9286\n",
            "Epoch 134/200\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 8.0153e-04 - accuracy: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.9048\n",
            "Epoch 135/200\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 2.1921e-04 - accuracy: 1.0000 - val_loss: 0.2524 - val_accuracy: 0.9048\n",
            "Epoch 136/200\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0115 - accuracy: 0.9940 - val_loss: 0.2539 - val_accuracy: 0.9048\n",
            "Epoch 137/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2332 - val_accuracy: 0.8810\n",
            "Epoch 138/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.2225 - val_accuracy: 0.8810\n",
            "Epoch 139/200\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 5.3351e-04 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.8810\n",
            "Epoch 140/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 5.7059e-04 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.8810\n",
            "Epoch 141/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0176 - accuracy: 0.9940 - val_loss: 0.2110 - val_accuracy: 0.8810\n",
            "Epoch 142/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.8810\n",
            "Epoch 143/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 8.9429e-04 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.8571\n",
            "Epoch 144/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 8.1271e-04 - accuracy: 1.0000 - val_loss: 0.2097 - val_accuracy: 0.8571\n",
            "Epoch 145/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.8571\n",
            "Epoch 146/200\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2119 - val_accuracy: 0.8810\n",
            "Epoch 147/200\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 9.6840e-04 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.8810\n",
            "Epoch 148/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2087 - val_accuracy: 0.9048\n",
            "Epoch 149/200\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.9048\n",
            "Epoch 150/200\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0069 - accuracy: 0.9940 - val_loss: 0.2102 - val_accuracy: 0.9048\n",
            "Epoch 151/200\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 9.1123e-04 - accuracy: 1.0000 - val_loss: 0.2145 - val_accuracy: 0.9048\n",
            "Epoch 152/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.9048\n",
            "Epoch 153/200\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0887 - accuracy: 0.9819 - val_loss: 0.2207 - val_accuracy: 0.9048\n",
            "Epoch 154/200\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.9048\n",
            "Epoch 155/200\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2486 - val_accuracy: 0.9048\n",
            "Epoch 156/200\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0673 - accuracy: 0.9880 - val_loss: 0.2482 - val_accuracy: 0.9048\n",
            "Epoch 157/200\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0074 - accuracy: 0.9940 - val_loss: 0.2274 - val_accuracy: 0.8810\n",
            "Epoch 158/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2020 - val_accuracy: 0.8571\n",
            "Epoch 159/200\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1975 - val_accuracy: 0.8571\n",
            "Epoch 160/200\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1947 - val_accuracy: 0.8571\n",
            "Epoch 161/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0142 - accuracy: 0.9940 - val_loss: 0.1909 - val_accuracy: 0.8810\n",
            "Epoch 162/200\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0408 - accuracy: 0.9940 - val_loss: 0.1865 - val_accuracy: 0.8810\n",
            "Epoch 163/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1947 - val_accuracy: 0.9048\n",
            "Epoch 164/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.2046 - val_accuracy: 0.9048\n",
            "Epoch 165/200\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2050 - val_accuracy: 0.9286\n",
            "Epoch 166/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2047 - val_accuracy: 0.9286\n",
            "Epoch 167/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0356 - accuracy: 0.9880 - val_loss: 0.1996 - val_accuracy: 0.9048\n",
            "Epoch 168/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0288 - accuracy: 0.9940 - val_loss: 0.1940 - val_accuracy: 0.9048\n",
            "Epoch 169/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1825 - val_accuracy: 0.9048\n",
            "Epoch 170/200\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1737 - val_accuracy: 0.9048\n",
            "Epoch 171/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1732 - val_accuracy: 0.9048\n",
            "Epoch 172/200\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1693 - val_accuracy: 0.9048\n",
            "Epoch 173/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.1680 - val_accuracy: 0.9048\n",
            "Epoch 174/200\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 5.9749e-04 - accuracy: 1.0000 - val_loss: 0.1634 - val_accuracy: 0.9048\n",
            "Epoch 175/200\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1604 - val_accuracy: 0.9048\n",
            "Epoch 176/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1605 - val_accuracy: 0.9048\n",
            "Epoch 177/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.0196 - accuracy: 0.9940 - val_loss: 0.1633 - val_accuracy: 0.9048\n",
            "Epoch 178/200\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1612 - val_accuracy: 0.9048\n",
            "Epoch 179/200\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1643 - val_accuracy: 0.9048\n",
            "Epoch 180/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1692 - val_accuracy: 0.9048\n",
            "Epoch 181/200\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1745 - val_accuracy: 0.9048\n",
            "Epoch 182/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1752 - val_accuracy: 0.8810\n",
            "Epoch 183/200\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1754 - val_accuracy: 0.8810\n",
            "Epoch 184/200\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 0.8810\n",
            "Epoch 185/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1774 - val_accuracy: 0.8810\n",
            "Epoch 186/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.0681 - accuracy: 0.9940 - val_loss: 0.1841 - val_accuracy: 0.8810\n",
            "Epoch 187/200\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 5.4624e-04 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.8810\n",
            "Epoch 188/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0320 - accuracy: 0.9940 - val_loss: 0.2036 - val_accuracy: 0.8810\n",
            "Epoch 189/200\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2083 - val_accuracy: 0.8571\n",
            "Epoch 190/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.8571\n",
            "Epoch 191/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2208 - val_accuracy: 0.8571\n",
            "Epoch 192/200\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2255 - val_accuracy: 0.8810\n",
            "Epoch 193/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.8810\n",
            "Epoch 194/200\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.8810\n",
            "Epoch 195/200\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0179 - accuracy: 0.9940 - val_loss: 0.2315 - val_accuracy: 0.8571\n",
            "Epoch 196/200\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0087 - accuracy: 0.9940 - val_loss: 0.2110 - val_accuracy: 0.8810\n",
            "Epoch 197/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2105 - val_accuracy: 0.8810\n",
            "Epoch 198/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2108 - val_accuracy: 0.8810\n",
            "Epoch 199/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.8810\n",
            "Epoch 200/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.8810\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=1e-4), metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, epochs=200, validation_data=(x_test ,y_test), verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Максимальная точность: {round(max(history.history['val_accuracy']) * 100, 2)} %\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZwZjP-l2J3P",
        "outputId": "a879487f-5f4c-465b-c6f5-f5e84c006226"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Максимальная точность: 95.24 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Выводы:"
      ],
      "metadata": {
        "id": "G5umHjYIzR7b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Для решения данного задания была выбрана довольно простая задача. Для того чтобы проводить множество различных экспериментов по времени. \n",
        "2. Использование **Генетических алгоритмов** поможет находить оптимальную архитектуру и гиперпараметры для конкретной задачи.\n",
        "3. На каждый вариант уходило много времени на обучение. \n",
        "4. Если увеличивать популяцию, то время обучения увеличивается пропорционально. Но тогда добавляется большая вариативность, и остаются в качестве родителей лучшие особи.\n",
        "5. Проделовая это вручную без **ГА**, можно потратить больше времени.\n",
        "6. Как видно из экспериментов для решения данной задачи не требуется сложная архитектура. Довольно простая нейронная сеть дает результат не хуже, чем сеть с большим количеством слоев.\n",
        "7. Так же с помощью **ГА** можно подбирать оптимальные гиперпараметры. \n",
        "8. Данная дамашняя работа помогает разобраться с построением **Генетических алгоритмов** для обучения нейронных сетей, что в дальнейшем очень пригодиться. "
      ],
      "metadata": {
        "id": "klo82cEhzUI9"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Теплов М.Н. - Ultra Pro- Генетические алгоритмы для обучения нейронных сетей",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}