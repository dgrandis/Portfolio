{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Теплов - Lite - Обработка текстов с помощью нейросетей.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cATy17YxtqEA"
      },
      "source": [
        "Задание **Lite**\r\n",
        "\r\n",
        "Выполните задания, по каждому варианту напишите точность распознавания на проверочной выборке и сделайте выводы (тексты писателей).\r\n",
        "\r\n",
        "А. Запустите нейронку c bag of words (01) при разных maxWordsCount\r\n",
        "\r\n",
        "1. 100\r\n",
        "2. 1000\r\n",
        "3. 10000\r\n",
        "4. 50000\r\n",
        "\r\n",
        "Б. Запустите нейронку c bag of words (01) при maxWordsCount = 20000 и разных архитектурах\r\n",
        "\r\n",
        "1. Поменяйте количество нейронов в слоях\r\n",
        "2. Поменяйте количество слоев\r\n",
        "3. Поменяйте активационные функции слоев\r\n",
        "\r\n",
        "В. Запустите нейронку c Embbedding при maxWordsCount = 50000, поменяйте размер Embedding пространства\r\n",
        "\r\n",
        "1. 10\r\n",
        "2. 50\r\n",
        "3. 200"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-GQT24B4qPQ"
      },
      "source": [
        "# Подключение библиотек "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNvBtaWGtdXg"
      },
      "source": [
        "# Для начала работы подключим все необходимые библиотеки\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dropout, Dense, SpatialDropout1D, BatchNormalization, Flatten, Embedding, Activation\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from tensorflow.keras import utils\r\n",
        "from google.colab import drive\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import time\r\n",
        "from google.colab import files\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "%matplotlib inline\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkGGagPu4I-y"
      },
      "source": [
        "# Объявим все необходимые функции"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuKTe6hZCmJH"
      },
      "source": [
        "# Создадим функцию для первоначальной обработки файла\r\n",
        "def readText(fileName):\r\n",
        "  op = open(fileName, 'r')        # Указываем что открытие будет в режиме чтения\r\n",
        "  text = op.read()                # Читаем файл с текстом\r\n",
        "  text = text.replace(\"\\n\", \" \")  # Заменям переносы строк на пробелы\r\n",
        "  return text                     # Возвращаем измененный файл"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3075MhUNxRj2"
      },
      "source": [
        "# Для начала создадим функции. \r\n",
        "# Первая для разделения на короткие векторы с заданным шагом и размером\r\n",
        "\r\n",
        "def getSetFromIndexes (wordIndexes, xLen, step):     # В качестве аргументов принимает (trainWordIndexes или testWordIndexes - список, размер и шаг) \r\n",
        "  xSample = []                                        # Созадим пустой спискок для хранения векторов\r\n",
        "  wordsLen = len(wordIndexes)                         # Кол-во слов в поданных на вход trainWordIndexes или testWordIndexes\r\n",
        "  index = 0                                           # Начальный индекс (с помощью этой переменной будем сдвигать шаг)\r\n",
        "\r\n",
        "\r\n",
        "  while (index + xLen <= wordsLen):                   # Задаем цикл пока не дойдем до конца    \r\n",
        "    xSample.append(wordIndexes[index:index + xLen])   # На каждой итерации добавляем в список кусок вектора заданной длины\r\n",
        "    index += step                                     # Смещаемся на шаг\r\n",
        "\r\n",
        "  return xSample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeUE6RwDxZJg"
      },
      "source": [
        "# Вторая функция для формирования обучающей и проверочной выборок\r\n",
        "\r\n",
        "def createSetsMultiClasses(wordIndexes, xLen, step):\r\n",
        "  nClasses = len(wordIndexes)                            # Зададим кол-во классов выборки\r\n",
        "  classesXSample = []                                    # Создадим пустой список в котором будут храниться список нарезанных кусочков предыдущей функцией getSetFromIndexes\r\n",
        "\r\n",
        "  # Пройдемся циклом по каждому тексту выборки из последовательнстей индексов\r\n",
        "  for i in wordIndexes:\r\n",
        "    classesXSample.append(getSetFromIndexes(i, xLen, step))\r\n",
        "  \r\n",
        "  # Сформируем один общий список\r\n",
        "  xSamples = []                                           # Создаем пустые списки\r\n",
        "  ySamples = []\r\n",
        "\r\n",
        "  for t in range(nClasses):                               # В нашем случаи цикл от 0 до 6 (кол-во классов)\r\n",
        "    xT = classesXSample[t]                                # На каждой итерации цикла берем очередной нарезанный текст одного из класса\r\n",
        "\r\n",
        "    for i in range (len(xT)):                             # Циклом проходимся по каждому его окну\r\n",
        "      xSamples.append(xT[i])                              # Добавляем в общий список обучающей выборке\r\n",
        "      ySamples.append(utils.to_categorical(t, nClasses))  # И соответствующий вектор класса\r\n",
        "  \r\n",
        "  # Переводим в numpy массив\r\n",
        "  xSamples = np.array(xSamples)                           \r\n",
        "  ySamples = np.array(ySamples)    \r\n",
        "\r\n",
        "  # B возвращаем выборки\r\n",
        "  return (xSamples, ySamples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mndi_l1HoShQ"
      },
      "source": [
        "# Создадим функцию которая будет представлять выборку в удобном для распознавания размерах\r\n",
        "\r\n",
        "def createTestMultiClasses(wordIndexes, xLen, step):\r\n",
        "\r\n",
        "  # Создаем тестовую выборку из индексов для каждого из 6 классов\r\n",
        "  nClasses = len(wordIndexes)                                             # Переменной nClasses присвоим кол-во классов\r\n",
        "  xTest6ClassesBow = []                                                   # Создадим пустой список, в котором будут список из всех классов\r\n",
        "  xTest6Classec = []                                                      # Создадим список массивов\r\n",
        "\r\n",
        "  # Пройдемся циклом по каждому тестовому тексту из последовательности индексов\r\n",
        "  for i in wordIndexes:\r\n",
        "    sample = (getSetFromIndexes(i,xLen, step))                            # Воспользуемся ранее написанной функцией для нарезки на векторы\r\n",
        "    xTest6Classec.append(sample)                                          # Добавляем в список на каждой итерации \r\n",
        "    xTest6ClassesBow.append(tokenizer.sequences_to_matrix(sample))        # Трансформируем в BOW\r\n",
        "  \r\n",
        "  xTest6ClassesBow = np.array(xTest6ClassesBow)                           # Переводим в numpy массив\r\n",
        "  xTest6Classec = np.array(xTest6Classec)                                 # Переводим в numpy массив\r\n",
        "\r\n",
        "  return xTest6ClassesBow, xTest6Classec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzKrKxi9Wmfd"
      },
      "source": [
        "# Создадим еще одну функцию которая будет распознавать тестовую выборку и выводить результаты\r\n",
        "def recognizerMultiClass (model, xTest, modelName):\r\n",
        "  #print (\"Название нейронной сети: \", modelName)        # Для наглядности выведем название сети\r\n",
        "  #print ()                                              # Пропустим стороку\r\n",
        "  totalSumRec = 0                                       # Создадим счетчик суммы правильных ответов\r\n",
        "\r\n",
        "  # Пройдемся циклом по всем классам\r\n",
        "  for i in range(nClasses):                             # От 0 до 6 \r\n",
        "    currPred = model.predict(xTest[i])                  # Получим результаты распознования класса по блокам слов длинны xLen.\r\n",
        "    currOut = np.argmax(currPred, axis=1)               # Определим номер распознанного класса с помощью функции argmax\r\n",
        "    evVal = []\r\n",
        "    \r\n",
        "    for j in range(nClasses):\r\n",
        "      evVal.append(len(currOut[currOut==j])/len(xTest[i]))\r\n",
        "\r\n",
        "    totalSumRec +=len(currOut[currOut==i])\r\n",
        "    recognizedClass = np.argmax(evVal)                  # Определяем какой класс за какой был распознан в итоге\r\n",
        "\r\n",
        "    # И выводим результаты\r\n",
        "\r\n",
        "    isRecognized = \"Ответ НЕВЕРНЫЙ, УВЫ\"\r\n",
        "    if (recognizedClass == i):\r\n",
        "      isRecognized = \"УРА, ответ ВЕРНЫЙ!\"\r\n",
        "    \r\n",
        "    str1 = 'Класс: ' + className[i] + \" \" * (11 - len(className[i])) + str(int(100*evVal[i])) + \"% сеть предсказала: \" + className[recognizedClass]\r\n",
        "    print(str1, \" \" * (55-len(str1)), isRecognized, sep='')\r\n",
        "\r\n",
        "  # Выведим средний процент распознавания \r\n",
        "  print ()                                                                          # Пустая строка чтобы отделить\r\n",
        "  sumCount = 0\r\n",
        "  # Пройдемся циклом по всем циклам\r\n",
        "  for i in range(nClasses):\r\n",
        "    sumCount += len(xTest[i])\r\n",
        "  print (\"Средний процент распознавания \", int(100*totalSumRec/sumCount), \"%\")\r\n",
        "  print ()                                                                          # Пустая строка чтобы отделить\r\n",
        "\r\n",
        "  return totalSumRec/sumCount"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfih5mcLD6-r"
      },
      "source": [
        "# Подготовка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm_Lqah8RGLc"
      },
      "source": [
        "# Объявим классы. Запишем в список\r\n",
        "className = [\"О. Генри\", \"Стругацкие\", \"Булгаков\", \"Саймак\", \"Фрай\", \"Брэдберри\"]\r\n",
        "\r\n",
        "# Подсчитаем кол-во нужных нам классов\r\n",
        "nClasses = len(className)\r\n",
        "\r\n",
        "# Создадим 2 пустых списка (обучающий и проверочный), для последующего заполнения\r\n",
        "trainText = []\r\n",
        "testText = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wt4Qv238WXbd",
        "outputId": "da479edb-a7e8-4678-9140-7d7244c5f649"
      },
      "source": [
        "# Пройдемся двумя циклами для заполнения списков. Так чтобы каждый i элемент в обучающей выборке соответствовал j элементу в тестовой.\r\n",
        "\r\n",
        "for i in className:\r\n",
        "  for j in os.listdir('/content/'):                     \r\n",
        "    if i in j:                                       \r\n",
        "      if 'Обучающая' in j:                           \r\n",
        "        trainText.append(readText('/content/' +j))      \r\n",
        "        print (j, 'добавлен в обучающую выборку')    \r\n",
        "      if 'Тестовая' in j:                            \r\n",
        "        testText.append(readText('/content/' +j))       \r\n",
        "        print (j, 'добавлен в тестовую выборку')     "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(О. Генри) Обучающая_50 вместе.txt добавлен в обучающую выборку\n",
            "(О. Генри) Тестовая_20 вместе.txt добавлен в тестовую выборку\n",
            "(Стругацкие) Тестовая_2 вместе.txt добавлен в тестовую выборку\n",
            "(Стругацкие) Обучающая_5 вместе.txt добавлен в обучающую выборку\n",
            "(Булгаков) Тестовая_2 вместе.txt добавлен в тестовую выборку\n",
            "(Булгаков) Обучающая_5 вместе.txt добавлен в обучающую выборку\n",
            "(Клиффорд_Саймак) Обучающая_5 вместе.txt добавлен в обучающую выборку\n",
            "(Клиффорд_Саймак) Тестовая_2 вместе.txt добавлен в тестовую выборку\n",
            "(Макс Фрай) Обучающая_5 вместе.txt добавлен в обучающую выборку\n",
            "(Макс Фрай) Тестовая_2 вместе.txt добавлен в тестовую выборку\n",
            "(Рэй Брэдберри) Обучающая_22 вместе.txt добавлен в обучающую выборку\n",
            "(Рэй Брэдберри) Тестовая_8 вместе.txt добавлен в тестовую выборку\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4K9FkJ-erlG"
      },
      "source": [
        "# Создадим таблицу [Значения maxWordsCount, Число нейроново в слое Dense, Значение в слое Dropout, Активационная функция в первом слое Dense, Кол-во эпох, размер batch_size, Ошибки, Точность ]\r\n",
        "df = pd.DataFrame(columns = ['Модель','Кол-во слоев','maxWordsCount','Dense', 'Dropout', 'activation', 'epochs', 'batch_size', 'learn_loss', 'learn_accuracy', 'val_loss', 'val_accuracy', 'Средний процент распознавания на проверочной выборке'])\r\n",
        "\r\n",
        "count = 0            # счетчик для строк таблицы pandas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpmWiQ41Hjmq"
      },
      "source": [
        "# Зададим значения которые будут неизменными во всем ноутбуке.\r\n",
        "\r\n",
        "xLen = 1000                                  # Длина отрезка текста на которые будет разбивать функция getSetFromIndexes\r\n",
        "step = 100                                   # Шаг разбивания для той же функции\r\n",
        "epochs = 15                                  # Количество эпох\r\n",
        "batch_size = 150                             # Размер batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SVi8toJM1Zd"
      },
      "source": [
        "# Задание А. Запустите нейронку c bag of words при разных maxWordsCount = 100, 1000, 10000, 50000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AHFh1qZ5fdI"
      },
      "source": [
        "В этом задании меняется лишь один параметр, а все остальное остается одно и тоже. \r\n",
        "\r\n",
        "Чтобы понимать как изменения значения maxWordsCount влияет на обучаемость сети, остальные гиперпараметры нейронной сети изменяться не будут.\r\n",
        "\r\n",
        "Для того чтобы 4 раза не переписывать подготовительные данные и нейронную сеть создадим цикл. Который будет перебирать значения maxWordsCount и в конце предоставит сравнительную таблицу."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txGvTmvsTIE3"
      },
      "source": [
        "# Зададим параметры неронной сети. Чтобы проходить в цикле и использовать в pandas таблице.\r\n",
        "# При желании можно быстро менять здесь значения и смотреть на результат обучения. \r\n",
        "\r\n",
        "maxWordsCount = [100, 1000, 10000, 25000]    # Создадим список чтобы проходиться по нему в цикле\r\n",
        "\r\n",
        "dense_num = 300                              # Число нейронов в первом Dense слое\r\n",
        "drop_num = 0.4                               # Значение в слое Dropout\r\n",
        "activ = 'relu'                               # Активационная функция в первом слое Dense\r\n",
        "\r\n",
        "hidden_layers = 2                            # Количество скрытых слоев, переменная нужна для записи в таблицу pandas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffz-wz-wOLwd"
      },
      "source": [
        "Параметр **verbose** установлен в **0**. Чтобы не было длинного вывода. Так как важны только крайние значения, которые будут предоставлены в сравнительной таблице."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGuKedTnfyhl"
      },
      "source": [
        "При установке значения **maxWordsCount** равным 50000, 40000, 30000 происходит переполнение памяти в ноутбуке. Придется проведить тест с крайним значениев в **25000**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSKyeNN5M58p"
      },
      "source": [
        "for i in maxWordsCount:\r\n",
        "\r\n",
        "  \r\n",
        "  tokenizer = Tokenizer(num_words = i, filters = '!\"#$%&()*+,-–—./…:;<=>?@[\\\\]^_`{|}~«»\\t\\n\\xa0\\ufeff', lower=True, split=' ', oov_token ='unknow', char_level = False)\r\n",
        "  tokenizer.fit_on_texts(trainText)   \r\n",
        "  items = list(tokenizer.word_index.items())\r\n",
        "\r\n",
        "  # Согласно частотному словарю можно преобразовать текст в последовательность индексов\r\n",
        "  trainWordIndexes = tokenizer.texts_to_sequences(trainText)\r\n",
        "  testWordIndexes = tokenizer.texts_to_sequences(testText)   \r\n",
        "\r\n",
        "  # Установим базовые параметры\r\n",
        "\r\n",
        "  # Сформируем выборки (обучающую и тестовую)\r\n",
        "  xTrain, yTrain = createSetsMultiClasses(trainWordIndexes, xLen, step)\r\n",
        "  xTest, yTest = createSetsMultiClasses(testWordIndexes, xLen, step)\r\n",
        "\r\n",
        "  # Преобразовываем в матрицы нулей и единиц по принципу BOW. xTrain и yTrain подаем в виду списка. \r\n",
        "  xTrainBOW = tokenizer.sequences_to_matrix(xTrain.tolist())      \r\n",
        "  xTestBOW = tokenizer.sequences_to_matrix(xTest.tolist()) \r\n",
        "\r\n",
        "  # Создадим полносвязную сеть\r\n",
        "  modelBow = Sequential()\r\n",
        "  modelBow.add(Dense(dense_num, input_dim=i, activation = activ))   \r\n",
        "  modelBow.add(Dropout(drop_num))\r\n",
        "  modelBow.add(BatchNormalization())\r\n",
        "  modelBow.add(Dense(6, activation ='softmax'))\r\n",
        "\r\n",
        "  # Скомпилируем ее\r\n",
        "  modelBow.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "  # Обучаем сеть на выборке, xTrainBOW\r\n",
        "  history = modelBow.fit(xTrainBOW, yTrain, epochs=epochs, batch_size=batch_size, validation_data=(xTestBOW, yTest), verbose=0)\r\n",
        "\r\n",
        "  # Создаем пустой словарь. \r\n",
        "  dct = []  \r\n",
        "  # В цикле проходимся по всем значениям из history                                                  \r\n",
        "  for v in history.history.values():                                        \r\n",
        "    dct.append (v)                                            # Результат выгружаются в словарь.                                                                \r\n",
        "  result = np.array(dct)                                      # Переводим в numpy массив.\r\n",
        "\r\n",
        "  # Распознавание проверочной выборки\r\n",
        "\r\n",
        "  # Преобразуем тестовую выборку\r\n",
        "  xTest6ClassesBow, x2 = createTestMultiClasses(testWordIndexes, xLen, step)\r\n",
        "\r\n",
        "  # Проверим точность сети на BOW\r\n",
        "  pred = recognizerMultiClass (modelBow, xTest6ClassesBow, \"BOW: Dense-DropOut-BatchNormalization-Dense\")\r\n",
        "\r\n",
        "  # Формируем строчку в DataFrame.\r\n",
        "  # В строке будет: Значения maxWordsCount, кол-во нейронов в Dense слое, размер batch_size, loss и accuracy во всех трех выборках \r\n",
        "\r\n",
        "  df.loc[count] = ['Bag of Words', hidden_layers, i, dense_num, drop_num , activ, epochs, batch_size, round(result[0][-1],2), round(result[1][-1]*100,2), round(result[2][-1],2), round(result[3][-1]*100,2), round(pred*100,2)]\r\n",
        "  count += 1\r\n",
        "\r\n",
        "  # Сохраним веса\r\n",
        "  modelBow.save_weights(f'modelBow[{i}] - loss: {round(result[0][-1],2)} - accuracy: {round(result[1][-1]*100,2)} - val_loss: {round(result[2][-1],2)} - val_accuracy: {round(pred*100,2)}.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "0JfI17wLJG5y",
        "outputId": "87e5fda8-5d00-4f8e-e782-da90d5da4c85"
      },
      "source": [
        " df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Модель</th>\n",
              "      <th>Кол-во слоев</th>\n",
              "      <th>maxWordsCount</th>\n",
              "      <th>Dense</th>\n",
              "      <th>Dropout</th>\n",
              "      <th>activation</th>\n",
              "      <th>epochs</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>learn_loss</th>\n",
              "      <th>learn_accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>Средний процент распознавания на проверочной выборке</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>300</td>\n",
              "      <td>0.4</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.37</td>\n",
              "      <td>86.58</td>\n",
              "      <td>1.76</td>\n",
              "      <td>51.11</td>\n",
              "      <td>51.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>1000</td>\n",
              "      <td>300</td>\n",
              "      <td>0.4</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>84.10</td>\n",
              "      <td>84.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>10000</td>\n",
              "      <td>300</td>\n",
              "      <td>0.4</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.34</td>\n",
              "      <td>88.02</td>\n",
              "      <td>88.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>25000</td>\n",
              "      <td>300</td>\n",
              "      <td>0.4</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.29</td>\n",
              "      <td>90.65</td>\n",
              "      <td>90.65</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Модель  ... Средний процент распознавания на проверочной выборке\n",
              "0  Bag of Words  ...                                              51.11  \n",
              "1  Bag of Words  ...                                              84.10  \n",
              "2  Bag of Words  ...                                              88.02  \n",
              "3  Bag of Words  ...                                              90.65  \n",
              "\n",
              "[4 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dRTbI49WUeH"
      },
      "source": [
        "# Б. Запустите нейронку c bag of words (01) при maxWordsCount = 20000 и разных архитектурах\r\n",
        "\r\n",
        "1. Поменяйте количество нейронов в слоях\r\n",
        "2. Поменяйте количество слоев\r\n",
        "3. Поменяйте активационные функции слоев"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vit9XdiOjh4"
      },
      "source": [
        "maxWordsCount =  20000                          # Задаем значение в 20000, как требуется в задании Б."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOCYxDxlhkRx"
      },
      "source": [
        "## Б. 1. Поменяйте количество нейронов в слоях"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnbWthtjnDgV"
      },
      "source": [
        "В данной задаче будет 2 цикла. Так как менять значения нейронов будем в первом Dense слое, а так же кол-во нейронов, которые будут отключаться в слое Dropout.\r\n",
        "\r\n",
        "Всего будет 36 вариантов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n655pbiNhrMm"
      },
      "source": [
        "dense_num = [10, 50, 100, 200, 600, 1000]       # Список нейронов в первом слое Dense\r\n",
        "drop_num =  [0.1, 0.15, 0.2, 0.25, 0.35, 0.4]   # Список значение в слое Dropout\r\n",
        "activ = 'relu'                                  # Активационная функция в первом слое Dense\r\n",
        "\r\n",
        "hidden_layers = 2                               # Количество скрытых слоев, переменная нужна для записи в таблицу pandas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlYy8Ju0hrMr"
      },
      "source": [
        "for i in dense_num:\r\n",
        "  for j in drop_num:\r\n",
        "    tokenizer = Tokenizer(num_words = i, filters = '!\"#$%&()*+,-–—./…:;<=>?@[\\\\]^_`{|}~«»\\t\\n\\xa0\\ufeff', lower=True, split=' ', oov_token ='unknow', char_level = False)\r\n",
        "    tokenizer.fit_on_texts(trainText)   \r\n",
        "    items = list(tokenizer.word_index.items())\r\n",
        "\r\n",
        "    trainWordIndexes = tokenizer.texts_to_sequences(trainText)\r\n",
        "    testWordIndexes = tokenizer.texts_to_sequences(testText)   \r\n",
        "\r\n",
        "    # Установим базовые параметры\r\n",
        "\r\n",
        "    # Сформируем выборки (обучающую и тестовую)\r\n",
        "    xTrain, yTrain = createSetsMultiClasses(trainWordIndexes, xLen, step)\r\n",
        "    xTest, yTest = createSetsMultiClasses(testWordIndexes, xLen, step)\r\n",
        "\r\n",
        "    # Преобразовываем в матрицы нулей и единиц по принципу BOW. xTrain и yTrain подаем в виду списка. \r\n",
        "    xTrainBOW = tokenizer.sequences_to_matrix(xTrain.tolist())      \r\n",
        "    xTestBOW = tokenizer.sequences_to_matrix(xTest.tolist()) \r\n",
        "\r\n",
        "    # Создадим полносвязную сеть\r\n",
        "    modelBow = Sequential()\r\n",
        "    modelBow.add(Dense(i, input_dim=i, activation = activ))   \r\n",
        "    modelBow.add(Dropout(j))\r\n",
        "    modelBow.add(BatchNormalization())\r\n",
        "    modelBow.add(Dense(6, activation ='softmax'))\r\n",
        "\r\n",
        "    # Скомпилируем ее\r\n",
        "    modelBow.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "    # Обучаем сеть на выборке, xTrainBOW\r\n",
        "    history = modelBow.fit(xTrainBOW, yTrain, epochs=epochs, batch_size=batch_size, validation_data=(xTestBOW, yTest), verbose=0)\r\n",
        "\r\n",
        "    # Создаем пустой словарь. \r\n",
        "    dct = []  \r\n",
        "    # В цикле проходимся по всем значениям из history                                                  \r\n",
        "    for v in history.history.values():                                        \r\n",
        "      dct.append (v)                                            # Результат выгружаются в словарь.                                                                \r\n",
        "    result = np.array(dct)                                      # Переводим в numpy массив.\r\n",
        "\r\n",
        "    # Распознавание проверочной выборки\r\n",
        "\r\n",
        "    # Преобразуем тестовую выборку\r\n",
        "    xTest6ClassesBow, x2 = createTestMultiClasses(testWordIndexes, xLen, step)\r\n",
        "\r\n",
        "    # Проверим точность сети на BOW\r\n",
        "    pred = recognizerMultiClass (modelBow, xTest6ClassesBow, \"BOW: Dense-DropOut-BatchNormalization-Dense\")\r\n",
        "\r\n",
        "    # Формируем строчку в DataFrame.\r\n",
        "    # В строке будет: Значения maxWordsCount, кол-во нейронов в Dense слое, размер batch_size, loss и accuracy во всех трех выборках \r\n",
        "\r\n",
        "    df.loc[count] = ['Bag of Words', hidden_layers, maxWordsCount, i, j , activ, epochs, batch_size, round(result[0][-1],2), round(result[1][-1]*100,2), round(result[2][-1],2), round(result[3][-1]*100,2), round(pred*100,2)]\r\n",
        "    count += 1\r\n",
        "\r\n",
        "    # Сохраним веса\r\n",
        "    modelBow.save_weights(f'modelBow[{i,j}] - loss: {round(result[0][-1],2)} - accuracy: {round(result[1][-1]*100,2)} - val_loss: {round(result[2][-1],2)} - val_accuracy: {round(pred*100,2)}.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "qEytSf2Npl6P",
        "outputId": "6029ab5f-4055-4795-aa28-70cd26e04e9b"
      },
      "source": [
        "# Посмотрим на часть таблицы. Так как она стала длиннее\r\n",
        "df[-5:] "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Модель</th>\n",
              "      <th>Кол-во слоев</th>\n",
              "      <th>maxWordsCount</th>\n",
              "      <th>Dense</th>\n",
              "      <th>Dropout</th>\n",
              "      <th>activation</th>\n",
              "      <th>epochs</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>learn_loss</th>\n",
              "      <th>learn_accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>Средний процент распознавания на проверочной выборке</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.15</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.56</td>\n",
              "      <td>84.28</td>\n",
              "      <td>84.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.2</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.51</td>\n",
              "      <td>84.92</td>\n",
              "      <td>84.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.25</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.53</td>\n",
              "      <td>84.55</td>\n",
              "      <td>84.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.35</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.52</td>\n",
              "      <td>84.19</td>\n",
              "      <td>84.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.4</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.49</td>\n",
              "      <td>85.30</td>\n",
              "      <td>85.30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Модель  ... Средний процент распознавания на проверочной выборке\n",
              "38  Bag of Words  ...                                              84.28  \n",
              "39  Bag of Words  ...                                              84.92  \n",
              "40  Bag of Words  ...                                              84.55  \n",
              "41  Bag of Words  ...                                              84.19  \n",
              "42  Bag of Words  ...                                              85.30  \n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMO8rTNCqtmd"
      },
      "source": [
        "## Б. 2. Поменяйте количество слоев"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATas1xPVqw8d"
      },
      "source": [
        "Добавим еще скрытых слоев. Посмотрим на результаты предыдущих обучений, чтобы установить лучшие гиперпараметры. Протестируем сеть и добавим данные в таблицу.\r\n",
        " \r\n",
        "По прежнему maxWordsCount = 20000."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk5btT3mrIPF"
      },
      "source": [
        "dense_num_1 = 300                                # Кол-во нейронов в первом слое Dense\r\n",
        "dense_num_2 = 600                                # Кол-во нейронов во втором слое Dense\r\n",
        "\r\n",
        "drop_num_1 =  0.3                               # Значение в первом  Dropout слое\r\n",
        "drop_num_2 =  0.4                               # Значение во втором  Dropout слое\r\n",
        "\r\n",
        "activ = 'relu'                                  # Активационная функция в первом слое Dense\r\n",
        "\r\n",
        "hidden_layers = 5                               # Количество скрытых слоев, переменная нужна для записи в таблицу pandas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdUh36nfi-q2"
      },
      "source": [
        "tokenizer = Tokenizer(num_words = maxWordsCount, filters = '!\"#$%&()*+,-–—./…:;<=>?@[\\\\]^_`{|}~«»\\t\\n\\xa0\\ufeff', lower=True, split=' ', oov_token ='unknow', char_level = False)\r\n",
        "tokenizer.fit_on_texts(trainText)   \r\n",
        "items = list(tokenizer.word_index.items())\r\n",
        "\r\n",
        "trainWordIndexes = tokenizer.texts_to_sequences(trainText)\r\n",
        "testWordIndexes = tokenizer.texts_to_sequences(testText)   \r\n",
        "\r\n",
        "# Сформируем выборки (обучающую и тестовую)\r\n",
        "xTrain, yTrain = createSetsMultiClasses(trainWordIndexes, xLen, step)\r\n",
        "xTest, yTest = createSetsMultiClasses(testWordIndexes, xLen, step)\r\n",
        "\r\n",
        "# Преобразовываем в матрицы нулей и единиц по принципу BOW. xTrain и yTrain подаем в виду списка. \r\n",
        "xTrainBOW = tokenizer.sequences_to_matrix(xTrain.tolist())      \r\n",
        "xTestBOW = tokenizer.sequences_to_matrix(xTest.tolist()) \r\n",
        "\r\n",
        "# Создадим полносвязную сеть\r\n",
        "modelBow = Sequential()\r\n",
        "\r\n",
        "modelBow.add(Dense(dense_num_1, input_dim=maxWordsCount, activation = activ))   \r\n",
        "modelBow.add(Dropout(drop_num_1))\r\n",
        "modelBow.add(BatchNormalization())\r\n",
        "\r\n",
        "modelBow.add(Dense(dense_num_2, input_dim=maxWordsCount, activation = activ))   \r\n",
        "modelBow.add(Dropout(drop_num_2))\r\n",
        "modelBow.add(BatchNormalization())\r\n",
        "\r\n",
        "modelBow.add(Dense(6, activation ='softmax'))\r\n",
        "\r\n",
        "# Скомпилируем ее\r\n",
        "modelBow.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "# Обучаем сеть на выборке, xTrainBOW\r\n",
        "history = modelBow.fit(xTrainBOW, yTrain, epochs=epochs, batch_size=batch_size, validation_data=(xTestBOW, yTest), verbose=0)\r\n",
        "\r\n",
        "# Создаем пустой словарь. \r\n",
        "dct = []  \r\n",
        "# В цикле проходимся по всем значениям из history                                                  \r\n",
        "for v in history.history.values():                                        \r\n",
        "  dct.append (v)                                            # Результат выгружаются в словарь.                                                                \r\n",
        "result = np.array(dct)                                      # Переводим в numpy массив.\r\n",
        "\r\n",
        "# Распознавание проверочной выборки\r\n",
        "\r\n",
        "# Преобразуем тестовую выборку\r\n",
        "xTest6ClassesBow, x2 = createTestMultiClasses(testWordIndexes, xLen, step)\r\n",
        "\r\n",
        "# Проверим точность сети на BOW\r\n",
        "pred = recognizerMultiClass (modelBow, xTest6ClassesBow, \"BOW: Dense-DropOut-BatchNormalization-Dense\")\r\n",
        "\r\n",
        "# Формируем строчку в DataFrame.\r\n",
        "# В строке будет: Значения maxWordsCount, кол-во нейронов в Dense слое, размер batch_size, loss и accuracy во всех трех выборках \r\n",
        "\r\n",
        "df.loc[count] = ['Bag of Words', hidden_layers, i, f'{dense_num_1}-{dense_num_2}', f'{drop_num_1}-{drop_num_2}' , activ, epochs, batch_size, round(result[0][-1],2), round(result[1][-1]*100,2), round(result[2][-1],2), round(result[3][-1]*100,2), round(pred*100,2)]\r\n",
        "count += 1\r\n",
        "\r\n",
        "# Сохраним веса\r\n",
        "modelBow.save_weights(f'modelBow[{i}] - loss: {round(result[0][-1],2)} - accuracy: {round(result[1][-1]*100,2)} - val_loss: {round(result[2][-1],2)} - val_accuracy: {round(pred*100,2)}.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "pRACyCqquTzp",
        "outputId": "03df2a0c-09c6-44de-f986-2ae38a64e276"
      },
      "source": [
        "df[-5:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Модель</th>\n",
              "      <th>Кол-во слоев</th>\n",
              "      <th>maxWordsCount</th>\n",
              "      <th>Dense</th>\n",
              "      <th>Dropout</th>\n",
              "      <th>activation</th>\n",
              "      <th>epochs</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>learn_loss</th>\n",
              "      <th>learn_accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>Средний процент распознавания на проверочной выборке</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.2</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.51</td>\n",
              "      <td>84.92</td>\n",
              "      <td>84.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.25</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.53</td>\n",
              "      <td>84.55</td>\n",
              "      <td>84.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.35</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.52</td>\n",
              "      <td>84.19</td>\n",
              "      <td>84.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.4</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.49</td>\n",
              "      <td>85.30</td>\n",
              "      <td>85.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>5</td>\n",
              "      <td>1000</td>\n",
              "      <td>300-600</td>\n",
              "      <td>0.3-0.4</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.36</td>\n",
              "      <td>88.60</td>\n",
              "      <td>88.60</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Модель  ... Средний процент распознавания на проверочной выборке\n",
              "39  Bag of Words  ...                                              84.92  \n",
              "40  Bag of Words  ...                                              84.55  \n",
              "41  Bag of Words  ...                                              84.19  \n",
              "42  Bag of Words  ...                                              85.30  \n",
              "43  Bag of Words  ...                                              88.60  \n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOJbGBueuxmj"
      },
      "source": [
        "**Добавим еще скрытых слоев**.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuQ-Szs4vXtQ"
      },
      "source": [
        "dense_num_1 = 300                                # Кол-во нейронов в первом слое Dense\r\n",
        "dense_num_2 = 600                                # Кол-во нейронов во втором слое Dense\r\n",
        "dense_num_3 = 900                                # Кол-во нейронов во втором слое Dense\r\n",
        "\r\n",
        "drop_num_1 =  0.2                                # Значение в первом  Dropout слое\r\n",
        "drop_num_2 =  0.3                                # Значение во втором  Dropout слое\r\n",
        "drop_num_3 =  0.4                                # Значение во втором  Dropout слое\r\n",
        "\r\n",
        "activ = 'relu'                                   # Активационная функция в первом слое Dense\r\n",
        "\r\n",
        "layers = 8                                       # Количество скрытый слоев, переменная нужна для таблицы"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkEUqfCcu6ax"
      },
      "source": [
        "tokenizer = Tokenizer(num_words = maxWordsCount, filters = '!\"#$%&()*+,-–—./…:;<=>?@[\\\\]^_`{|}~«»\\t\\n\\xa0\\ufeff', lower=True, split=' ', oov_token ='unknow', char_level = False)\r\n",
        "tokenizer.fit_on_texts(trainText)   \r\n",
        "items = list(tokenizer.word_index.items())\r\n",
        "\r\n",
        "trainWordIndexes = tokenizer.texts_to_sequences(trainText)\r\n",
        "testWordIndexes = tokenizer.texts_to_sequences(testText)   \r\n",
        "\r\n",
        "# Установим базовые параметры\r\n",
        "\r\n",
        "# Сформируем выборки (обучающую и тестовую)\r\n",
        "xTrain, yTrain = createSetsMultiClasses(trainWordIndexes, xLen, step)\r\n",
        "xTest, yTest = createSetsMultiClasses(testWordIndexes, xLen, step)\r\n",
        "\r\n",
        "# Преобразовываем в матрицы нулей и единиц по принципу BOW. xTrain и yTrain подаем в виду списка. \r\n",
        "xTrainBOW = tokenizer.sequences_to_matrix(xTrain.tolist())      \r\n",
        "xTestBOW = tokenizer.sequences_to_matrix(xTest.tolist()) \r\n",
        "\r\n",
        "# Создадим полносвязную сеть\r\n",
        "modelBow = Sequential()\r\n",
        "modelBow.add(Dense(dense_num_1, input_dim=maxWordsCount, activation = activ))   \r\n",
        "modelBow.add(Dropout(drop_num_1))\r\n",
        "modelBow.add(BatchNormalization())\r\n",
        "\r\n",
        "modelBow.add(Dense(dense_num_2, input_dim=i, activation = activ))   \r\n",
        "modelBow.add(Dropout(drop_num_2))\r\n",
        "modelBow.add(BatchNormalization())\r\n",
        "\r\n",
        "modelBow.add(Dense(dense_num_3, input_dim=i, activation = activ))   \r\n",
        "modelBow.add(Dropout(drop_num_3))\r\n",
        "modelBow.add(BatchNormalization())\r\n",
        "\r\n",
        "modelBow.add(Dense(6, activation ='softmax'))\r\n",
        "\r\n",
        "# Скомпилируем ее\r\n",
        "modelBow.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "# Обучаем сеть на выборке, xTrainBOW\r\n",
        "history = modelBow.fit(xTrainBOW, yTrain, epochs=epochs, batch_size=batch_size, validation_data=(xTestBOW, yTest), verbose=0)\r\n",
        "\r\n",
        "# Создаем пустой словарь. \r\n",
        "dct = []  \r\n",
        "# В цикле проходимся по всем значениям из history                                                  \r\n",
        "for v in history.history.values():                                        \r\n",
        "  dct.append (v)                                            # Результат выгружаются в словарь.                                                                \r\n",
        "result = np.array(dct)                                      # Переводим в numpy массив.\r\n",
        "\r\n",
        "# Распознавание проверочной выборки\r\n",
        "\r\n",
        "# Преобразуем тестовую выборку\r\n",
        "xTest6ClassesBow, x2 = createTestMultiClasses(testWordIndexes, xLen, step)\r\n",
        "\r\n",
        "# Проверим точность сети на BOW\r\n",
        "pred = recognizerMultiClass (modelBow, xTest6ClassesBow, \"BOW: Dense-DropOut-BatchNormalization-Dense\")\r\n",
        "\r\n",
        "# Формируем строчку в DataFrame.\r\n",
        "\r\n",
        "df.loc[count] = ['Bag of Words', hidden_layers, i, f'{dense_num_1}-{dense_num_2}-{dense_num_3}', f'{drop_num_1}-{drop_num_2}-{drop_num_3}' , activ, epochs, batch_size, round(result[0][-1],2), round(result[1][-1]*100,2), round(result[2][-1],2), round(result[3][-1]*100,2), round(pred*100,2)]\r\n",
        "count += 1\r\n",
        "\r\n",
        "\r\n",
        "# Сохраним веса\r\n",
        "modelBow.save_weights(f'modelBow[layers = 5] - loss: {round(result[0][-1],2)} - accuracy: {round(result[1][-1]*100,2)} - val_loss: {round(result[2][-1],2)} - val_accuracy: {round(pred*100,2)}.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "OeT6daZ1wmSn",
        "outputId": "25beab6c-dcb3-468d-b2ad-2d03ef6a2381"
      },
      "source": [
        "df[-5:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Модель</th>\n",
              "      <th>Кол-во слоев</th>\n",
              "      <th>maxWordsCount</th>\n",
              "      <th>Dense</th>\n",
              "      <th>Dropout</th>\n",
              "      <th>activation</th>\n",
              "      <th>epochs</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>learn_loss</th>\n",
              "      <th>learn_accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>Средний процент распознавания на проверочной выборке</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.25</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.53</td>\n",
              "      <td>84.55</td>\n",
              "      <td>84.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.35</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.52</td>\n",
              "      <td>84.19</td>\n",
              "      <td>84.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.4</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.49</td>\n",
              "      <td>85.30</td>\n",
              "      <td>85.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>5</td>\n",
              "      <td>1000</td>\n",
              "      <td>300-600</td>\n",
              "      <td>0.3-0.4</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.36</td>\n",
              "      <td>88.60</td>\n",
              "      <td>88.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>5</td>\n",
              "      <td>1000</td>\n",
              "      <td>300-600-900</td>\n",
              "      <td>0.2-0.3-0.4</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.42</td>\n",
              "      <td>87.27</td>\n",
              "      <td>87.27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Модель  ... Средний процент распознавания на проверочной выборке\n",
              "40  Bag of Words  ...                                              84.55  \n",
              "41  Bag of Words  ...                                              84.19  \n",
              "42  Bag of Words  ...                                              85.30  \n",
              "43  Bag of Words  ...                                              88.60  \n",
              "44  Bag of Words  ...                                              87.27  \n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KrOvYcNz0-N"
      },
      "source": [
        "## Б. 3. Поменяйте активационные функции слоев"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7yB7Mko7nLu"
      },
      "source": [
        "Для первого примера в этом задании возьмем изначальную сеть с 2мя скрытыми слоями и будем менять активационые функции в первом Dense слое используя цикл. \r\n",
        "\r\n",
        "Остальные гиперпараметры сделаем такими же, чтобы посмотреть как повлияет только изменение активационной функции:\r\n",
        "\r\n",
        "- Кол-во нейронов в Dense слое 300\r\n",
        "- Dropout 0.4\r\n",
        "- Была функция 'relu'. Будем перебирать 'linear', 'softmax', 'sigmoid', 'softplus', 'tanh'.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1_pDhJy7ltP"
      },
      "source": [
        "dense_num_1 = 300                                             # Кол-во нейронов в первом слое Dense\r\n",
        "drop_num_1 = 0.4                                              # Значение в слое Dropout\r\n",
        "\r\n",
        "activ = ['linear','softmax','softplus', 'sigmoid','tanh']     # Активационная функция в первом слое Dense  'softmax', 'linear','sigmoid',\r\n",
        "\r\n",
        "hidden_layers = 2                                             # Количество скрытый слоев, переменная нужна для таблицы"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty-r9hjNHjAg"
      },
      "source": [
        "for i in activ:\r\n",
        "\r\n",
        "  tokenizer = Tokenizer(num_words = maxWordsCount, filters = '!\"#$%&()*+,-–—./…:;<=>?@[\\\\]^_`{|}~«»\\t\\n\\xa0\\ufeff', lower=True, split=' ', oov_token ='unknow', char_level = False)\r\n",
        "  tokenizer.fit_on_texts(trainText)   \r\n",
        "  items = list(tokenizer.word_index.items())\r\n",
        "\r\n",
        "  trainWordIndexes = tokenizer.texts_to_sequences(trainText)\r\n",
        "  testWordIndexes = tokenizer.texts_to_sequences(testText)   \r\n",
        "\r\n",
        "  # Установим базовые параметры\r\n",
        "\r\n",
        "  # Сформируем выборки (обучающую и тестовую)\r\n",
        "  xTrain, yTrain = createSetsMultiClasses(trainWordIndexes, xLen, step)\r\n",
        "  xTest, yTest = createSetsMultiClasses(testWordIndexes, xLen, step)\r\n",
        "\r\n",
        "  # Преобразовываем в матрицы нулей и единиц по принципу BOW. xTrain и yTrain подаем в виду списка. \r\n",
        "  xTrainBOW = tokenizer.sequences_to_matrix(xTrain.tolist())      \r\n",
        "  xTestBOW = tokenizer.sequences_to_matrix(xTest.tolist()) \r\n",
        "\r\n",
        "  # Создадим полносвязную сеть\r\n",
        "  modelBow = Sequential()\r\n",
        "  modelBow.add(Dense(dense_num_1, input_dim=maxWordsCount, activation = i))   \r\n",
        "  modelBow.add(Dropout(drop_num_1))\r\n",
        "  modelBow.add(BatchNormalization())\r\n",
        "  modelBow.add(Dense(6, activation ='softmax'))\r\n",
        "\r\n",
        "  # Скомпилируем ее\r\n",
        "  modelBow.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "  # Обучаем сеть на выборке, xTrainBOW\r\n",
        "  history = modelBow.fit(xTrainBOW, yTrain, epochs=epochs, batch_size=batch_size, validation_data=(xTestBOW, yTest), verbose=0)\r\n",
        "\r\n",
        "  # Создаем пустой словарь. \r\n",
        "  dct = []  \r\n",
        "  # В цикле проходимся по всем значениям из history                                                  \r\n",
        "  for v in history.history.values():                                        \r\n",
        "    dct.append (v)                                            # Результат выгружаются в словарь.                                                                \r\n",
        "  result = np.array(dct)                                      # Переводим в numpy массив.\r\n",
        "\r\n",
        "  # Распознавание проверочной выборки\r\n",
        "\r\n",
        "  # Преобразуем тестовую выборку\r\n",
        "  xTest6ClassesBow, x2 = createTestMultiClasses(testWordIndexes, xLen, step)\r\n",
        "\r\n",
        "  # Проверим точность сети на BOW\r\n",
        "  pred = recognizerMultiClass (modelBow, xTest6ClassesBow, \"BOW: Dense-DropOut-BatchNormalization-Dense\")\r\n",
        "\r\n",
        "  # Формируем строчку в DataFrame.\r\n",
        "  # В строке будет: Значения maxWordsCount, кол-во нейронов в Dense слое, размер batch_size, loss и accuracy во всех трех выборках \r\n",
        "\r\n",
        "  df.loc[count] = ['Bag of Words', hidden_layers, maxWordsCount, dense_num_1, drop_num_1 , i, epochs, batch_size, round(result[0][-1],2), round(result[1][-1]*100,2), round(result[2][-1],2), round(result[3][-1]*100,2), round(pred*100,2)]\r\n",
        "  count += 1\r\n",
        "\r\n",
        "  # Сохраним веса\r\n",
        "  modelBow.save_weights(f'modelBow[{i}] - loss: {round(result[0][-1],2)} - accuracy: {round(result[1][-1]*100,2)} - val_loss: {round(result[2][-1],2)} - val_accuracy: {round(pred*100,2)}.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "Onz7C_vEPKMf",
        "outputId": "05d71cc0-e871-4ae2-b77b-1235260dcaa4"
      },
      "source": [
        "df[-5:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Модель</th>\n",
              "      <th>Кол-во слоев</th>\n",
              "      <th>maxWordsCount</th>\n",
              "      <th>Dense</th>\n",
              "      <th>Dropout</th>\n",
              "      <th>activation</th>\n",
              "      <th>epochs</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>learn_loss</th>\n",
              "      <th>learn_accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>Средний процент распознавания на проверочной выборке</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>300</td>\n",
              "      <td>0.4</td>\n",
              "      <td>linear</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.35</td>\n",
              "      <td>88.45</td>\n",
              "      <td>88.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>300</td>\n",
              "      <td>0.4</td>\n",
              "      <td>softmax</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.09</td>\n",
              "      <td>97.42</td>\n",
              "      <td>0.51</td>\n",
              "      <td>83.11</td>\n",
              "      <td>83.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>300</td>\n",
              "      <td>0.4</td>\n",
              "      <td>softplus</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.28</td>\n",
              "      <td>90.68</td>\n",
              "      <td>90.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>300</td>\n",
              "      <td>0.4</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.27</td>\n",
              "      <td>92.22</td>\n",
              "      <td>92.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>300</td>\n",
              "      <td>0.4</td>\n",
              "      <td>tanh</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.34</td>\n",
              "      <td>88.59</td>\n",
              "      <td>88.59</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Модель  ... Средний процент распознавания на проверочной выборке\n",
              "45  Bag of Words  ...                                              88.45  \n",
              "46  Bag of Words  ...                                              83.11  \n",
              "47  Bag of Words  ...                                              90.68  \n",
              "48  Bag of Words  ...                                              92.22  \n",
              "49  Bag of Words  ...                                              88.59  \n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLsW4yARPT7X"
      },
      "source": [
        "**Проверим какие показатели будут у сети, если добавить еще слоев как предыдущем задании и поменять активационные функции**. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TTv2EYEPoVG"
      },
      "source": [
        "dense_num_1 = 300                                            # Кол-во нейронов в первом слое Dense\r\n",
        "dense_num_2 = 600                                            # Кол-во нейронов во втором слое Dense\r\n",
        "\r\n",
        "drop_num_1 =  0.3                                            # Значение в первом  Dropout слое\r\n",
        "drop_num_2 =  0.4                                            # Значение во втором  Dropout слое\r\n",
        "\r\n",
        "activ = ['linear','softmax','softplus', 'sigmoid','tanh']    # Активационная функция в первом слое Dense\r\n",
        "                                               \r\n",
        "hidden_layers = 5                                            # Количество скрытых слоев, переменная нужна для записи в таблицу pandas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZBSQ2oZP4ER"
      },
      "source": [
        "for i in activ:\r\n",
        "\r\n",
        "  tokenizer = Tokenizer(num_words = maxWordsCount, filters = '!\"#$%&()*+,-–—./…:;<=>?@[\\\\]^_`{|}~«»\\t\\n\\xa0\\ufeff', lower=True, split=' ', oov_token ='unknow', char_level = False)\r\n",
        "  tokenizer.fit_on_texts(trainText)   \r\n",
        "  items = list(tokenizer.word_index.items())\r\n",
        "\r\n",
        "  trainWordIndexes = tokenizer.texts_to_sequences(trainText)\r\n",
        "  testWordIndexes = tokenizer.texts_to_sequences(testText)   \r\n",
        "\r\n",
        "  # Установим базовые параметры\r\n",
        "\r\n",
        "  # Сформируем выборки (обучающую и тестовую)\r\n",
        "  xTrain, yTrain = createSetsMultiClasses(trainWordIndexes, xLen, step)\r\n",
        "  xTest, yTest = createSetsMultiClasses(testWordIndexes, xLen, step)\r\n",
        "\r\n",
        "  # Преобразовываем в матрицы нулей и единиц по принципу BOW. xTrain и yTrain подаем в виду списка. \r\n",
        "  xTrainBOW = tokenizer.sequences_to_matrix(xTrain.tolist())      \r\n",
        "  xTestBOW = tokenizer.sequences_to_matrix(xTest.tolist()) \r\n",
        "\r\n",
        "  # Создадим полносвязную сеть\r\n",
        "  modelBow = Sequential()\r\n",
        "\r\n",
        "  modelBow.add(Dense(dense_num_1, input_dim=maxWordsCount, activation = i))   \r\n",
        "  modelBow.add(Dropout(drop_num_1))\r\n",
        "  modelBow.add(BatchNormalization())\r\n",
        "\r\n",
        "  modelBow.add(Dense(dense_num_2, input_dim=maxWordsCount, activation = i))   \r\n",
        "  modelBow.add(Dropout(drop_num_2))\r\n",
        "  modelBow.add(BatchNormalization())\r\n",
        "\r\n",
        "  modelBow.add(Dense(6, activation ='softmax'))\r\n",
        "\r\n",
        "  # Скомпилируем ее\r\n",
        "  modelBow.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "  # Обучаем сеть на выборке, xTrainBOW\r\n",
        "  history = modelBow.fit(xTrainBOW, yTrain, epochs=epochs, batch_size=batch_size, validation_data=(xTestBOW, yTest), verbose=0)\r\n",
        "\r\n",
        "  # Создаем пустой словарь. \r\n",
        "  dct = []  \r\n",
        "  # В цикле проходимся по всем значениям из history                                                  \r\n",
        "  for v in history.history.values():                                        \r\n",
        "    dct.append (v)                                            # Результат выгружаются в словарь.                                                                \r\n",
        "  result = np.array(dct)                                      # Переводим в numpy массив.\r\n",
        "\r\n",
        "  # Распознавание проверочной выборки\r\n",
        "\r\n",
        "  # Преобразуем тестовую выборку\r\n",
        "  xTest6ClassesBow, x2 = createTestMultiClasses(testWordIndexes, xLen, step)\r\n",
        "\r\n",
        "  # Проверим точность сети на BOW\r\n",
        "  pred = recognizerMultiClass (modelBow, xTest6ClassesBow, \"BOW: Dense-DropOut-BatchNormalization-Dense\")\r\n",
        "\r\n",
        "  df.loc[count] = ['Bag of Words', hidden_layers, maxWordsCount, f'{dense_num_1}-{dense_num_2}', f'{drop_num_1}-{drop_num_2}', i, epochs, batch_size, round(result[0][-1],2), round(result[1][-1]*100,2), round(result[2][-1],2), round(result[3][-1]*100,2), round(pred*100,2)]\r\n",
        "  count += 1\r\n",
        "\r\n",
        "  # Сохраним веса\r\n",
        "  modelBow.save_weights(f'modelBow[{i}] - loss: {round(result[0][-1],2)} - accuracy: {round(result[1][-1]*100,2)} - val_loss: {round(result[2][-1],2)} - val_accuracy: {round(pred*100,2)}.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "YkCDiQEsVwN2",
        "outputId": "96f58c56-d249-4025-b095-f1b3effe62d2"
      },
      "source": [
        "df[-5:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Модель</th>\n",
              "      <th>Кол-во слоев</th>\n",
              "      <th>maxWordsCount</th>\n",
              "      <th>Dense</th>\n",
              "      <th>Dropout</th>\n",
              "      <th>activation</th>\n",
              "      <th>epochs</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>learn_loss</th>\n",
              "      <th>learn_accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>Средний процент распознавания на проверочной выборке</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>5</td>\n",
              "      <td>20000</td>\n",
              "      <td>300-600</td>\n",
              "      <td>0.3-0.4</td>\n",
              "      <td>linear</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.29</td>\n",
              "      <td>90.31</td>\n",
              "      <td>90.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>5</td>\n",
              "      <td>20000</td>\n",
              "      <td>300-600</td>\n",
              "      <td>0.3-0.4</td>\n",
              "      <td>softmax</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.08</td>\n",
              "      <td>97.02</td>\n",
              "      <td>1.85</td>\n",
              "      <td>71.31</td>\n",
              "      <td>71.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>5</td>\n",
              "      <td>20000</td>\n",
              "      <td>300-600</td>\n",
              "      <td>0.3-0.4</td>\n",
              "      <td>softplus</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.27</td>\n",
              "      <td>91.38</td>\n",
              "      <td>91.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>5</td>\n",
              "      <td>20000</td>\n",
              "      <td>300-600</td>\n",
              "      <td>0.3-0.4</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.29</td>\n",
              "      <td>90.62</td>\n",
              "      <td>90.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>5</td>\n",
              "      <td>20000</td>\n",
              "      <td>300-600</td>\n",
              "      <td>0.3-0.4</td>\n",
              "      <td>tanh</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.39</td>\n",
              "      <td>88.77</td>\n",
              "      <td>88.77</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Модель  ... Средний процент распознавания на проверочной выборке\n",
              "50  Bag of Words  ...                                              90.31  \n",
              "51  Bag of Words  ...                                              71.31  \n",
              "52  Bag of Words  ...                                              91.38  \n",
              "53  Bag of Words  ...                                              90.62  \n",
              "54  Bag of Words  ...                                              88.77  \n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jphGSD8-Jvp"
      },
      "source": [
        "# В. Запустите нейронку c Embbedding при maxWordsCount = 50000, поменяйте размер Embedding пространства:\r\n",
        "# 1. 10\r\n",
        "# 2. 50\r\n",
        "# 3. 200"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HegVvIWL-bpb"
      },
      "source": [
        "## Данные параметры будем перебирать в цикле, чтобы не было много строчек кода. \r\n",
        "   Параметр maxWordsCount пришлось установить равным **25000**. Если поставить **50000**, то идет переполнение памяти и ноутбук перезагружается.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZCdICtt-2W_"
      },
      "source": [
        "emb_space = [10,50,200]                         # Создадим список для изменения Embbedding пространства\r\n",
        "\r\n",
        "maxWordsCount =  25000                        \r\n",
        "           \r\n",
        "dense_num_1 = 500                               # Кол-во нейронов в первом слое Dense\r\n",
        "spat_drop_out = 0.2                             # Значение в слое SpatialDropout1D\r\n",
        "drop_out_1 =  0.3                               # Значение в первом  Dropout слое\r\n",
        "\r\n",
        "activ = 'relu'                                  # Активационная функция в первом слое Dense\r\n",
        "                                                \r\n",
        "hidden_layers = 6                               # Количество скрытых слоев, переменная нужна для записи в таблицу pandas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0vFnANxpAC9"
      },
      "source": [
        "for i in emb_space:\r\n",
        "\r\n",
        "  tokenizer = Tokenizer(num_words = maxWordsCount, filters = '!\"#$%&()*+,-–—./…:;<=>?@[\\\\]^_`{|}~«»\\t\\n\\xa0\\ufeff', lower=True, split=' ', oov_token ='unknow', char_level = False)\r\n",
        "  tokenizer.fit_on_texts(trainText)   \r\n",
        "  items = list(tokenizer.word_index.items())\r\n",
        "\r\n",
        "  trainWordIndexes = tokenizer.texts_to_sequences(trainText)\r\n",
        "  testWordIndexes = tokenizer.texts_to_sequences(testText)   \r\n",
        "\r\n",
        "  # Установим базовые параметры\r\n",
        "\r\n",
        "  # Сформируем выборки (обучающую и тестовую)\r\n",
        "  xTrain, yTrain = createSetsMultiClasses(trainWordIndexes, xLen, step)\r\n",
        "  xTest, yTest = createSetsMultiClasses(testWordIndexes, xLen, step)\r\n",
        "\r\n",
        "  # Преобразовываем в матрицы нулей и единиц по принципу BOW. xTrain и yTrain подаем в виду списка. \r\n",
        "  xTrainBOW = tokenizer.sequences_to_matrix(xTrain.tolist())      \r\n",
        "  xTestBOW = tokenizer.sequences_to_matrix(xTest.tolist()) \r\n",
        "\r\n",
        "\r\n",
        "  # Создаем нейронную сеть со слоем Embedding  и activation='softmax'\r\n",
        "  modelEmb = Sequential()\r\n",
        "\r\n",
        "  modelEmb.add(Embedding(maxWordsCount, i, input_length=xLen))       # maxWordsCount = 30000\r\n",
        "  modelEmb.add(SpatialDropout1D(spat_drop_out))\r\n",
        "\r\n",
        "  modelEmb.add(Flatten())\r\n",
        "  modelEmb.add(BatchNormalization())\r\n",
        "\r\n",
        "  modelEmb.add(Dense(dense_num_1, activation = activ))\r\n",
        "  modelEmb.add(Dropout(drop_out_1))\r\n",
        "  modelEmb.add(BatchNormalization())\r\n",
        "\r\n",
        "  modelEmb.add(Dense(6,activation='softmax'))\r\n",
        "\r\n",
        "  # Скомпилируем данную сеть\r\n",
        "  modelEmb.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "  # Обучим сеть на обучающей выборке xTrain\r\n",
        "  history = modelEmb.fit(xTrain, yTrain, epochs=1, batch_size=150, validation_data=(xTest, yTest), verbose=0)\r\n",
        "\r\n",
        "  # Создаем пустой словарь. \r\n",
        "  dct = []  \r\n",
        "  # В цикле проходимся по всем значениям из history                                                  \r\n",
        "  for v in history.history.values():                                        \r\n",
        "    dct.append (v)                                            # Результат выгружаются в словарь.                                                                \r\n",
        "  result = np.array(dct)                                      # Переводим в numpy массив.\r\n",
        "\r\n",
        "  # Проверим результаты Embedding сети\r\n",
        "\r\n",
        "  # Преобразуем тестовую выборку\r\n",
        "  _, xtest6Classes = createTestMultiClasses(testWordIndexes, xLen, step)\r\n",
        "\r\n",
        "  pred = recognizerMultiClass (modelEmb, xtest6Classes, \"Embedding\")\r\n",
        "\r\n",
        "  df.loc[count] = [f'Embbedding - {i}', hidden_layers, maxWordsCount, dense_num_1, f'{spat_drop_out }-{drop_out_1}', activ, epochs, batch_size, round(result[0][-1],2), round(result[1][-1]*100,2), round(result[2][-1],2), round(result[3][-1]*100,2), round(pred*100,2)]\r\n",
        "  count += 1\r\n",
        "\r\n",
        "  # Сохраним веса\r\n",
        "  modelEmb.save_weights(f'Embbedding[{i}] - loss: {round(result[0][-1],2)} - accuracy: {round(result[1][-1]*100,2)} - val_loss: {round(result[2][-1],2)} - val_accuracy: {round(pred*100,2)}.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "INVLbi-EIjEG",
        "outputId": "f4fe8fd8-fa00-4129-93fe-53ba269d2519"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Модель</th>\n",
              "      <th>Кол-во слоев</th>\n",
              "      <th>maxWordsCount</th>\n",
              "      <th>Dense</th>\n",
              "      <th>Dropout</th>\n",
              "      <th>activation</th>\n",
              "      <th>epochs</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>learn_loss</th>\n",
              "      <th>learn_accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>Средний процент распознавания на проверочной выборке</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Embbedding - 10</td>\n",
              "      <td>6</td>\n",
              "      <td>25000</td>\n",
              "      <td>500</td>\n",
              "      <td>0.2-0.3</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>1.06</td>\n",
              "      <td>66.88</td>\n",
              "      <td>1.59</td>\n",
              "      <td>30.08</td>\n",
              "      <td>30.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Embbedding - 50</td>\n",
              "      <td>6</td>\n",
              "      <td>25000</td>\n",
              "      <td>500</td>\n",
              "      <td>0.2-0.3</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.78</td>\n",
              "      <td>79.15</td>\n",
              "      <td>1.97</td>\n",
              "      <td>19.32</td>\n",
              "      <td>19.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Embbedding - 200</td>\n",
              "      <td>6</td>\n",
              "      <td>25000</td>\n",
              "      <td>500</td>\n",
              "      <td>0.2-0.3</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.73</td>\n",
              "      <td>82.56</td>\n",
              "      <td>1.76</td>\n",
              "      <td>39.72</td>\n",
              "      <td>39.72</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Модель  ... Средний процент распознавания на проверочной выборке\n",
              "0   Embbedding - 10  ...                                              30.08  \n",
              "1   Embbedding - 50  ...                                              19.32  \n",
              "2  Embbedding - 200  ...                                              39.72  \n",
              "\n",
              "[3 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTT43vjHHW2g"
      },
      "source": [
        "# Так как таблица получилась слишком большая и найти в ней нужные нам данные будет сложно, посмотрим на топ 5 лучших и худших результатов. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RboG8GgC1EPa"
      },
      "source": [
        "Последнее задание с Embbedding запускал в самом начале, так как на его исполнение требовалось больше памяти. И если запускать его в конце, то идет переполнение памяти и ноутбук перезагружается. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iecXAnZvX2cs",
        "outputId": "bd0587be-bad2-43f0-da5d-f10653dbb1b9"
      },
      "source": [
        "# Общая таблица\r\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Модель</th>\n",
              "      <th>Кол-во слоев</th>\n",
              "      <th>maxWordsCount</th>\n",
              "      <th>Dense</th>\n",
              "      <th>Dropout</th>\n",
              "      <th>activation</th>\n",
              "      <th>epochs</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>learn_loss</th>\n",
              "      <th>learn_accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>Средний процент распознавания на проверочной выборке</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Embbedding - 10</td>\n",
              "      <td>6</td>\n",
              "      <td>25000</td>\n",
              "      <td>500</td>\n",
              "      <td>0.2-0.3</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>1.06</td>\n",
              "      <td>66.88</td>\n",
              "      <td>1.59</td>\n",
              "      <td>30.08</td>\n",
              "      <td>30.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Embbedding - 50</td>\n",
              "      <td>6</td>\n",
              "      <td>25000</td>\n",
              "      <td>500</td>\n",
              "      <td>0.2-0.3</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.78</td>\n",
              "      <td>79.15</td>\n",
              "      <td>1.97</td>\n",
              "      <td>19.32</td>\n",
              "      <td>19.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Embbedding - 200</td>\n",
              "      <td>6</td>\n",
              "      <td>25000</td>\n",
              "      <td>500</td>\n",
              "      <td>0.2-0.3</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.73</td>\n",
              "      <td>82.56</td>\n",
              "      <td>1.76</td>\n",
              "      <td>39.72</td>\n",
              "      <td>39.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>300</td>\n",
              "      <td>0.4</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.37</td>\n",
              "      <td>86.67</td>\n",
              "      <td>1.92</td>\n",
              "      <td>49.90</td>\n",
              "      <td>49.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>1000</td>\n",
              "      <td>300</td>\n",
              "      <td>0.4</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.47</td>\n",
              "      <td>85.15</td>\n",
              "      <td>85.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>10000</td>\n",
              "      <td>300</td>\n",
              "      <td>0.4</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>88.44</td>\n",
              "      <td>88.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>25000</td>\n",
              "      <td>300</td>\n",
              "      <td>0.4</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.33</td>\n",
              "      <td>88.96</td>\n",
              "      <td>88.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.1</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>1.67</td>\n",
              "      <td>33.93</td>\n",
              "      <td>1.76</td>\n",
              "      <td>29.51</td>\n",
              "      <td>29.51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.15</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>1.68</td>\n",
              "      <td>34.08</td>\n",
              "      <td>1.75</td>\n",
              "      <td>29.60</td>\n",
              "      <td>29.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.2</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>1.68</td>\n",
              "      <td>33.78</td>\n",
              "      <td>1.74</td>\n",
              "      <td>29.60</td>\n",
              "      <td>29.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.25</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>1.68</td>\n",
              "      <td>34.05</td>\n",
              "      <td>1.74</td>\n",
              "      <td>29.60</td>\n",
              "      <td>29.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.35</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>1.68</td>\n",
              "      <td>33.49</td>\n",
              "      <td>1.74</td>\n",
              "      <td>29.45</td>\n",
              "      <td>29.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.4</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>1.68</td>\n",
              "      <td>34.01</td>\n",
              "      <td>1.75</td>\n",
              "      <td>29.45</td>\n",
              "      <td>29.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>50</td>\n",
              "      <td>0.1</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>1.15</td>\n",
              "      <td>56.35</td>\n",
              "      <td>1.65</td>\n",
              "      <td>40.55</td>\n",
              "      <td>40.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>50</td>\n",
              "      <td>0.15</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>1.17</td>\n",
              "      <td>56.10</td>\n",
              "      <td>1.62</td>\n",
              "      <td>41.22</td>\n",
              "      <td>41.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>50</td>\n",
              "      <td>0.2</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>1.17</td>\n",
              "      <td>55.81</td>\n",
              "      <td>1.74</td>\n",
              "      <td>39.78</td>\n",
              "      <td>39.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>1.17</td>\n",
              "      <td>55.77</td>\n",
              "      <td>1.66</td>\n",
              "      <td>41.01</td>\n",
              "      <td>41.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>50</td>\n",
              "      <td>0.35</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>1.23</td>\n",
              "      <td>53.79</td>\n",
              "      <td>1.60</td>\n",
              "      <td>41.53</td>\n",
              "      <td>41.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>50</td>\n",
              "      <td>0.4</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>1.27</td>\n",
              "      <td>51.90</td>\n",
              "      <td>1.60</td>\n",
              "      <td>40.89</td>\n",
              "      <td>40.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>100</td>\n",
              "      <td>0.1</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.37</td>\n",
              "      <td>86.80</td>\n",
              "      <td>1.76</td>\n",
              "      <td>49.99</td>\n",
              "      <td>49.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>100</td>\n",
              "      <td>0.15</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.40</td>\n",
              "      <td>85.65</td>\n",
              "      <td>1.81</td>\n",
              "      <td>49.87</td>\n",
              "      <td>49.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>100</td>\n",
              "      <td>0.2</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.46</td>\n",
              "      <td>83.50</td>\n",
              "      <td>1.69</td>\n",
              "      <td>49.90</td>\n",
              "      <td>49.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>100</td>\n",
              "      <td>0.25</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.48</td>\n",
              "      <td>82.69</td>\n",
              "      <td>1.64</td>\n",
              "      <td>51.08</td>\n",
              "      <td>51.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>100</td>\n",
              "      <td>0.35</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.58</td>\n",
              "      <td>78.85</td>\n",
              "      <td>1.53</td>\n",
              "      <td>49.30</td>\n",
              "      <td>49.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>100</td>\n",
              "      <td>0.4</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.62</td>\n",
              "      <td>77.28</td>\n",
              "      <td>1.49</td>\n",
              "      <td>50.39</td>\n",
              "      <td>50.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>200</td>\n",
              "      <td>0.1</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.01</td>\n",
              "      <td>99.94</td>\n",
              "      <td>1.67</td>\n",
              "      <td>64.48</td>\n",
              "      <td>64.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>200</td>\n",
              "      <td>0.15</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.01</td>\n",
              "      <td>99.94</td>\n",
              "      <td>1.58</td>\n",
              "      <td>66.35</td>\n",
              "      <td>66.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>200</td>\n",
              "      <td>0.2</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.01</td>\n",
              "      <td>99.82</td>\n",
              "      <td>1.57</td>\n",
              "      <td>67.17</td>\n",
              "      <td>67.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>200</td>\n",
              "      <td>0.25</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.01</td>\n",
              "      <td>99.71</td>\n",
              "      <td>1.62</td>\n",
              "      <td>65.06</td>\n",
              "      <td>65.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>200</td>\n",
              "      <td>0.35</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.02</td>\n",
              "      <td>99.37</td>\n",
              "      <td>1.50</td>\n",
              "      <td>66.17</td>\n",
              "      <td>66.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>200</td>\n",
              "      <td>0.4</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.03</td>\n",
              "      <td>99.18</td>\n",
              "      <td>1.54</td>\n",
              "      <td>65.91</td>\n",
              "      <td>65.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>600</td>\n",
              "      <td>0.1</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.83</td>\n",
              "      <td>77.46</td>\n",
              "      <td>77.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>600</td>\n",
              "      <td>0.15</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.81</td>\n",
              "      <td>78.93</td>\n",
              "      <td>78.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>600</td>\n",
              "      <td>0.2</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.79</td>\n",
              "      <td>78.49</td>\n",
              "      <td>78.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>600</td>\n",
              "      <td>0.25</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.83</td>\n",
              "      <td>77.39</td>\n",
              "      <td>77.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>600</td>\n",
              "      <td>0.35</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.79</td>\n",
              "      <td>78.91</td>\n",
              "      <td>78.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>600</td>\n",
              "      <td>0.4</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.76</td>\n",
              "      <td>78.79</td>\n",
              "      <td>78.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.1</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.57</td>\n",
              "      <td>83.73</td>\n",
              "      <td>83.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.15</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.56</td>\n",
              "      <td>84.28</td>\n",
              "      <td>84.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.2</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.51</td>\n",
              "      <td>84.92</td>\n",
              "      <td>84.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.25</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.53</td>\n",
              "      <td>84.55</td>\n",
              "      <td>84.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.35</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.52</td>\n",
              "      <td>84.19</td>\n",
              "      <td>84.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.4</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.49</td>\n",
              "      <td>85.30</td>\n",
              "      <td>85.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>5</td>\n",
              "      <td>1000</td>\n",
              "      <td>300-600</td>\n",
              "      <td>0.3-0.4</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.36</td>\n",
              "      <td>88.60</td>\n",
              "      <td>88.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>5</td>\n",
              "      <td>1000</td>\n",
              "      <td>300-600-900</td>\n",
              "      <td>0.2-0.3-0.4</td>\n",
              "      <td>relu</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.42</td>\n",
              "      <td>87.27</td>\n",
              "      <td>87.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>300</td>\n",
              "      <td>0.4</td>\n",
              "      <td>linear</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.35</td>\n",
              "      <td>88.45</td>\n",
              "      <td>88.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>300</td>\n",
              "      <td>0.4</td>\n",
              "      <td>softmax</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.09</td>\n",
              "      <td>97.42</td>\n",
              "      <td>0.51</td>\n",
              "      <td>83.11</td>\n",
              "      <td>83.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>300</td>\n",
              "      <td>0.4</td>\n",
              "      <td>softplus</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.28</td>\n",
              "      <td>90.68</td>\n",
              "      <td>90.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>300</td>\n",
              "      <td>0.4</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.27</td>\n",
              "      <td>92.22</td>\n",
              "      <td>92.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>300</td>\n",
              "      <td>0.4</td>\n",
              "      <td>tanh</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.34</td>\n",
              "      <td>88.59</td>\n",
              "      <td>88.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>5</td>\n",
              "      <td>20000</td>\n",
              "      <td>300-600</td>\n",
              "      <td>0.3-0.4</td>\n",
              "      <td>linear</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.29</td>\n",
              "      <td>90.31</td>\n",
              "      <td>90.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>5</td>\n",
              "      <td>20000</td>\n",
              "      <td>300-600</td>\n",
              "      <td>0.3-0.4</td>\n",
              "      <td>softmax</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.08</td>\n",
              "      <td>97.02</td>\n",
              "      <td>1.85</td>\n",
              "      <td>71.31</td>\n",
              "      <td>71.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>5</td>\n",
              "      <td>20000</td>\n",
              "      <td>300-600</td>\n",
              "      <td>0.3-0.4</td>\n",
              "      <td>softplus</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.27</td>\n",
              "      <td>91.38</td>\n",
              "      <td>91.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>5</td>\n",
              "      <td>20000</td>\n",
              "      <td>300-600</td>\n",
              "      <td>0.3-0.4</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.29</td>\n",
              "      <td>90.62</td>\n",
              "      <td>90.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>5</td>\n",
              "      <td>20000</td>\n",
              "      <td>300-600</td>\n",
              "      <td>0.3-0.4</td>\n",
              "      <td>tanh</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.39</td>\n",
              "      <td>88.77</td>\n",
              "      <td>88.77</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Модель  ... Средний процент распознавания на проверочной выборке\n",
              "0    Embbedding - 10  ...                                              30.08  \n",
              "1    Embbedding - 50  ...                                              19.32  \n",
              "2   Embbedding - 200  ...                                              39.72  \n",
              "3       Bag of Words  ...                                              49.90  \n",
              "4       Bag of Words  ...                                              85.15  \n",
              "5       Bag of Words  ...                                              88.44  \n",
              "6       Bag of Words  ...                                              88.96  \n",
              "7       Bag of Words  ...                                              29.51  \n",
              "8       Bag of Words  ...                                              29.60  \n",
              "9       Bag of Words  ...                                              29.60  \n",
              "10      Bag of Words  ...                                              29.60  \n",
              "11      Bag of Words  ...                                              29.45  \n",
              "12      Bag of Words  ...                                              29.45  \n",
              "13      Bag of Words  ...                                              40.55  \n",
              "14      Bag of Words  ...                                              41.22  \n",
              "15      Bag of Words  ...                                              39.78  \n",
              "16      Bag of Words  ...                                              41.01  \n",
              "17      Bag of Words  ...                                              41.53  \n",
              "18      Bag of Words  ...                                              40.89  \n",
              "19      Bag of Words  ...                                              49.99  \n",
              "20      Bag of Words  ...                                              49.87  \n",
              "21      Bag of Words  ...                                              49.90  \n",
              "22      Bag of Words  ...                                              51.08  \n",
              "23      Bag of Words  ...                                              49.30  \n",
              "24      Bag of Words  ...                                              50.39  \n",
              "25      Bag of Words  ...                                              64.48  \n",
              "26      Bag of Words  ...                                              66.35  \n",
              "27      Bag of Words  ...                                              67.17  \n",
              "28      Bag of Words  ...                                              65.06  \n",
              "29      Bag of Words  ...                                              66.17  \n",
              "30      Bag of Words  ...                                              65.91  \n",
              "31      Bag of Words  ...                                              77.46  \n",
              "32      Bag of Words  ...                                              78.93  \n",
              "33      Bag of Words  ...                                              78.49  \n",
              "34      Bag of Words  ...                                              77.39  \n",
              "35      Bag of Words  ...                                              78.91  \n",
              "36      Bag of Words  ...                                              78.79  \n",
              "37      Bag of Words  ...                                              83.73  \n",
              "38      Bag of Words  ...                                              84.28  \n",
              "39      Bag of Words  ...                                              84.92  \n",
              "40      Bag of Words  ...                                              84.55  \n",
              "41      Bag of Words  ...                                              84.19  \n",
              "42      Bag of Words  ...                                              85.30  \n",
              "43      Bag of Words  ...                                              88.60  \n",
              "44      Bag of Words  ...                                              87.27  \n",
              "45      Bag of Words  ...                                              88.45  \n",
              "46      Bag of Words  ...                                              83.11  \n",
              "47      Bag of Words  ...                                              90.68  \n",
              "48      Bag of Words  ...                                              92.22  \n",
              "49      Bag of Words  ...                                              88.59  \n",
              "50      Bag of Words  ...                                              90.31  \n",
              "51      Bag of Words  ...                                              71.31  \n",
              "52      Bag of Words  ...                                              91.38  \n",
              "53      Bag of Words  ...                                              90.62  \n",
              "54      Bag of Words  ...                                              88.77  \n",
              "\n",
              "[55 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl3uFR7S3GSX"
      },
      "source": [
        "# Так как таблица получилась очень большая из-за такого количества разных вариантов и искать в ней нужные для нас данные будет не просто, то выведем лучшие 5 результатов. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg6WjGHGCw63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "826b5046-9139-41da-a3e3-2e268b959a1d"
      },
      "source": [
        "print('5 лучших результата по максимальному среднему проценту')\r\n",
        "df.sort_values('Средний процент распознавания на проверочной выборке', ascending=False).head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5 лучших результата по максимальному среднему проценту\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Модель</th>\n",
              "      <th>Кол-во слоев</th>\n",
              "      <th>maxWordsCount</th>\n",
              "      <th>Dense</th>\n",
              "      <th>Dropout</th>\n",
              "      <th>activation</th>\n",
              "      <th>epochs</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>learn_loss</th>\n",
              "      <th>learn_accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>Средний процент распознавания на проверочной выборке</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>300</td>\n",
              "      <td>0.4</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.27</td>\n",
              "      <td>92.22</td>\n",
              "      <td>92.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>5</td>\n",
              "      <td>20000</td>\n",
              "      <td>300-600</td>\n",
              "      <td>0.3-0.4</td>\n",
              "      <td>softplus</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.27</td>\n",
              "      <td>91.38</td>\n",
              "      <td>91.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>300</td>\n",
              "      <td>0.4</td>\n",
              "      <td>softplus</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.28</td>\n",
              "      <td>90.68</td>\n",
              "      <td>90.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>5</td>\n",
              "      <td>20000</td>\n",
              "      <td>300-600</td>\n",
              "      <td>0.3-0.4</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.29</td>\n",
              "      <td>90.62</td>\n",
              "      <td>90.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>5</td>\n",
              "      <td>20000</td>\n",
              "      <td>300-600</td>\n",
              "      <td>0.3-0.4</td>\n",
              "      <td>linear</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.29</td>\n",
              "      <td>90.31</td>\n",
              "      <td>90.31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Модель  ... Средний процент распознавания на проверочной выборке\n",
              "48  Bag of Words  ...                                              92.22  \n",
              "52  Bag of Words  ...                                              91.38  \n",
              "47  Bag of Words  ...                                              90.68  \n",
              "53  Bag of Words  ...                                              90.62  \n",
              "50  Bag of Words  ...                                              90.31  \n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sABF89Mf0kVL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "421d5f7d-9f46-477d-8d91-21beb1ba8993"
      },
      "source": [
        "print('5 лучших результата по максимальной точности тестовой выборки')\r\n",
        "df.sort_values('val_accuracy', ascending=False).head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5 лучших результата по максимальной точности тестовой выборки\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Модель</th>\n",
              "      <th>Кол-во слоев</th>\n",
              "      <th>maxWordsCount</th>\n",
              "      <th>Dense</th>\n",
              "      <th>Dropout</th>\n",
              "      <th>activation</th>\n",
              "      <th>epochs</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>learn_loss</th>\n",
              "      <th>learn_accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>Средний процент распознавания на проверочной выборке</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>300</td>\n",
              "      <td>0.4</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.27</td>\n",
              "      <td>92.22</td>\n",
              "      <td>92.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>5</td>\n",
              "      <td>20000</td>\n",
              "      <td>300-600</td>\n",
              "      <td>0.3-0.4</td>\n",
              "      <td>softplus</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.27</td>\n",
              "      <td>91.38</td>\n",
              "      <td>91.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>300</td>\n",
              "      <td>0.4</td>\n",
              "      <td>softplus</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.28</td>\n",
              "      <td>90.68</td>\n",
              "      <td>90.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>5</td>\n",
              "      <td>20000</td>\n",
              "      <td>300-600</td>\n",
              "      <td>0.3-0.4</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.29</td>\n",
              "      <td>90.62</td>\n",
              "      <td>90.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>5</td>\n",
              "      <td>20000</td>\n",
              "      <td>300-600</td>\n",
              "      <td>0.3-0.4</td>\n",
              "      <td>linear</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.29</td>\n",
              "      <td>90.31</td>\n",
              "      <td>90.31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Модель  ... Средний процент распознавания на проверочной выборке\n",
              "48  Bag of Words  ...                                              92.22  \n",
              "52  Bag of Words  ...                                              91.38  \n",
              "47  Bag of Words  ...                                              90.68  \n",
              "53  Bag of Words  ...                                              90.62  \n",
              "50  Bag of Words  ...                                              90.31  \n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "UsCz6__10LR5",
        "outputId": "47286b27-bc5e-4295-cb23-d3fb9153bb20"
      },
      "source": [
        "print('5 лучших результата по минимальной ошибке тестовой выборки')\r\n",
        "df.sort_values('val_loss').head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5 лучших результата по минимальной ошибке тестовой выборки\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Модель</th>\n",
              "      <th>Кол-во слоев</th>\n",
              "      <th>maxWordsCount</th>\n",
              "      <th>Dense</th>\n",
              "      <th>Dropout</th>\n",
              "      <th>activation</th>\n",
              "      <th>epochs</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>learn_loss</th>\n",
              "      <th>learn_accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>Средний процент распознавания на проверочной выборке</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>5</td>\n",
              "      <td>20000</td>\n",
              "      <td>300-600</td>\n",
              "      <td>0.3-0.4</td>\n",
              "      <td>softplus</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.27</td>\n",
              "      <td>91.38</td>\n",
              "      <td>91.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>300</td>\n",
              "      <td>0.4</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.27</td>\n",
              "      <td>92.22</td>\n",
              "      <td>92.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>2</td>\n",
              "      <td>20000</td>\n",
              "      <td>300</td>\n",
              "      <td>0.4</td>\n",
              "      <td>softplus</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.28</td>\n",
              "      <td>90.68</td>\n",
              "      <td>90.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>5</td>\n",
              "      <td>20000</td>\n",
              "      <td>300-600</td>\n",
              "      <td>0.3-0.4</td>\n",
              "      <td>linear</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.29</td>\n",
              "      <td>90.31</td>\n",
              "      <td>90.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Bag of Words</td>\n",
              "      <td>5</td>\n",
              "      <td>20000</td>\n",
              "      <td>300-600</td>\n",
              "      <td>0.3-0.4</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>15</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.29</td>\n",
              "      <td>90.62</td>\n",
              "      <td>90.62</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Модель  ... Средний процент распознавания на проверочной выборке\n",
              "52  Bag of Words  ...                                              91.38  \n",
              "48  Bag of Words  ...                                              92.22  \n",
              "47  Bag of Words  ...                                              90.68  \n",
              "50  Bag of Words  ...                                              90.31  \n",
              "53  Bag of Words  ...                                              90.62  \n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9MK5Yt_4edq"
      },
      "source": [
        "# Выводы: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nxQpW5U4hl9"
      },
      "source": [
        "1. В данных примерах прослеживается закономерность, что чем больше кол-во слов в словаре, тем большая точность на тестовой выборке.\r\n",
        "\r\n",
        "    При значении maxWordsCount равным 20000 точность значительно выше чем при 100. Можно предположить что при значении в 50000 точность будет выше. \r\n",
        "\r\n",
        "2. В данном случаи, при такой архитектуре нейронных сетей и с одинаковыми параметрами метод Bag of Words показал лучше результат чем Embbedding. \r\n",
        "\r\n",
        "3. В сравнительно таблице видно, что кол-во нейронов в полносвязном Dense слое тоже влияют на результат. Так даже при большом словаре и 10 нейронов в Dense слое, показатели не удовлетворительные. \r\n",
        "\r\n",
        "4. Значение в слое Dropout тоже влияет. Так данные эксперименты показали что лучшие показатели при значении 0.4. \r\n",
        "\r\n",
        "5. Добавление новых слоев увеличивают средний процент на тестовой выборке, но не значительно.\r\n",
        "\r\n",
        "6. Так же как и использование других активациооных функций. \r\n",
        "\r\n",
        "\r\n",
        "7. Но не смотря на это даже прирост в несколько процентов имееет смысл. Поэтому нужно эксперементировать и подбирать лучшую архитектуру и гиперпарметры нейронной сети. "
      ]
    }
  ]
}