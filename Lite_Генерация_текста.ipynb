{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Теплов М.Н. -Lite - Генерация текста",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Задание **Lite**\n",
        "\n",
        "Используя три любых простых вопроса, сравните ответы сети на них на разной степени натренированности:\n",
        "\n",
        "1.  20 эпох – удается ли боту отвечать целыми словами?\n",
        "\n",
        "2.  Еще 30 эпох на этой же сетке и с этими же вопросами – появился ли прогресс в качестве ответа сети (ответ целыми предложениями разумной длины)?\n",
        "\n",
        "3.  Ещё + 50 эпох – удается ли сети выдавать ответы, “похожие на правду”?"
      ],
      "metadata": {
        "id": "F1xTEMtnh7_n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подключение библиотек"
      ],
      "metadata": {
        "id": "QvNsGMkTL5Uv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3h_s5azfLtT9"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import yaml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKmLo1YYOXAb",
        "outputId": "a927113b-a87c-406d-f5e7-e4c8a78dbb79"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Парсинг данных"
      ],
      "metadata": {
        "id": "LMcldUH2OfQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Открываем файл с диалогами\n",
        "corpus = open('/content/drive/MyDrive/УИИ/Генерация текста/Диалоги.yml', 'r')\n",
        "document = yaml.safe_load(corpus)\n",
        "conversations = document['разговоры']\n",
        "print(f'Количество пар вопрос-ответ : {len(conversations)}')\n",
        "print(f'Пример диалога : {conversations[10000]}')\n",
        "corpus.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxP7g0f0OiTK",
        "outputId": "43f1d193-487e-44ab-9af6-49786f5523bc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество пар вопрос-ответ : 11893\n",
            "Пример диалога : ['Откуда вы знаете?', 'Я  Чорин-Цу,  господин.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Разбираем вопросы-ответы с проставлением тегов ответам\n",
        "questions = []\n",
        "answers   = []\n",
        "\n",
        "for con in conversations[:len(conversations)//2]:   # Из-за нехватки памяти пришлось сократить обучающий набор пополам\n",
        "  if len(con) > 2:\n",
        "    questions.append(con[0])\n",
        "    replies = con[1:]\n",
        "    ans = ''\n",
        "    for rep in replies:\n",
        "      ans += \" \" + rep\n",
        "    answers.append(ans)\n",
        "  elif len(con) > 1:\n",
        "    questions.append(con[0])\n",
        "    answers.append(con[1])"
      ],
      "metadata": {
        "id": "UsN_pbTaPe2d"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Очищаем строки с неопределенным типом ответов\n",
        "answersCleaned = []\n",
        "for i in range(len(answers)):\n",
        "  if type(answers[i]) == str:\n",
        "    answersCleaned.append(answers[i])\n",
        "  else:\n",
        "    questions.pop()"
      ],
      "metadata": {
        "id": "Z9AfZkF7Qutw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Сделаем теги-метки для начала и конца ответов\n",
        "answers = []\n",
        "for i in range(len(answersCleaned)):\n",
        "  answers.append('<START>' + answersCleaned[i] + '<END>')"
      ],
      "metadata": {
        "id": "Th9hCMWmQvmY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Выведем обновленные данные на экран\n",
        "print('Вопрос : {}'.format(questions[5000]))\n",
        "print('Ответ  : {}'.format(answers[5000]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYAU-sYtRjHL",
        "outputId": "dfd80db4-68bd-4b7c-f3ac-c58f36cc8cdd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вопрос : Что?..\n",
            "Ответ  : <START>К Туманной Скале!<END>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Подключаем керасовский токенизатор и собираем словарь индексов\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(questions + answers)\n",
        "vocabularyItems = list(tokenizer.word_index.items())\n",
        "vocabularySize = len(vocabularyItems) + 1"
      ],
      "metadata": {
        "id": "0dek4TfiQupJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print( 'Размер словаря   : {}'.format(vocabularySize))\n",
        "print( 'Фрагмент словаря : {}'.format(vocabularyItems[:100]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfxiEbzgSQLQ",
        "outputId": "f2623a0f-d4e1-4e93-d3b9-a137084aa375"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер словаря   : 9382\n",
            "Фрагмент словаря : [('start', 1), ('end', 2), ('что', 3), ('не', 4), ('а', 5), ('ты', 6), ('я', 7), ('это', 8), ('в', 9), ('как', 10), ('и', 11), ('да', 12), ('нет', 13), ('вы', 14), ('ну', 15), ('на', 16), ('с', 17), ('же', 18), ('где', 19), ('так', 20), ('у', 21), ('кто', 22), ('он', 23), ('то', 24), ('все', 25), ('тебя', 26), ('мы', 27), ('куда', 28), ('мне', 29), ('там', 30), ('есть', 31), ('почему', 32), ('вот', 33), ('за', 34), ('меня', 35), ('тебе', 36), ('ничего', 37), ('здесь', 38), ('еще', 39), ('знаю', 40), ('ли', 41), ('товарищ', 42), ('его', 43), ('к', 44), ('чего', 45), ('вас', 46), ('о', 47), ('надо', 48), ('зачем', 49), ('может', 50), ('вам', 51), ('сейчас', 52), ('по', 53), ('они', 54), ('нас', 55), ('можно', 56), ('чем', 57), ('тут', 58), ('бы', 59), ('но', 60), ('из', 61), ('она', 62), ('тоже', 63), ('конечно', 64), ('какой', 65), ('будет', 66), ('очень', 67), ('случилось', 68), ('уже', 69), ('дело', 70), ('сам', 71), ('сколько', 72), ('значит', 73), ('когда', 74), ('только', 75), ('хорошо', 76), ('такое', 77), ('нибудь', 78), ('точно', 79), ('откуда', 80), ('тогда', 81), ('теперь', 82), ('если', 83), ('быть', 84), ('хочешь', 85), ('их', 86), ('нам', 87), ('командир', 88), ('делать', 89), ('было', 90), ('кого', 91), ('ж', 92), ('от', 93), ('спасибо', 94), ('ага', 95), ('разве', 96), ('или', 97), ('хочу', 98), ('будем', 99), ('мой', 100)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подготовка выборки"
      ],
      "metadata": {
        "id": "buGjwt4SSV5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Устанавливаем закодированные входные данные(вопросы)\n",
        "tokenizedQuestions = tokenizer.texts_to_sequences(questions)\n",
        "maxLenQuestions = max([len(x) for x in tokenizedQuestions])\n",
        "\n",
        "# Делаем последовательности одной длины\n",
        "encoderForInput = pad_sequences(tokenizedQuestions, maxlen=maxLenQuestions, padding='post')"
      ],
      "metadata": {
        "id": "WiqH34CCSYIg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Пример оригинального вопроса на вход : {}'.format(questions[1000])) \n",
        "print('Пример кодированного вопроса на вход : {}'.format(encoderForInput[1000])) \n",
        "print('Размеры закодированного массива вопросов на вход : {}'.format(encoderForInput.shape)) \n",
        "print('Установленная длина вопросов на вход : {}'.format(maxLenQuestions)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptxLuQAkSYMC",
        "outputId": "bb9e34ce-31f1-4425-dd84-de0e04ca13d5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример оригинального вопроса на вход : Куда теперь?\n",
            "Пример кодированного вопроса на вход : [28 82  0  0  0  0  0  0  0  0  0]\n",
            "Размеры закодированного массива вопросов на вход : (5943, 11)\n",
            "Установленная длина вопросов на вход : 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Устанавливаем раскодированные входные данные(ответы)\n",
        "tokenizedAnswers = tokenizer.texts_to_sequences(answers)\n",
        "maxLenAnswers = max([len(x) for x in tokenizedAnswers])\n",
        "\n",
        "# Делаем последовательности одной длины\n",
        "decoderForInput = pad_sequences(tokenizedAnswers, maxlen=maxLenAnswers, padding='post')"
      ],
      "metadata": {
        "id": "GhxXwChSSYPl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Пример оригинального ответа на вход: {}'.format(answers[1000])) \n",
        "print('Пример раскодированного ответа на вход : {}'.format(decoderForInput[1000])) \n",
        "print('Размеры раскодированного массива ответов на вход : {}'.format(decoderForInput.shape)) \n",
        "print('Установленная длина ответов на вход : {}'.format(maxLenAnswers)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wsknex0SYT5",
        "outputId": "766a1a01-71ef-451e-c2fb-92ac037b083c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример оригинального ответа на вход: <START>На Родину!<END>\n",
            "Пример раскодированного ответа на вход : [  1  16 942   2   0   0   0   0   0   0   0   0   0]\n",
            "Размеры раскодированного массива ответов на вход : (5943, 13)\n",
            "Установленная длина ответов на вход : 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Раскодированные выходные данные(ответы)\n",
        "for i in range(len(tokenizedAnswers)):\n",
        "  tokenizedAnswers[i] = tokenizedAnswers[i][1:]  # избавляемся от тега <START>\n",
        "\n",
        "# Делаем последовательности одной длины\n",
        "paddedAnswers = pad_sequences(tokenizedAnswers, maxlen=maxLenAnswers, padding='post')"
      ],
      "metadata": {
        "id": "tsU9mGTjXcez"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# переводим в one hot vector\n",
        "oneHotAnswers = to_categorical(paddedAnswers, vocabularySize)\n",
        "decoderForOutput = np.array(oneHotAnswers)"
      ],
      "metadata": {
        "id": "asSi_g_OXci-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Пример раскодированного ответа на вход : {}'.format(decoderForInput[4999][:21]))  \n",
        "print('Пример раскодированного ответа на выход : {}'.format(decoderForOutput[4999][4][:21])) \n",
        "print('Размеры раскодированного массива ответов на выход : {}'.format(decoderForOutput.shape))\n",
        "print('Установленная длина вопросов на выход : {}'.format(maxLenAnswers)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhGV3zSMZMgg",
        "outputId": "391183e7-6c6b-415e-eb71-bcaba2318590"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример раскодированного ответа на вход : [   1    7    4 8940  420    2    0    0    0    0    0    0    0]\n",
            "Пример раскодированного ответа на выход : [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Размеры раскодированного массива ответов на выход : (5943, 13, 9382)\n",
            "Установленная длина вопросов на выход : 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем рабочую модель для вывода ответов на запросы пользователя\n",
        "def makeInferenceModels():\n",
        "  encoderModel = Model(encoderInputs, encoderStates)\n",
        "\n",
        "  decoderStateInput_h = Input(shape=(200,))\n",
        "  decoderStateInput_c = Input(shape=(200,))\n",
        "  decoderStatesInputs = [decoderStateInput_h, decoderStateInput_c]\n",
        "\n",
        "  decoderOutputs, state_h, state_c = decoderLSTM(decoderEmbedding, initial_state=decoderStatesInputs)\n",
        "  decoderStates = [state_h, state_c]\n",
        "  decoderOutputs = decoderDense(decoderOutputs)\n",
        "\n",
        "  decoderModel = Model([decoderInputs] + decoderStatesInputs, [decoderOutputs] + decoderStates)\n",
        "\n",
        "  return encoderModel, decoderModel"
      ],
      "metadata": {
        "id": "fZR-XTwofEyi"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создадим функцию, которая преобразует вопрос пользователя в последовательность индексов\n",
        "def strToTokens(sentence):\n",
        "  words = sentence.lower().split()\n",
        "  tokensList = []\n",
        "  for word in words:\n",
        "    tokensList.append(tokenizer.word_index[word])\n",
        "  \n",
        "  return pad_sequences([tokensList], maxlen = maxLenQuestions, padding='post')"
      ],
      "metadata": {
        "id": "NU2nsA2mMs8M"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ0Dxd1eiEid"
      },
      "source": [
        "# Устанавливаем окончательные настройки и запускаем модель \n",
        "def TestModel():\n",
        "  encModel , decModel = makeInferenceModels()\n",
        "\n",
        "  for _ in range(5):\n",
        "    statesValues = encModel.predict(strToTokens(input( 'Задайте вопрос : ' )))\n",
        "    emptyTargetSeq = np.zeros((1, 1))    \n",
        "    emptyTargetSeq[0, 0] = tokenizer.word_index['start']\n",
        "\n",
        "    stopCondition = False\n",
        "    decodedTranslation = ''\n",
        "    while not stopCondition :\n",
        "      decOutputs , h , c = decModel.predict([emptyTargetSeq] + statesValues)\n",
        "      sampledWordIndex = np.argmax( decOutputs[0, 0, :])\n",
        "      sampledWord = None\n",
        "      for word , index in tokenizer.word_index.items():\n",
        "        if sampledWordIndex == index:\n",
        "          decodedTranslation += ' {}'.format(word)\n",
        "          sampledWord = word\n",
        "      \n",
        "      if sampledWord == 'end' or len(decodedTranslation.split()) > maxLenAnswers:\n",
        "        stopCondition = True\n",
        "\n",
        "      emptyTargetSeq[0, 0] = sampledWordIndex\n",
        "      statesValues = [h, c]\n",
        "    \n",
        "    print(decodedTranslation[:-3])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Параметры нейросети и модель обучения"
      ],
      "metadata": {
        "id": "fUVbDABMZ8Hy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Первый входной слой, кодер, выходной слой\n",
        "encoderInputs = Input(shape=(None, ))\n",
        "encoderEmbedding = Embedding(vocabularySize, 200, mask_zero=True)(encoderInputs)\n",
        "encoderOutputs, state_h, state_c = LSTM(200, return_state=True)(encoderEmbedding)\n",
        "encoderStates = [state_h, state_c]"
      ],
      "metadata": {
        "id": "PJB7rcUnZ8wr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Второй входной слой, декодер, выходной слой\n",
        "decoderInputs = Input(shape=(None, ))\n",
        "decoderEmbedding = Embedding(vocabularySize, 200, mask_zero=True)(decoderInputs)\n",
        "decoderLSTM = LSTM(200, return_state=True, return_sequences=True)\n",
        "decoderOutputs, _ , _ = decoderLSTM (decoderEmbedding, initial_state=encoderStates)\n",
        "decoderDense =  Dense(vocabularySize, activation='softmax')\n",
        "output = decoderDense(decoderOutputs)"
      ],
      "metadata": {
        "id": "gtOwbk75Z8z_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Собираем тренировочную модель нейросети\n",
        "model = Model([encoderInputs, decoderInputs], output)\n",
        "model.compile(optimizer=RMSprop(), loss='categorical_crossentropy')"
      ],
      "metadata": {
        "id": "Ym8sZPYsdWb2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение **20** эпох"
      ],
      "metadata": {
        "id": "Drey5enI341A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Запустим обучение и сохраним модель\n",
        "model.fit([encoderForInput , decoderForInput], decoderForOutput, batch_size=50, epochs=20)\n",
        "\n",
        "# Сохранение весов\n",
        "model.save_weights('/content/drive/MyDrive/УИИ/Генерация текста/sequences_to_sequences.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INNh3fj5Z89f",
        "outputId": "e53ab46e-280b-4c7d-a93d-8c8d4f015efd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "119/119 [==============================] - 16s 31ms/step - loss: 2.3318\n",
            "Epoch 2/20\n",
            "119/119 [==============================] - 4s 30ms/step - loss: 1.9860\n",
            "Epoch 3/20\n",
            "119/119 [==============================] - 4s 30ms/step - loss: 1.9284\n",
            "Epoch 4/20\n",
            "119/119 [==============================] - 4s 30ms/step - loss: 1.8847\n",
            "Epoch 5/20\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 1.8463\n",
            "Epoch 6/20\n",
            "119/119 [==============================] - 4s 30ms/step - loss: 1.8145\n",
            "Epoch 7/20\n",
            "119/119 [==============================] - 4s 30ms/step - loss: 1.7842\n",
            "Epoch 8/20\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 1.7550\n",
            "Epoch 9/20\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 1.7269\n",
            "Epoch 10/20\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 1.6988\n",
            "Epoch 11/20\n",
            "119/119 [==============================] - 4s 30ms/step - loss: 1.6684\n",
            "Epoch 12/20\n",
            "119/119 [==============================] - 4s 30ms/step - loss: 1.6392\n",
            "Epoch 13/20\n",
            "119/119 [==============================] - 4s 30ms/step - loss: 1.6074\n",
            "Epoch 14/20\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 1.5773\n",
            "Epoch 15/20\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 1.5465\n",
            "Epoch 16/20\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 1.5149\n",
            "Epoch 17/20\n",
            "119/119 [==============================] - 4s 30ms/step - loss: 1.4828\n",
            "Epoch 18/20\n",
            "119/119 [==============================] - 4s 30ms/step - loss: 1.4532\n",
            "Epoch 19/20\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 1.4231\n",
            "Epoch 20/20\n",
            "119/119 [==============================] - 4s 30ms/step - loss: 1.3939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Проверка результата\n"
      ],
      "metadata": {
        "id": "B2uqk2vDeaPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка весов\n",
        "#model.load_weights('/content/drive/MyDrive/УИИ/Генерация текста/sequences_to_sequences.h5')"
      ],
      "metadata": {
        "id": "nWeytbkleave"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TestModel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-isQb9hkI3h",
        "outputId": "7c33b538-98f5-43e8-b3d7-7f34b8f3093f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Задайте вопрос : Что делаешь\n",
            " не знаю \n",
            "Задайте вопрос : Как твои дела\n",
            " ну что \n",
            "Задайте вопрос : Зачем все это нужно\n",
            " нет \n",
            "Задайте вопрос : Что можешь сказать\n",
            " ну что ж в порядке \n",
            "Задайте вопрос : Как тебя зовут\n",
            " да \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Дообучение еще **30** эпох"
      ],
      "metadata": {
        "id": "iSdiA2YtjWSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка весов\n",
        "#model.load_weights('/content/drive/MyDrive/УИИ/Генерация текста/sequences_to_sequences.h5')"
      ],
      "metadata": {
        "id": "gFFderZUoS5Y"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Запустим обучение и сохраним модель\n",
        "model.fit([encoderForInput , decoderForInput], decoderForOutput, batch_size=50, epochs=30)\n",
        "\n",
        "# Сохранение весов\n",
        "model.save_weights('/content/drive/MyDrive/УИИ/Генерация текста/sequences_to_sequences.h5')"
      ],
      "metadata": {
        "id": "K_WEyNfx0d2J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be28a96d-cd08-40fe-846b-aa47ec488a42"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "119/119 [==============================] - 16s 34ms/step - loss: 1.3982\n",
            "Epoch 2/30\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 1.3537\n",
            "Epoch 3/30\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 1.3157\n",
            "Epoch 4/30\n",
            "119/119 [==============================] - 4s 37ms/step - loss: 1.2802\n",
            "Epoch 5/30\n",
            "119/119 [==============================] - 4s 36ms/step - loss: 1.2511\n",
            "Epoch 6/30\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 1.2188\n",
            "Epoch 7/30\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 1.1893\n",
            "Epoch 8/30\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 1.1584\n",
            "Epoch 9/30\n",
            "119/119 [==============================] - 4s 30ms/step - loss: 1.1285\n",
            "Epoch 10/30\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 1.0997\n",
            "Epoch 11/30\n",
            "119/119 [==============================] - 4s 32ms/step - loss: 1.0712\n",
            "Epoch 12/30\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 1.0433\n",
            "Epoch 13/30\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 1.0145\n",
            "Epoch 14/30\n",
            "119/119 [==============================] - 4s 32ms/step - loss: 0.9841\n",
            "Epoch 15/30\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.9561\n",
            "Epoch 16/30\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.9298\n",
            "Epoch 17/30\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.9040\n",
            "Epoch 18/30\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.8798\n",
            "Epoch 19/30\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.8572\n",
            "Epoch 20/30\n",
            "119/119 [==============================] - 4s 30ms/step - loss: 0.8339\n",
            "Epoch 21/30\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.8116\n",
            "Epoch 22/30\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.7896\n",
            "Epoch 23/30\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.7700\n",
            "Epoch 24/30\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.7489\n",
            "Epoch 25/30\n",
            "119/119 [==============================] - 4s 30ms/step - loss: 0.7301\n",
            "Epoch 26/30\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.7110\n",
            "Epoch 27/30\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.6943\n",
            "Epoch 28/30\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.6779\n",
            "Epoch 29/30\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.6620\n",
            "Epoch 30/30\n",
            "119/119 [==============================] - 4s 30ms/step - loss: 0.6475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Проверка результата"
      ],
      "metadata": {
        "id": "W7juLW_bjuPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TestModel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgopfvxAjwqs",
        "outputId": "4a032a2f-ebac-45bd-afe7-1bd35f144577"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Задайте вопрос : Что делаешь\n",
            " а \n",
            "Задайте вопрос : Как твои дела\n",
            " все в порядке \n",
            "Задайте вопрос : Зачем все это нужно\n",
            " да так \n",
            "Задайте вопрос : Что можешь сказать\n",
            " тогда тут таком общем \n",
            "Задайте вопрос : Как тебя зовут\n",
            " не я сам тобой \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Дообучение еще 50 эпох"
      ],
      "metadata": {
        "id": "D2JaSRML3_mM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка весов\n",
        "model.load_weights('/content/drive/MyDrive/УИИ/Генерация текста/sequences_to_sequences.h5')"
      ],
      "metadata": {
        "id": "wP-AprFdoW8X"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Запустим обучение и сохраним модель\n",
        "model.fit([encoderForInput , decoderForInput], decoderForOutput, batch_size=50, epochs=50)\n",
        "\n",
        "# Сохранение весов\n",
        "model.save_weights('/content/drive/MyDrive/УИИ/Генерация текста/sequences_to_sequences.h5')"
      ],
      "metadata": {
        "id": "kMAJwjaB3vBD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e4bc398-41b3-4c4c-f03f-0a094779d783"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "119/119 [==============================] - 16s 32ms/step - loss: 0.6756\n",
            "Epoch 2/50\n",
            "119/119 [==============================] - 4s 32ms/step - loss: 0.6518\n",
            "Epoch 3/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.6327\n",
            "Epoch 4/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.6171\n",
            "Epoch 5/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.6017\n",
            "Epoch 6/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.5885\n",
            "Epoch 7/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.5744\n",
            "Epoch 8/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.5622\n",
            "Epoch 9/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.5511\n",
            "Epoch 10/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.5394\n",
            "Epoch 11/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.5305\n",
            "Epoch 12/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.5210\n",
            "Epoch 13/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.5127\n",
            "Epoch 14/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.5046\n",
            "Epoch 15/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.4985\n",
            "Epoch 16/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.4915\n",
            "Epoch 17/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.4851\n",
            "Epoch 18/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.4790\n",
            "Epoch 19/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.4734\n",
            "Epoch 20/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.4674\n",
            "Epoch 21/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.4622\n",
            "Epoch 22/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.4579\n",
            "Epoch 23/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.4529\n",
            "Epoch 24/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.4481\n",
            "Epoch 25/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.4440\n",
            "Epoch 26/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.4404\n",
            "Epoch 27/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.4364\n",
            "Epoch 28/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.4326\n",
            "Epoch 29/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.4296\n",
            "Epoch 30/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.4258\n",
            "Epoch 31/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.4227\n",
            "Epoch 32/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.4182\n",
            "Epoch 33/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.4144\n",
            "Epoch 34/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.4119\n",
            "Epoch 35/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.4095\n",
            "Epoch 36/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.4068\n",
            "Epoch 37/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.4049\n",
            "Epoch 38/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.4025\n",
            "Epoch 39/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.4004\n",
            "Epoch 40/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3985\n",
            "Epoch 41/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3974\n",
            "Epoch 42/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3958\n",
            "Epoch 43/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3944\n",
            "Epoch 44/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3919\n",
            "Epoch 45/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3907\n",
            "Epoch 46/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3879\n",
            "Epoch 47/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3867\n",
            "Epoch 48/50\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3847\n",
            "Epoch 49/50\n",
            "119/119 [==============================] - 4s 32ms/step - loss: 0.3830\n",
            "Epoch 50/50\n",
            "119/119 [==============================] - 4s 32ms/step - loss: 0.3826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Проверка результата"
      ],
      "metadata": {
        "id": "0_YAPMlJjvZ_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JU6W5VLJqbnG",
        "outputId": "04cd8d28-c0e6-45c7-f9cc-a087e7f330b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Задайте вопрос : Что делаешь\n",
            " а что без чем \n",
            "Задайте вопрос : Как твои дела\n",
            " все в порядке \n",
            "Задайте вопрос : Зачем все это нужно\n",
            " да как же это \n",
            "Задайте вопрос : Что можешь сказать\n",
            " да \n",
            "Задайте вопрос : Как тебя зовут\n",
            " нет не я \n"
          ]
        }
      ],
      "source": [
        "TestModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Дообучение еще 100 эпох"
      ],
      "metadata": {
        "id": "exFCTiCGqbnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка весов\n",
        "model.load_weights('/content/drive/MyDrive/УИИ/Генерация текста/sequences_to_sequences.h5')"
      ],
      "metadata": {
        "id": "66UcjmIeqbnD"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Запустим обучение и сохраним модель\n",
        "model.fit([encoderForInput , decoderForInput], decoderForOutput, batch_size=50, epochs=100)\n",
        "\n",
        "# Сохранение весов\n",
        "model.save_weights('/content/drive/MyDrive/УИИ/Генерация текста/sequences_to_sequences.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e867226-b150-46af-9b20-aa394660f3a7",
        "id": "Ms4GxIO2qbnE"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "119/119 [==============================] - 15s 31ms/step - loss: 0.4211\n",
            "Epoch 2/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.4134\n",
            "Epoch 3/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.4075\n",
            "Epoch 4/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.4024\n",
            "Epoch 5/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3988\n",
            "Epoch 6/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3952\n",
            "Epoch 7/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3916\n",
            "Epoch 8/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3887\n",
            "Epoch 9/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3864\n",
            "Epoch 10/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3843\n",
            "Epoch 11/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3828\n",
            "Epoch 12/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3806\n",
            "Epoch 13/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3784\n",
            "Epoch 14/100\n",
            "119/119 [==============================] - 4s 32ms/step - loss: 0.3763\n",
            "Epoch 15/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3747\n",
            "Epoch 16/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3732\n",
            "Epoch 17/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3716\n",
            "Epoch 18/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3691\n",
            "Epoch 19/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3686\n",
            "Epoch 20/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3667\n",
            "Epoch 21/100\n",
            "119/119 [==============================] - 4s 32ms/step - loss: 0.3655\n",
            "Epoch 22/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3643\n",
            "Epoch 23/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3641\n",
            "Epoch 24/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3624\n",
            "Epoch 25/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3616\n",
            "Epoch 26/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3613\n",
            "Epoch 27/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3604\n",
            "Epoch 28/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3594\n",
            "Epoch 29/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3586\n",
            "Epoch 30/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3587\n",
            "Epoch 31/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3580\n",
            "Epoch 32/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3584\n",
            "Epoch 33/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3574\n",
            "Epoch 34/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3577\n",
            "Epoch 35/100\n",
            "119/119 [==============================] - 4s 30ms/step - loss: 0.3574\n",
            "Epoch 36/100\n",
            "119/119 [==============================] - 4s 30ms/step - loss: 0.3573\n",
            "Epoch 37/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3573\n",
            "Epoch 38/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3580\n",
            "Epoch 39/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3580\n",
            "Epoch 40/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3591\n",
            "Epoch 41/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3595\n",
            "Epoch 42/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3599\n",
            "Epoch 43/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3608\n",
            "Epoch 44/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3603\n",
            "Epoch 45/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3611\n",
            "Epoch 46/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3599\n",
            "Epoch 47/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3601\n",
            "Epoch 48/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3616\n",
            "Epoch 49/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3627\n",
            "Epoch 50/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3626\n",
            "Epoch 51/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3622\n",
            "Epoch 52/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3626\n",
            "Epoch 53/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3631\n",
            "Epoch 54/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3627\n",
            "Epoch 55/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3618\n",
            "Epoch 56/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3634\n",
            "Epoch 57/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3628\n",
            "Epoch 58/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3631\n",
            "Epoch 59/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3639\n",
            "Epoch 60/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3637\n",
            "Epoch 61/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3634\n",
            "Epoch 62/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3636\n",
            "Epoch 63/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3629\n",
            "Epoch 64/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3624\n",
            "Epoch 65/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3624\n",
            "Epoch 66/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3624\n",
            "Epoch 67/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3619\n",
            "Epoch 68/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3624\n",
            "Epoch 69/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3618\n",
            "Epoch 70/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3620\n",
            "Epoch 71/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3619\n",
            "Epoch 72/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3614\n",
            "Epoch 73/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3608\n",
            "Epoch 74/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3598\n",
            "Epoch 75/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3595\n",
            "Epoch 76/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3598\n",
            "Epoch 77/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3586\n",
            "Epoch 78/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3590\n",
            "Epoch 79/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3587\n",
            "Epoch 80/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3580\n",
            "Epoch 81/100\n",
            "119/119 [==============================] - 4s 30ms/step - loss: 0.3582\n",
            "Epoch 82/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3571\n",
            "Epoch 83/100\n",
            "119/119 [==============================] - 4s 30ms/step - loss: 0.3564\n",
            "Epoch 84/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3565\n",
            "Epoch 85/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3560\n",
            "Epoch 86/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3554\n",
            "Epoch 87/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3543\n",
            "Epoch 88/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3539\n",
            "Epoch 89/100\n",
            "119/119 [==============================] - 4s 30ms/step - loss: 0.3537\n",
            "Epoch 90/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3527\n",
            "Epoch 91/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3532\n",
            "Epoch 92/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3525\n",
            "Epoch 93/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3513\n",
            "Epoch 94/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3512\n",
            "Epoch 95/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3500\n",
            "Epoch 96/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3496\n",
            "Epoch 97/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3491\n",
            "Epoch 98/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3485\n",
            "Epoch 99/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3478\n",
            "Epoch 100/100\n",
            "119/119 [==============================] - 4s 31ms/step - loss: 0.3466\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Проверка результата"
      ],
      "metadata": {
        "id": "DJhGa-v8qbnF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задайте вопрос : Что делаешь\n",
        " а что без чем \n",
        "Задайте вопрос : Как твои дела\n",
        " все в порядке \n",
        "Задайте вопрос : Зачем все это нужно\n",
        " да как же это \n",
        "Задайте вопрос : Что можешь сказать\n",
        " да \n",
        "Задайте вопрос : Как тебя зовут\n",
        " нет не я "
      ],
      "metadata": {
        "id": "XSXGEyUjshdL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nCSxb0Lh3mA",
        "outputId": "c13a7640-432f-40d6-84e7-8c303fe3ec54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Задайте вопрос : Что делаешь\n",
            " ох а так вон не \n",
            "Задайте вопрос : Что делаешь\n",
            " ох а так вон не \n",
            "Задайте вопрос : Зачем все это нужно\n",
            " да так нет \n",
            "Задайте вопрос : Что можешь сказать\n",
            " да вы куда это \n",
            "Задайте вопрос : Как тебя зовут\n",
            " нет не я \n"
          ]
        }
      ],
      "source": [
        "TestModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Дополнительные вопросы"
      ],
      "metadata": {
        "id": "hNPAiaqssqXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TestModel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6_KbiZsstib",
        "outputId": "bbd71ac8-af79-4df0-c39f-e3a384122558"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Задайте вопрос : Как дела\n",
            " покажите \n",
            "Задайте вопрос : как тебя зовут\n",
            " нет не я \n",
            "Задайте вопрос : сколько тебе лет\n",
            " это мой брат \n",
            "Задайте вопрос : зачем он тебе\n",
            " нет \n",
            "Задайте вопрос : Скажи что\n",
            " а ты кто же до такой и нет \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Выводы:"
      ],
      "metadata": {
        "id": "kw1xkQVNe9v-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Обучение нейронной сети происходит быстро, но требуется много памяти для такого большого массива данных. Поэтому пришлось уменьшить обучающую базу в 2 раза.\n",
        "2. Как видно при обучении ошибка падает.\n",
        "3. Чтобы лучше работала генерация текста вопросы надо задавать более точные, а не общие или расплывчатые.\n",
        "4. При дальнейшем обучении нейросеть уже лучше справляется со своей задачей.\n",
        "5. Для достижения более лучшего результата требуется увеличение обучающей выборке. Подбор архитекруты нейронной сети и ее гиперпараметров. А так же необходимые мощности для обучения."
      ],
      "metadata": {
        "id": "ILpcg548fALm"
      }
    }
  ]
}