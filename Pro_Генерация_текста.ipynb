{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Теплов М.Н. - Pro - Генерация текста",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Задание **Pro**\n",
        "\n",
        "Попробуйте улучшить текущий скрипт чат-бота, внедрив блок кода для присвоения словам вне словаря (out-of-vocabulary) метки «unknown» так, чтобы, встретив в запросе незнакомое слово, исполнение кода не останавливалось, а продолжалось, игнорируя «unknown» слова."
      ],
      "metadata": {
        "id": "rdTK4bDd0lz4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подключение библиотек"
      ],
      "metadata": {
        "id": "QvNsGMkTL5Uv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3h_s5azfLtT9"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import yaml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKmLo1YYOXAb",
        "outputId": "760dc24b-fb1d-4495-c9db-0ef628f5b3d9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Парсинг данных"
      ],
      "metadata": {
        "id": "LMcldUH2OfQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Открываем файл с диалогами\n",
        "corpus = open('/content/drive/MyDrive/УИИ/Генерация текста/Диалоги.yml', 'r')\n",
        "document = yaml.safe_load(corpus)\n",
        "conversations = document['разговоры']\n",
        "print(f'Количество пар вопрос-ответ : {len(conversations)}')\n",
        "print(f'Пример диалога : {conversations[10000]}')\n",
        "corpus.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxP7g0f0OiTK",
        "outputId": "ae1890d0-b957-4200-b007-b4e385d8394e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество пар вопрос-ответ : 11893\n",
            "Пример диалога : ['Откуда вы знаете?', 'Я  Чорин-Цу,  господин.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Разбираем вопросы-ответы с проставлением тегов ответам\n",
        "questions = []\n",
        "answers   = []\n",
        "\n",
        "for con in conversations[:len(conversations)//2]:   # Из-за нехватки памяти пришлось сократить обучающий набор пополам\n",
        "  if len(con) > 2:\n",
        "    questions.append(con[0])\n",
        "    replies = con[1:]\n",
        "    ans = ''\n",
        "    for rep in replies:\n",
        "      ans += \" \" + rep\n",
        "    answers.append(ans)\n",
        "  elif len(con) > 1:\n",
        "    questions.append(con[0])\n",
        "    answers.append(con[1])"
      ],
      "metadata": {
        "id": "UsN_pbTaPe2d"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Очищаем строки с неопределенным типом ответов\n",
        "answersCleaned = []\n",
        "for i in range(len(answers)):\n",
        "  if type(answers[i]) == str:\n",
        "    answersCleaned.append(answers[i])\n",
        "  else:\n",
        "    questions.pop()"
      ],
      "metadata": {
        "id": "Z9AfZkF7Qutw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Сделаем теги-метки для начала и конца ответов\n",
        "answers = []\n",
        "for i in range(len(answersCleaned)):\n",
        "  answers.append('<START>' + answersCleaned[i] + '<END>')"
      ],
      "metadata": {
        "id": "Th9hCMWmQvmY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Выведем обновленные данные на экран\n",
        "print('Вопрос : {}'.format(questions[5000]))\n",
        "print('Ответ  : {}'.format(answers[5000]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYAU-sYtRjHL",
        "outputId": "ecac1a49-18d3-4421-9123-0991eca8bdd6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вопрос : Что?..\n",
            "Ответ  : <START>К Туманной Скале!<END>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Токенайзер"
      ],
      "metadata": {
        "id": "6bwgCX8NC-kl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для токенизации устанавливаем дополнительный парметр **oov_token='unknown'** для того чтобы все неизвестые слова имели индекс **1** с названием **'unknown'**. Так же как и в уроке работа с текстами писателей. "
      ],
      "metadata": {
        "id": "HIyBXITdDA9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Подключаем керасовский токенизатор и собираем словарь индексов\n",
        "#tokenizer = Tokenizer()\n",
        "tokenizer = Tokenizer(oov_token='unknown')\n",
        "tokenizer.fit_on_texts(questions + answers)\n",
        "vocabularyItems = list(tokenizer.word_index.items())\n",
        "vocabularySize = len(vocabularyItems) + 1"
      ],
      "metadata": {
        "id": "0dek4TfiQupJ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print( 'Размер словаря   : {}'.format(vocabularySize))\n",
        "print( 'Фрагмент словаря : {}'.format(vocabularyItems[:100]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfxiEbzgSQLQ",
        "outputId": "f88056dc-7831-4444-c50b-b86e25afbe27"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер словаря   : 9383\n",
            "Фрагмент словаря : [('unknown', 1), ('start', 2), ('end', 3), ('что', 4), ('не', 5), ('а', 6), ('ты', 7), ('я', 8), ('это', 9), ('в', 10), ('как', 11), ('и', 12), ('да', 13), ('нет', 14), ('вы', 15), ('ну', 16), ('на', 17), ('с', 18), ('же', 19), ('где', 20), ('так', 21), ('у', 22), ('кто', 23), ('он', 24), ('то', 25), ('все', 26), ('тебя', 27), ('мы', 28), ('куда', 29), ('мне', 30), ('там', 31), ('есть', 32), ('почему', 33), ('вот', 34), ('за', 35), ('меня', 36), ('тебе', 37), ('ничего', 38), ('здесь', 39), ('еще', 40), ('знаю', 41), ('ли', 42), ('товарищ', 43), ('его', 44), ('к', 45), ('чего', 46), ('вас', 47), ('о', 48), ('надо', 49), ('зачем', 50), ('может', 51), ('вам', 52), ('сейчас', 53), ('по', 54), ('они', 55), ('нас', 56), ('можно', 57), ('чем', 58), ('тут', 59), ('бы', 60), ('но', 61), ('из', 62), ('она', 63), ('тоже', 64), ('конечно', 65), ('какой', 66), ('будет', 67), ('очень', 68), ('случилось', 69), ('уже', 70), ('дело', 71), ('сам', 72), ('сколько', 73), ('значит', 74), ('когда', 75), ('только', 76), ('хорошо', 77), ('такое', 78), ('нибудь', 79), ('точно', 80), ('откуда', 81), ('тогда', 82), ('теперь', 83), ('если', 84), ('быть', 85), ('хочешь', 86), ('их', 87), ('нам', 88), ('командир', 89), ('делать', 90), ('было', 91), ('кого', 92), ('ж', 93), ('от', 94), ('спасибо', 95), ('ага', 96), ('разве', 97), ('или', 98), ('хочу', 99), ('будем', 100)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подготовка выборки"
      ],
      "metadata": {
        "id": "buGjwt4SSV5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Устанавливаем закодированные входные данные(вопросы)\n",
        "tokenizedQuestions = tokenizer.texts_to_sequences(questions)\n",
        "maxLenQuestions = max([len(x) for x in tokenizedQuestions])\n",
        "\n",
        "# Делаем последовательности одной длины\n",
        "encoderForInput = pad_sequences(tokenizedQuestions, maxlen=maxLenQuestions, padding='post')"
      ],
      "metadata": {
        "id": "WiqH34CCSYIg"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Пример оригинального вопроса на вход : {}'.format(questions[1000])) \n",
        "print('Пример кодированного вопроса на вход : {}'.format(encoderForInput[1000])) \n",
        "print('Размеры закодированного массива вопросов на вход : {}'.format(encoderForInput.shape)) \n",
        "print('Установленная длина вопросов на вход : {}'.format(maxLenQuestions)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptxLuQAkSYMC",
        "outputId": "fa0e10b2-bd95-434d-c8af-068290f25f70"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример оригинального вопроса на вход : Куда теперь?\n",
            "Пример кодированного вопроса на вход : [29 83  0  0  0  0  0  0  0  0  0]\n",
            "Размеры закодированного массива вопросов на вход : (5943, 11)\n",
            "Установленная длина вопросов на вход : 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Устанавливаем раскодированные входные данные(ответы)\n",
        "tokenizedAnswers = tokenizer.texts_to_sequences(answers)\n",
        "maxLenAnswers = max([len(x) for x in tokenizedAnswers])\n",
        "\n",
        "# Делаем последовательности одной длины\n",
        "decoderForInput = pad_sequences(tokenizedAnswers, maxlen=maxLenAnswers, padding='post')"
      ],
      "metadata": {
        "id": "GhxXwChSSYPl"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Пример оригинального ответа на вход: {}'.format(answers[1000])) \n",
        "print('Пример раскодированного ответа на вход : {}'.format(decoderForInput[1000])) \n",
        "print('Размеры раскодированного массива ответов на вход : {}'.format(decoderForInput.shape)) \n",
        "print('Установленная длина ответов на вход : {}'.format(maxLenAnswers)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wsknex0SYT5",
        "outputId": "f21a5fa5-1b31-4fa7-c568-92303dbe9aa9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример оригинального ответа на вход: <START>На Родину!<END>\n",
            "Пример раскодированного ответа на вход : [  2  17 943   3   0   0   0   0   0   0   0   0   0]\n",
            "Размеры раскодированного массива ответов на вход : (5943, 13)\n",
            "Установленная длина ответов на вход : 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Раскодированные выходные данные(ответы)\n",
        "for i in range(len(tokenizedAnswers)):\n",
        "  tokenizedAnswers[i] = tokenizedAnswers[i][1:]  # избавляемся от тега <START>\n",
        "\n",
        "# Делаем последовательности одной длины\n",
        "paddedAnswers = pad_sequences(tokenizedAnswers, maxlen=maxLenAnswers, padding='post')"
      ],
      "metadata": {
        "id": "tsU9mGTjXcez"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# переводим в one hot vector\n",
        "oneHotAnswers = to_categorical(paddedAnswers, vocabularySize)\n",
        "decoderForOutput = np.array(oneHotAnswers)"
      ],
      "metadata": {
        "id": "asSi_g_OXci-"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Пример раскодированного ответа на вход : {}'.format(decoderForInput[4999][:21]))  \n",
        "print('Пример раскодированного ответа на выход : {}'.format(decoderForOutput[4999][4][:21])) \n",
        "print('Размеры раскодированного массива ответов на выход : {}'.format(decoderForOutput.shape))\n",
        "print('Установленная длина вопросов на выход : {}'.format(maxLenAnswers)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhGV3zSMZMgg",
        "outputId": "1f081c8e-4901-4d9c-c734-9928ac226fbc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример раскодированного ответа на вход : [   2    8    5 8941  421    3    0    0    0    0    0    0    0]\n",
            "Пример раскодированного ответа на выход : [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Размеры раскодированного массива ответов на выход : (5943, 13, 9383)\n",
            "Установленная длина вопросов на выход : 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем рабочую модель для вывода ответов на запросы пользователя\n",
        "def makeInferenceModels():\n",
        "  encoderModel = Model(encoderInputs, encoderStates)\n",
        "\n",
        "  decoderStateInput_h = Input(shape=(200,))\n",
        "  decoderStateInput_c = Input(shape=(200,))\n",
        "  decoderStatesInputs = [decoderStateInput_h, decoderStateInput_c]\n",
        "\n",
        "  decoderOutputs, state_h, state_c = decoderLSTM(decoderEmbedding, initial_state=decoderStatesInputs)\n",
        "  decoderStates = [state_h, state_c]\n",
        "  decoderOutputs = decoderDense(decoderOutputs)\n",
        "\n",
        "  decoderModel = Model([decoderInputs] + decoderStatesInputs, [decoderOutputs] + decoderStates)\n",
        "\n",
        "  return encoderModel, decoderModel"
      ],
      "metadata": {
        "id": "fZR-XTwofEyi"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################\n",
        "# Создадим функцию, которая преобразует вопрос пользователя в последовательность индексов\n",
        "######################\n",
        "def strToTokens(sentence):      # функция принимает строку на вход (предложение с вопросом)\n",
        "  CheckIndex = tokenizer.texts_to_sequences([sentence])\n",
        "  return pad_sequences(CheckIndex, maxlen=maxLenQuestions , padding='post')"
      ],
      "metadata": {
        "id": "wlx8oe1vJhH0"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ0Dxd1eiEid"
      },
      "source": [
        "# Устанавливаем окончательные настройки и запускаем модель \n",
        "def TestModel():\n",
        "  encModel , decModel = makeInferenceModels()\n",
        "\n",
        "  for _ in range(5):\n",
        "    statesValues = encModel.predict(pad_sequences(tokenizer.texts_to_sequences([input('Задайте вопрос : ')]), maxlen=maxLenQuestions , padding='post'))\n",
        "    emptyTargetSeq = np.zeros((1, 1))    \n",
        "    emptyTargetSeq[0, 0] = tokenizer.word_index['start']\n",
        "\n",
        "    stopCondition = False\n",
        "    decodedTranslation = ''\n",
        "    while not stopCondition :\n",
        "      decOutputs , h , c = decModel.predict([emptyTargetSeq] + statesValues)\n",
        "      sampledWordIndex = np.argmax( decOutputs[0, 0, :])\n",
        "      sampledWord = None\n",
        "      for word , index in tokenizer.word_index.items():\n",
        "        if sampledWordIndex == index:\n",
        "          decodedTranslation += ' {}'.format(word)\n",
        "          sampledWord = word\n",
        "      \n",
        "      if sampledWord == 'end' or len(decodedTranslation.split()) > maxLenAnswers:\n",
        "        stopCondition = True\n",
        "\n",
        "      emptyTargetSeq[0, 0] = sampledWordIndex\n",
        "      statesValues = [h, c]\n",
        "    \n",
        "    print(decodedTranslation[:-3])"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Параметры нейросети и модель обучения"
      ],
      "metadata": {
        "id": "fUVbDABMZ8Hy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Первый входной слой, кодер, выходной слой\n",
        "encoderInputs = Input(shape=(None, ))\n",
        "encoderEmbedding = Embedding(vocabularySize, 200, mask_zero=True)(encoderInputs)\n",
        "encoderOutputs, state_h, state_c = LSTM(200, return_state=True)(encoderEmbedding)\n",
        "encoderStates = [state_h, state_c]"
      ],
      "metadata": {
        "id": "PJB7rcUnZ8wr"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Второй входной слой, декодер, выходной слой\n",
        "decoderInputs = Input(shape=(None, ))\n",
        "decoderEmbedding = Embedding(vocabularySize, 200, mask_zero=True)(decoderInputs)\n",
        "decoderLSTM = LSTM(200, return_state=True, return_sequences=True)\n",
        "decoderOutputs, _ , _ = decoderLSTM (decoderEmbedding, initial_state=encoderStates)\n",
        "decoderDense =  Dense(vocabularySize, activation='softmax')\n",
        "output = decoderDense(decoderOutputs)"
      ],
      "metadata": {
        "id": "gtOwbk75Z8z_"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Собираем тренировочную модель нейросети\n",
        "model = Model([encoderInputs, decoderInputs], output)\n",
        "model.compile(optimizer=RMSprop(), loss='categorical_crossentropy')"
      ],
      "metadata": {
        "id": "Ym8sZPYsdWb2"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучение 20 эпох"
      ],
      "metadata": {
        "id": "MehU3bfxO1TF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit([encoderForInput , decoderForInput], decoderForOutput, batch_size=50, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEZkR_HoHeLb",
        "outputId": "fe174cdd-a7ac-45e6-a133-2e0393f107ce"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "119/119 [==============================] - 4s 33ms/step - loss: 1.3218\n",
            "Epoch 2/50\n",
            "119/119 [==============================] - 4s 34ms/step - loss: 1.2903\n",
            "Epoch 3/50\n",
            "119/119 [==============================] - 5s 39ms/step - loss: 1.2603\n",
            "Epoch 4/50\n",
            "119/119 [==============================] - 4s 32ms/step - loss: 1.2311\n",
            "Epoch 5/50\n",
            "119/119 [==============================] - 4s 33ms/step - loss: 1.2020\n",
            "Epoch 6/50\n",
            "119/119 [==============================] - 4s 32ms/step - loss: 1.1747\n",
            "Epoch 7/50\n",
            "119/119 [==============================] - 4s 32ms/step - loss: 1.1456\n",
            "Epoch 8/50\n",
            "119/119 [==============================] - 4s 33ms/step - loss: 1.1179\n",
            "Epoch 9/50\n",
            "119/119 [==============================] - 4s 36ms/step - loss: 1.0911\n",
            "Epoch 10/50\n",
            "119/119 [==============================] - 4s 32ms/step - loss: 1.0617\n",
            "Epoch 11/50\n",
            "119/119 [==============================] - 4s 33ms/step - loss: 1.0344\n",
            "Epoch 12/50\n",
            "119/119 [==============================] - 4s 34ms/step - loss: 1.0083\n",
            "Epoch 13/50\n",
            "119/119 [==============================] - 4s 33ms/step - loss: 0.9842\n",
            "Epoch 14/50\n",
            "119/119 [==============================] - 4s 32ms/step - loss: 0.9584\n",
            "Epoch 15/50\n",
            "119/119 [==============================] - 4s 32ms/step - loss: 0.9332\n",
            "Epoch 16/50\n",
            "119/119 [==============================] - 4s 32ms/step - loss: 0.9077\n",
            "Epoch 17/50\n",
            "119/119 [==============================] - 4s 33ms/step - loss: 0.8821\n",
            "Epoch 18/50\n",
            "119/119 [==============================] - 4s 34ms/step - loss: 0.8595\n",
            "Epoch 19/50\n",
            "119/119 [==============================] - 4s 33ms/step - loss: 0.8365\n",
            "Epoch 20/50\n",
            "119/119 [==============================] - 4s 33ms/step - loss: 0.8142\n",
            "Epoch 21/50\n",
            "119/119 [==============================] - 4s 34ms/step - loss: 0.7929\n",
            "Epoch 22/50\n",
            "119/119 [==============================] - 4s 35ms/step - loss: 0.7712\n",
            "Epoch 23/50\n",
            "119/119 [==============================] - 4s 33ms/step - loss: 0.7503\n",
            "Epoch 24/50\n",
            "119/119 [==============================] - 4s 33ms/step - loss: 0.7304\n",
            "Epoch 25/50\n",
            "119/119 [==============================] - 4s 33ms/step - loss: 0.7103\n",
            "Epoch 26/50\n",
            "119/119 [==============================] - 4s 32ms/step - loss: 0.6913\n",
            "Epoch 27/50\n",
            "119/119 [==============================] - 4s 35ms/step - loss: 0.6727\n",
            "Epoch 28/50\n",
            "119/119 [==============================] - 5s 40ms/step - loss: 0.6547\n",
            "Epoch 29/50\n",
            "119/119 [==============================] - 4s 32ms/step - loss: 0.6386\n",
            "Epoch 30/50\n",
            "119/119 [==============================] - 4s 32ms/step - loss: 0.6222\n",
            "Epoch 31/50\n",
            "119/119 [==============================] - 4s 32ms/step - loss: 0.6078\n",
            "Epoch 32/50\n",
            "119/119 [==============================] - 4s 32ms/step - loss: 0.5935\n",
            "Epoch 33/50\n",
            "119/119 [==============================] - 4s 32ms/step - loss: 0.5809\n",
            "Epoch 34/50\n",
            "119/119 [==============================] - 4s 32ms/step - loss: 0.5669\n",
            "Epoch 35/50\n",
            "119/119 [==============================] - 4s 33ms/step - loss: 0.5551\n",
            "Epoch 36/50\n",
            "119/119 [==============================] - 4s 33ms/step - loss: 0.5420\n",
            "Epoch 37/50\n",
            "119/119 [==============================] - 4s 33ms/step - loss: 0.5298\n",
            "Epoch 38/50\n",
            "119/119 [==============================] - 4s 32ms/step - loss: 0.5186\n",
            "Epoch 39/50\n",
            "119/119 [==============================] - 4s 32ms/step - loss: 0.5091\n",
            "Epoch 40/50\n",
            "119/119 [==============================] - 4s 32ms/step - loss: 0.5002\n",
            "Epoch 41/50\n",
            "119/119 [==============================] - 4s 33ms/step - loss: 0.4912\n",
            "Epoch 42/50\n",
            "119/119 [==============================] - 4s 33ms/step - loss: 0.4831\n",
            "Epoch 43/50\n",
            "119/119 [==============================] - 4s 32ms/step - loss: 0.4755\n",
            "Epoch 44/50\n",
            "119/119 [==============================] - 4s 32ms/step - loss: 0.4684\n",
            "Epoch 45/50\n",
            "119/119 [==============================] - 4s 32ms/step - loss: 0.4624\n",
            "Epoch 46/50\n",
            "119/119 [==============================] - 4s 32ms/step - loss: 0.4562\n",
            "Epoch 47/50\n",
            "119/119 [==============================] - 4s 32ms/step - loss: 0.4497\n",
            "Epoch 48/50\n",
            "119/119 [==============================] - 4s 33ms/step - loss: 0.4447\n",
            "Epoch 49/50\n",
            "119/119 [==============================] - 4s 33ms/step - loss: 0.4398\n",
            "Epoch 50/50\n",
            "119/119 [==============================] - 4s 33ms/step - loss: 0.4348\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa86c554e50>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Сохранение весов\n",
        "model.save_weights('/content/drive/MyDrive/УИИ/Генерация текста/Pro.h5')"
      ],
      "metadata": {
        "id": "rzYyNg0TOTLH"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Проверка результата\n"
      ],
      "metadata": {
        "id": "B2uqk2vDeaPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка весов\n",
        "#model.load_weights('/content/drive/MyDrive/УИИ/Генерация текста/Pro.h5')"
      ],
      "metadata": {
        "id": "Jd3CVkF7OXFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TestModel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-isQb9hkI3h",
        "outputId": "396ee6fc-e00a-451c-90a6-0dec2e8fe53b"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Задайте вопрос : Как твои дела\n",
            " все в порядке \n",
            "Задайте вопрос : Есть ли жизнь на Марсе\n",
            " нет в порядке \n",
            "Задайте вопрос : ку\n",
            " нет ничего \n",
            "Задайте вопрос : А что если авыаывроавы\n",
            " это тебе теперь \n",
            "Задайте вопрос : А вот если так оыводлыап\n",
            " мне бы и хорошо \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Выводы:"
      ],
      "metadata": {
        "id": "AFH4xd3VO4-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Обучение происходило лишь на половине примеров из-за нехватки памяти. Но в целом ответы нейронной сети приемлемы.\n",
        "2. Слова которые не входят в ее словарь принимают значения **unknow** с индексом **1**. Что не вызывает ошибок.\n",
        "3. Перевод в цифровое значение происходит так же как и в занятиях по работе с текстами писателей. \n",
        "4. Данный пример показывает что возможно хорошо обучить нейронную сеть имея большее кол-во разнообразных примеров. Пробуя различную архитектуру и оптимальный подбор гиперпараметров.  "
      ],
      "metadata": {
        "id": "N48_zLowO7oR"
      }
    }
  ]
}